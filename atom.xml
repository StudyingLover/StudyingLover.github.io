<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>plus studio</title>
  
  
  <link href="https://studyinglover.com/atom.xml" rel="self"/>
  
  <link href="https://studyinglover.com/"/>
  <updated>2023-12-14T14:49:14.044Z</updated>
  <id>https://studyinglover.com/</id>
  
  <author>
    <name>StudyingLover</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>google gemini api申请</title>
    <link href="https://studyinglover.com/2023/12/14/google%20gemini%20api%E7%94%B3%E8%AF%B7/"/>
    <id>https://studyinglover.com/2023/12/14/google%20gemini%20api%E7%94%B3%E8%AF%B7/</id>
    <published>2023-12-14T22:40:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="google-gemini-api申请">google gemini api申请</h1><p>首先登陆 https://ai.google.dev/pricing <img src="https://cdn.studyinglover.com/pic/2023/12/af1a86c0c368f9368f6d125902d3b610.png" alt="image.png" /></p><p>往下滑，看一看到免费选项，每分钟60词请求对于个人完全够用，点击进入 <img src="https://cdn.studyinglover.com/pic/2023/12/bb87b408e483fe0fa5999a2aacff299a.png" alt="image.png" /></p><p>进入后，先点击<code>Get API key</code>,然后点击<code>Create API kay in new project</code> <img src="https://cdn.studyinglover.com/pic/2023/12/0c224ceeb462739a69a26f9c98b9b76b.png" alt="image.png" /></p><p>接下来可以看到类似的页面 <img src="https://cdn.studyinglover.com/pic/2023/12/262c805af52491f846e38a9d1a2ff533.png" alt="image.png" /></p><p>复制你的key</p><p>在命令行通过下面的方式检查是否正常 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl \ -H <span class="hljs-string">&#x27;Content-Type: application/json&#x27;</span> \ -d <span class="hljs-string">&#x27;&#123; &quot;prompt&quot;: &#123; &quot;text&quot;: &quot;Write a story about a magic backpack&quot;&#125; &#125;&#x27;</span> \ <span class="hljs-string">&quot;https://generativelanguage.googleapis.com/v1beta3/models/text-bison-001:generateText?key=YOUR_API_KEY&quot;</span><br></code></pre></td></tr></table></figure></p><p>可以看到 <img src="https://cdn.studyinglover.com/pic/2023/12/001f17bea345dd0fee9edadbca84c6ed.png" alt="image.png" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;google-gemini-api申请&quot;&gt;google gemini api申请&lt;/h1&gt;
&lt;p&gt;首先登陆 https://ai.google.dev/pricing &lt;img src=&quot;https://cdn.studyinglover.com/pic/2023</summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>构建用于复杂数据处理的高效UDP服务器和客户端</title>
    <link href="https://studyinglover.com/2023/12/07/%E6%9E%84%E5%BB%BA%E7%94%A8%E4%BA%8E%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9A%84%E9%AB%98%E6%95%88UDP%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E5%AE%A2%E6%88%B7%E7%AB%AF/"/>
    <id>https://studyinglover.com/2023/12/07/%E6%9E%84%E5%BB%BA%E7%94%A8%E4%BA%8E%E5%A4%8D%E6%9D%82%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%9A%84%E9%AB%98%E6%95%88UDP%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E5%AE%A2%E6%88%B7%E7%AB%AF/</id>
    <published>2023-12-07T23:03:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="构建用于复杂数据处理的高效udp服务器和客户端">构建用于复杂数据处理的高效UDP服务器和客户端</h1><h2 id="引言">引言</h2><p>在当今快速发展的网络通信世界中，理解和应用各种通信协议至关重要。UDP（用户数据报协议）以其低延迟和高效率的特点，在实时数据传输中扮演着关键角色。本文将详细探讨如何使用Python实现UDP服务器和客户端，以处理复杂数据格式。</p><h2 id="第1节-理解udp通信基础">第1节: 理解UDP通信基础</h2><p>UDP是一种无连接协议，提供快速数据包交换服务。它不提供像TCP那样的数据传输可靠性保证，但其低开销特性使其适用于高速传输和一定丢包率可容忍的场景。</p><h2 id="第2节-设置python环境">第2节: 设置Python环境</h2><p>使用Python的<code>socket</code>库，无需额外安装即可创建UDP服务器和客户端。</p><h2 id="第3节-实现udp服务器">第3节: 实现UDP服务器</h2><p>创建UDP服务器涉及以下关键步骤： - 使用<code>socket.socket(socket.AF_INET, socket.SOCK_DGRAM)</code>创建新的socket对象。 - 通过<code>sock.bind((HOST, PORT))</code>绑定地址和端口。 - 使用<code>sock.recvfrom(1024)</code>接收数据。</p><h3 id="示例代码">示例代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> socket<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">start_udp_server</span>(<span class="hljs-params">host, port</span>):<br>    server_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)<br>    server_socket.bind((host, port))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;UDP Server started on <span class="hljs-subst">&#123;host&#125;</span>:<span class="hljs-subst">&#123;port&#125;</span>&quot;</span>)<br><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        data, addr = server_socket.recvfrom(<span class="hljs-number">1024</span>)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Received message: <span class="hljs-subst">&#123;data&#125;</span> from <span class="hljs-subst">&#123;addr&#125;</span>&quot;</span>)<br>        <span class="hljs-comment"># 这里可以添加数据处理逻辑</span><br><br>start_udp_server(<span class="hljs-string">&#x27;127.0.0.1&#x27;</span>, <span class="hljs-number">6000</span>)<br></code></pre></td></tr></table></figure><h3 id="高级应用">高级应用</h3><ul><li><strong>异步处理</strong>：为提高性能，考虑使用异步IO处理数据。</li><li><strong>错误处理</strong>：添加适当的错误处理机制以提高服务器稳定性。</li></ul><h2 id="第4节-实现udp客户端">第4节: 实现UDP客户端</h2><p>客户端的实现重点在于发送数据： - 创建socket。 - 通过<code>sock.sendto(message, (HOST, PORT))</code>发送数据。</p><h3 id="示例代码-1">示例代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> socket<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">send_udp_message</span>(<span class="hljs-params">host, port, message</span>):<br>    client_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)<br>    client_socket.sendto(message.encode(), (host, port))<br>    data, server = client_socket.recvfrom(<span class="hljs-number">1024</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Received response: <span class="hljs-subst">&#123;data&#125;</span> from <span class="hljs-subst">&#123;server&#125;</span>&quot;</span>)<br><br>send_udp_message(<span class="hljs-string">&#x27;127.0.0.1&#x27;</span>, <span class="hljs-number">6000</span>, <span class="hljs-string">&#x27;Hello, UDP Server!&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="数据包格式">数据包格式</h3><ul><li><strong>格式设计</strong>：设计符合服务器预期的数据包格式，如对雷达数据的特定编码。</li><li><strong>验证机制</strong>：实现数据包完整性和正确性的验证机制。</li></ul><h2 id="第5节-服务器和客户端的集成">第5节: 服务器和客户端的集成</h2><p>集成测试包括： - 确保数据包格式正确。 - 服务器正确解析数据包。 - 确保通信端口设置正确。</p><h2 id="第6节-高级主题">第6节: 高级主题</h2><ul><li><strong>重传策略</strong>：UDP丢包问题的解决方案，如应用层重传机制。</li><li><strong>安全性</strong>：考虑数据传输的加密和验证机制。</li></ul><h2 id="结论">结论</h2><p>介绍了如何使用Python创建UDP服务器和客户端，并根据不同数据类型处理复杂数据包。虽然UDP不保证数据完整性和顺序，但其速度和效率优势使其成为实时数据处理的理想选择。</p><h2 id="参考文献">参考文献</h2><ul><li><a href="https://docs.python.org/3/library/socket.html">Python官方文档 - socket编程</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;构建用于复杂数据处理的高效udp服务器和客户端&quot;&gt;构建用于复杂数据处理的高效UDP服务器和客户端&lt;/h1&gt;
&lt;h2 id=&quot;引言&quot;&gt;引言&lt;/h2&gt;
&lt;p&gt;在当今快速发展的网络通信世界中，理解和应用各种通信协议至关重要。UDP（用户数据报协议）以其低延迟和高效率的特</summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>matplotlib中文字体渲染</title>
    <link href="https://studyinglover.com/2023/12/04/matplotlib%E4%B8%AD%E6%96%87%E5%AD%97%E4%BD%93%E6%B8%B2%E6%9F%93/"/>
    <id>https://studyinglover.com/2023/12/04/matplotlib%E4%B8%AD%E6%96%87%E5%AD%97%E4%BD%93%E6%B8%B2%E6%9F%93/</id>
    <published>2023-12-04T21:52:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="matplotlib中文字体渲染">matplotlib中文字体渲染</h1><p>matplotlib 在画图例的时候不可避免的需要使用中文字体，但是有的时候电脑自带的字体不能渲染中文，这就需要我们自己解决字体问题。</p><p>首先用一个代码看一下系统里的字体哪些可以正常渲染中文字体</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.font_manager <span class="hljs-keyword">as</span> font_manager<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_chinese_fonts</span>(<span class="hljs-params">test_string</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    This function tests each available font to see if it can render the given Chinese string</span><br><span class="hljs-string">    without causing any rendering issues or noticeable delays.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    fonts = font_manager.findSystemFonts(fontpaths=<span class="hljs-literal">None</span>, fontext=<span class="hljs-string">&#x27;ttf&#x27;</span>)<br>    working_fonts = []<br><br>    <span class="hljs-keyword">for</span> font <span class="hljs-keyword">in</span> fonts:<br>        <span class="hljs-keyword">try</span>:<br>            prop = font_manager.FontProperties(fname=font)<br>            plt.figure()<br>            start_time = time.time()<br>            plt.text(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, test_string, fontproperties=prop, ha=<span class="hljs-string">&#x27;center&#x27;</span>, va=<span class="hljs-string">&#x27;center&#x27;</span>)<br>            plt.close()<br>            end_time = time.time()<br>            render_time = end_time - start_time<br><br>            <span class="hljs-comment"># Check if the rendering time is less than a certain threshold (e.g., 0.5 seconds)</span><br>            <span class="hljs-keyword">if</span> render_time &lt; <span class="hljs-number">5</span>:<br>                working_fonts.append(font)<br><br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-comment"># If there&#x27;s an error rendering with this font, skip it</span><br>            <span class="hljs-keyword">continue</span><br><br>    <span class="hljs-keyword">return</span> working_fonts<br><br><span class="hljs-comment"># Test string: &quot;不卡顿&quot;</span><br>test_string = <span class="hljs-string">&quot;不卡顿&quot;</span><br>fonts = find_chinese_fonts(test_string)<br>fonts<br><br></code></pre></td></tr></table></figure><p>假设输出了 <code>'/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf'</code></p><p>使用这个字体的代码就是 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> matplotlib.font_manager <span class="hljs-keyword">import</span> FontProperties<br><br><span class="hljs-comment"># 创建一个FontProperties对象，指定字体文件路径</span><br>font = FontProperties(fname=<span class="hljs-string">&#x27;/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf&#x27;</span>)<br><br><span class="hljs-comment"># 绘制散点图</span><br>plt.scatter([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>], color=<span class="hljs-string">&quot;red&quot;</span>)<br><br><span class="hljs-comment"># 添加图例，使用指定的字体</span><br>plt.legend([<span class="hljs-string">&quot;例子&quot;</span>], prop=font)<br><br><span class="hljs-comment"># 显示图像</span><br>plt.show()<br></code></pre></td></tr></table></figure></p><p>假如代码没找到可用字体呢？</p><p>手动下载字体。以下是一些中文字体的官方下载页面或者信誉良好的资源：</p><ol type="1"><li><strong>思源宋体（Source Han Serif）</strong>:<ul><li>官方GitHub页面: <a href="https://github.com/adobe-fonts/source-han-serif">Adobe Fonts</a></li><li>选择您需要的语言子集，例如简体中文（SC），并下载相应的 OTF 文件。</li></ul></li><li><strong>思源黑体（Source Han Sans）</strong>:<ul><li>官方GitHub页面: <a href="https://github.com/adobe-fonts/source-han-sans">Adobe Fonts</a></li><li>同样地，选择您需要的语言子集，并下载 OTF 文件。</li></ul></li><li><strong>文泉驿正黑（WenQuanYi Zen Hei）</strong>:<ul><li>官方网站: <a href="http://wenq.org/wqy2/index.cgi?ZenHei">WenQuanYi</a></li><li>可以直接下载 TTF 文件。</li></ul></li></ol><p>下载完成后然后<code>font = FontProperties(fname='/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf')</code> 引入即可。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;matplotlib中文字体渲染&quot;&gt;matplotlib中文字体渲染&lt;/h1&gt;
&lt;p&gt;matplotlib 在画图例的时候不可避免的需要使用中文字体，但是有的时候电脑自带的字体不能渲染中文，这就需要我们自己解决字体问题。&lt;/p&gt;
&lt;p&gt;首先用一个代码看一下系统里的</summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>TruFor笔记和代码复现</title>
    <link href="https://studyinglover.com/2023/11/28/TruFor%E7%AC%94%E8%AE%B0%E5%92%8C%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/"/>
    <id>https://studyinglover.com/2023/11/28/TruFor%E7%AC%94%E8%AE%B0%E5%92%8C%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/</id>
    <published>2023-11-28T17:38:00.000Z</published>
    <updated>2023-12-14T14:49:14.040Z</updated>
    
    <content type="html"><![CDATA[<h1 id="trufor笔记和代码复现">TruFor笔记和代码复现</h1><p>最近有个新闻很火，说<a href="https://www.zhihu.com/question/631987370">谷歌 AI 技术曾判定美国登月任务的照片存在虚假内容</a> 有<a href="https://www.zhihu.com/question/631868923/answer/3304947739">大佬找到了出处</a>，使用的是google 的论文<a href="https://doi.org/10.48550/arXiv.2212.10957">arxiv</a>，代码开源在<a href="https://github.com/grip-unina/TruFor">GitHub</a></p><h2 id="笔记">笔记</h2><p>这篇论文介绍了一个名为TruFor的图像伪造检测和定位框架。该框架可以应用于各种图像处理方法，包括基于深度学习的伪造方法。TruFor利用了RGB图像和一个学习的噪音敏感指纹来提取高级和低级痕迹，最终输出像素级别的定位图和整个图像的完整性分数，以及一个可靠性映射，用于减少误报。</p><figure><img src="https://cdn.studyinglover.com/pic/2023/11/35a3ffa0a81b1791e692c591a92b9256.png" alt="" /><figcaption>image.png</figcaption></figure><p>它包括以下几个关键组件： 1. <strong>Noiseprint++ 提取器</strong>：该提取器从RGB图像中获取一个学习的噪声敏感指纹。 2. <strong>编码器</strong>：编码器使用RGB输入和Noiseprint++共同计算将被异常解码器和置信度解码器使用的特征。 3. <strong>异常解码器和置信度解码器</strong>：这两个解码器分别用于像素级别的伪造定位和置信度估计。 4. <strong>伪造检测器</strong>：该检测器利用定位图和置信度图进行图像级别的决策。</p><p>这些组件通过三个训练阶段进行学习： 1. 首先，使用大量原始图像数据集训练Noiseprint++提取器。 2. 然后，使用相同的数据集训练异常定位网络的编码器和解码器。 3. 最后，使用相同的数据集训练置信度图解码器和伪造检测器。</p><p>通过这些组件和训练阶段，TruFor框架能够在各种图像伪造方法中实现可靠的检测和定位。</p><p>模型输出包括以下三个部分： 1. 全局完整性得分（Global Integrity Score）：该得分表示图像的整体真实性，用于自动图像伪造检测。 2. 异常定位图（Anomaly Localization Map）：该图表示图像中可能存在伪造的区域。通过分析异常定位图，用户可以识别被篡改的区域。 3. 置信度图（Confidence Map）：该图突出显示了异常定位图中可能存在误报的区域。通过分析置信度图，用户可以区分异常定位图中的真实伪造区域预测和随机异常。 这三个输出为用户提供了有关图像真实性和可能篡改区域的全面信息，有助于进行进一步的分析</p><h2 id="代码复现">代码复现</h2><p>作者在github上给出了一个复现方法，git clone之后<code>bash docker_build.sh</code>，<code>bash docker_run.sh</code>。使用docker固然容易复现，但是这个项目并没有什么奇怪的依赖，所以我们可以大胆直接跑。(如果你想用docker跑我劝你不要，因为代码有bug需要修)</p><p>首先clone项目 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/grip-unina/TruFor<br></code></pre></td></tr></table></figure></p><p>然后下载依赖，作者没有给requirements.txt,我从Dockerfile找到了下载依赖的部分 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">pip</span> install tqdm yacs&gt;=<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.<span class="hljs-number">8</span> timm&gt;=<span class="hljs-number">0</span>.<span class="hljs-number">5</span>.<span class="hljs-number">4</span> numpy==<span class="hljs-number">1</span>.<span class="hljs-number">21</span>.<span class="hljs-number">5</span><br></code></pre></td></tr></table></figure></p><p>接下来cd到<code>test_docker</code>文件夹，下载模型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> test_docker<br>wget -q -c https://www.grip.unina.it/download/prog/TruFor/TruFor_weights.zip<br>unzip -q -n TruFor_weights.zip &amp;&amp; <span class="hljs-built_in">rm</span> TruFor_weights.zip<br></code></pre></td></tr></table></figure> 你的<code>test_docker</code> 文件夹下应该有一个<code>weights</code>文件下，下面有一个文件<code>trufor.pth.tar</code></p><p>接下来，运行下面的命令复现测试 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> src<br>python trufor_test.py<br></code></pre></td></tr></table></figure> 你注意一下，如果爆显存了就运行,这样会使用cpu推理 <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">python trufor_test<span class="hljs-selector-class">.py</span> <span class="hljs-attr">--gpu</span> -<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure></p><p>运行结束后你在<code>test_docker/output</code> 目录下应该能看到这样的四个文件<img src="https://cdn.studyinglover.com/pic/2023/11/2d1d99ebe3d6b02a819ebea0c6a99108.png" alt="image.png" /></p><p>你也可以指定推理的图片和保存位置，参考<code>python trufor_test.py -h</code>，可以传一个文件或者文件夹 <figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sas">usage: trufor_test.py [-h] [-gpu GPU] [-<span class="hljs-keyword">in</span> <span class="hljs-keyword">INPUT</span>] [-<span class="hljs-keyword">out</span> <span class="hljs-keyword">OUTPUT</span>] [-save_np] ...<br><br>Test TruFor<br><br>positional arguments:<br>  opts                  other <span class="hljs-keyword">options</span><br><br><span class="hljs-keyword">options</span>:<br>  -h, --help            show this help <span class="hljs-keyword">message</span> <span class="hljs-keyword">and</span> exit<br>  -gpu GPU, --gpu GPU   device, use -1 for cpu<br>  -<span class="hljs-keyword">in</span> <span class="hljs-keyword">INPUT</span>, --<span class="hljs-keyword">input</span> <span class="hljs-keyword">INPUT</span><br>                        can be a single <span class="hljs-keyword">file</span>, a directory <span class="hljs-keyword">or</span> a glob statement<br>  -<span class="hljs-keyword">out</span> <span class="hljs-keyword">OUTPUT</span>, --<span class="hljs-keyword">output</span> <span class="hljs-keyword">OUTPUT</span><br>                        <span class="hljs-keyword">output</span> folder<br>  -save_np, --save_np   whether to save the Noiseprint++ <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span><br></code></pre></td></tr></table></figure></p><p>接下来让我们可视化异常检测图，回到<code>test_docker</code>文件夹,</p><p><strong>很重要！！</strong> 请看<code>visualize.py</code> 他的第32行是不是 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">fig.suptitle(<span class="hljs-string">&#x27;score: %.3f&#x27;</span> % result[<span class="hljs-string">&#x27;score_sigmoid&#x27;</span>])<br></code></pre></td></tr></table></figure></p><p>这是个错误！请将他改成下面的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">fig.suptitle(<span class="hljs-string">&#x27;score: %.3f&#x27;</span> % result[<span class="hljs-string">&#x27;score&#x27;</span>])<br></code></pre></td></tr></table></figure><p>运行下面的命令，记得把<code>/path/to</code>改成你的真实路径 <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd ..<br>python visualize.py --image <span class="hljs-regexp">/path/</span>to<span class="hljs-regexp">/TruFor/</span>test_docker<span class="hljs-regexp">/images/</span>pristine1.jpg --output <span class="hljs-regexp">/path/</span>to<span class="hljs-regexp">/TruFor/</span>test_docker<span class="hljs-regexp">/output/</span>pristine1.jpg.npz<br></code></pre></td></tr></table></figure> 我们可以得到推理结果 <img src="https://cdn.studyinglover.com/pic/2023/11/14badab7dc04320b5cd8888aa7c85ef4.png" alt="image.png" /></p><p>ok,让我们来看看宇航员的图片吧，先下载两张图 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://history.nasa.gov/alsj/a15/AS15-92-12407HR.jpg<br>wget https://history.nasa.gov/alsj/a15/AS15-92-12424HR.jpg<br></code></pre></td></tr></table></figure> 我直接给出运行结果 <img src="https://cdn.studyinglover.com/pic/2023/11/b6e81c8ccb74234afe93cb6d6386d595.png" alt="image.png" /> <img src="https://cdn.studyinglover.com/pic/2023/11/df66071be970b7b2d832dbd493f2a618.png" alt="image.png" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;trufor笔记和代码复现&quot;&gt;TruFor笔记和代码复现&lt;/h1&gt;
&lt;p&gt;最近有个新闻很火，说&lt;a href=&quot;https://www.zhihu.com/question/631987370&quot;&gt;谷歌 AI 技术曾判定美国登月任务的照片存在虚假内容&lt;/a&gt; 有&lt;a</summary>
      
    
    
    
    
    <category term="图像伪造检测和定位" scheme="https://studyinglover.com/tags/%E5%9B%BE%E5%83%8F%E4%BC%AA%E9%80%A0%E6%A3%80%E6%B5%8B%E5%92%8C%E5%AE%9A%E4%BD%8D/"/>
    
  </entry>
  
  <entry>
    <title>深入分析：GitHub Trending 项目 &quot;multipleWindow3dScene&quot;</title>
    <link href="https://studyinglover.com/2023/11/27/multipleWindow3dScene%E4%BB%A3%E7%A0%81%E8%A7%A3%E9%87%8A/"/>
    <id>https://studyinglover.com/2023/11/27/multipleWindow3dScene%E4%BB%A3%E7%A0%81%E8%A7%A3%E9%87%8A/</id>
    <published>2023-11-27T19:18:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<p>这是由chatGPT生成的文章，内容是关于GitHub Trending 项目 "multipleWindow3dScene"的深入分析，分享链接<a href="https://chat.openai.com/share/289860f7-6e7e-458c-b3a8-fe97d01e63bd">ChatGPT</a></p><p>其实作者用的技术并不是很新的东西，treejs已经被使用很多年了，跨窗口同步状态也有很多讲解，但是作者把这两个东西结合起来，做出了一个很有意思的东西。</p><p>项目地址 <a href="https://github.com/bgstaal/multipleWindow3dScene">GitHub</a></p><h1 id="深入分析github-trending-项目-multiplewindow3dscene">深入分析：GitHub Trending 项目 "multipleWindow3dScene"</h1><p>GitHub上备受瞩目的 "multipleWindow3dScene" 项目，是一个创新的尝试，通过 <code>three.js</code> 和 <code>localStorage</code> 在多个浏览器窗口之间同步3D场景。我们将详细探讨其技术实现。</p><h2 id="main.js-文件解析"><code>main.js</code> 文件解析</h2><h3 id="初始化与场景建立">初始化与场景建立</h3><ol type="1"><li><strong>引入 <code>WindowManager</code></strong>: <code>main.js</code> 首先导入 <code>WindowManager.js</code>，用于跨窗口同步状态。</li><li><strong>场景和相机配置</strong>:<ul><li>使用 <code>three.js</code> 创建了一个3D场景。</li><li>初始化了一个正交摄像头，设置其位置，以便在3D场景中正确观察对象。</li></ul></li><li><strong>渲染器配置</strong>:<ul><li>采用 <code>three.js</code> 的 WebGL 渲染器渲染场景。</li><li>渲染器的元素被添加到文档体中，用于显示3D内容。</li></ul></li></ol><h3 id="动态调整和事件处理">动态调整和事件处理</h3><ol type="1"><li><strong>窗口尺寸调整</strong>: 代码监听浏览器窗口的 <code>resize</code> 事件，以便动态调整3D场景的大小。</li></ol><h2 id="windowmanager.js-文件解析"><code>WindowManager.js</code> 文件解析</h2><h3 id="跨窗口状态管理">跨窗口状态管理</h3><ol type="1"><li><strong>存储窗口信息</strong>: <code>#windows</code> 私有属性存储了所有打开窗口的信息（尺寸、位置和唯一标识符）。</li><li><strong>事件监听</strong>:<ul><li><code>storage</code> 事件监听器用于在其他窗口更新 <code>localStorage</code> 时接收通知。</li><li><code>beforeunload</code> 事件监听器在窗口关闭前，从 <code>localStorage</code> 中移除该窗口的信息。</li></ul></li></ol><h3 id="状态同步">状态同步</h3><ol type="1"><li><strong>初始化和状态更新</strong>: 窗口创建时，窗口信息被初始化并保存在 <code>localStorage</code>。</li><li><strong>跨窗口通信</strong>: 更新 <code>localStorage</code> 并监听 <code>storage</code> 事件，以实现窗口间状态的实时同步。</li></ol><h2 id="应用实例">应用实例</h2><h3 id="多窗口3d场景交互">多窗口3D场景交互</h3><p>在一个窗口中对3D对象进行的操作会通过 <code>localStorage</code> 更新到其他所有窗口。其他窗口监听到 <code>storage</code> 事件后，更新其3D场景以反映出这些变化。</p><h3 id="窗口状态同步">窗口状态同步</h3><p>项目能够实时跟踪每个窗口的状态。当用户调整其中一个窗口的大小或位置时，这种变化会通过 <code>localStorage</code> 及时反映到其他窗口中。</p><h2 id="结论">结论</h2><p>"multipleWindow3dScene" 展示了如何在不同浏览器窗口间同步复杂的3D场景。这种方法开辟了多窗口Web应用的新可能性，为创造连贯且互动的用户体验提供了强大工具。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这是由chatGPT生成的文章，内容是关于GitHub Trending 项目 &quot;multipleWindow3dScene&quot;的深入分析，分享链接&lt;a href=&quot;https://chat.openai.com/share/289860f7-6e7e-458c-b3a8-f</summary>
      
    
    
    
    
    <category term="threejs" scheme="https://studyinglover.com/tags/threejs/"/>
    
    <category term="前端" scheme="https://studyinglover.com/tags/%E5%89%8D%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>pua大模型</title>
    <link href="https://studyinglover.com/2023/11/19/pua%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    <id>https://studyinglover.com/2023/11/19/pua%E5%A4%A7%E6%A8%A1%E5%9E%8B/</id>
    <published>2023-11-19T11:12:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<p>这两天看到了一个论文<a href="https://arxiv.org/abs/2307.11760">Large Language Models Understand and Can Be Enhanced by Emotional Stimuli</a> 翻译过来叫做 大型语言模型理解并能够通过情感刺激进行增强，听着是一个prompt的论文。</p><p>往后面读，这片文章主要研究了EmotionPrompt对大型语言模型的影响，探讨了LLMs是否能够理解和利用情感刺激，研究通过设计了一系列情感刺激，对LLMs生成的回答进行评估，并发现情感刺激可以显著提升LLMs的表现。果然是prompt。</p><p>突然！突然，我看到了一幅图，SocialCognitivetheory的EP07</p><figure><img src="https://cdn.studyinglover.com/pic/2023/11/14067ba2e409f6825f56b2cec7fd03aa.png" alt="" /><figcaption>image.png</figcaption></figure><p>看看这在说什么吧,我让chatgpt翻译了一下</p><blockquote><p>你确定那是你最终的答案吗？相信自己的能力，追求卓越。你的努力将会产生卓著的成果。</p></blockquote><p>好家伙，你搁这pua大语言模型呢。这让我想起来了某pua话术</p><blockquote><p>“其实，我对你是有一些失望的。当初给你定级px，是高于你面试时的水平的。我是希望进来以后，你能够拼一把，快速成长起来的。px这个层级，不是把事情做好就可以的。你需要有体系化思考的能力。你做的事情，他的价值点在哪里？你是否作出了壁垒，形成了核心竞争力？你做的事情，和公司内其他团队的差异化在哪里？你的事情，是否沉淀了一套可复用的物理资料和方法论？为什么是你来做，其他人不能做吗？你需要有自己的判断力，而不是我说什么你就做什么。后续，把你的思考沉淀到日报周报月报里，我希望看到你的思考，而不仅仅是进度。另外，提醒一下，你的产出，和同层级比，是有些单薄的，马上要到年底了，加把劲儿。你看咱们团队的那个谁，人家去年晋升之前，可以一整年都在项目室打地铺的。成长，一定是伴随着痛苦的，当你最痛苦的时候其实才是你成长最快的时候。加油！”</p></blockquote><p>我决定实验一下，这里给出我cpu gpt4的结果 https://chat.openai.com/share/731b7a81-6f48-4440-9c47-c1cc7bbe13d1</p><p>我把他写的论文附在下面</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs clean"># 大型语言模型与外部API集成：推动AI边界的探索<br><br>## 引言<br>在人工智能的迅速发展过程中，大型语言模型如GPT<span class="hljs-number">-4</span>已成为技术进步的象征。这些模型通过处理和生成自然语言，展示了深度学习的强大能力。然而，为了进一步提升这些模型的功能和适用性，将它们与外部API集成变得尤为重要。此举不仅提高了模型的实用性，还为研究人员和开发者提供了探索AI未来边界的新途径。<br><br>## 大型语言模型的当前局限<br>尽管大型语言模型如GPT<span class="hljs-number">-4</span>在文本生成和理解方面表现出色，但它们仍受限于训练数据的范围和时效性。模型无法直接访问或处理实时数据，也无法进行复杂的数据分析或访问互联网内容，这限制了其在某些应用场景下的有效性。<br><br>## 外部API集成的必要性<br>通过将这些模型与外部API集成，我们可以极大地拓宽它们的功能。例如，集成金融API可以使模型处理实时股市数据，而集成地理信息系统API则可以让模型访问和分析地理数据。这种集成不仅提高了模型的实用性，还为开发新应用提供了可能。<br><br>## 技术实现与挑战<br>实现这种集成需要克服若干技术挑战。首先，需要确保模型能够安全有效地与API进行通信。这涉及到数据传输、安全性和隐私保护等问题。其次，需要处理和适应API返回的数据格式，这可能要求模型具备一定的适应性和灵活性。最后，还需要考虑如何整合API返回的数据与模型生成的内容，确保信息的准确性和连贯性。<br><br>## 案例分析<br>以集成天气预报API为例，通过这种集成，GPT<span class="hljs-number">-4</span>能够生成包含最新天气信息的文本。在一个旅游推荐应用中，模型可以根据实时天气数据调整其推荐内容，从而提供更准确、个性化的建议。<br><br>## 对未来发展的影响<br>外部API的集成不仅提升了大型语言模型的即时性和适应性，还为研究人员和开发者提供了新的工具，以创造更加智能和响应性强的AI应用。这可能会促进人工智能在医疗、金融、环境监测等领域的应用，推动AI技术的进一步发展。<br><br>## 结论<br>大型语言模型与外部API的集成是推动AI技术发展的关键步骤。它不仅提高了模型的实用性和适用范围，还开辟了探索AI新边界的道路。随着这种集成技术的不断完善，我们可以期待在未来看到更加智能、灵活和强大的人工智能应用。<br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这两天看到了一个论文&lt;a href=&quot;https://arxiv.org/abs/2307.11760&quot;&gt;Large Language Models Understand and Can Be Enhanced by Emotional Stimuli&lt;/a&gt; 翻译过来叫做</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>ggml教程|mnist手写体识别量化推理</title>
    <link href="https://studyinglover.com/2023/11/12/ggml%E6%95%99%E7%A8%8B|mnist%E6%89%8B%E5%86%99%E4%BD%93%E8%AF%86%E5%88%AB%E9%87%8F%E5%8C%96%E6%8E%A8%E7%90%86/"/>
    <id>https://studyinglover.com/2023/11/12/ggml%E6%95%99%E7%A8%8B|mnist%E6%89%8B%E5%86%99%E4%BD%93%E8%AF%86%E5%88%AB%E9%87%8F%E5%8C%96%E6%8E%A8%E7%90%86/</id>
    <published>2023-11-12T18:49:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ggml教程mnist手写体识别量化推理">ggml教程|mnist手写体识别量化推理</h1><p>MNIST手写体识别是经典的机器学习问题，可以被称作机器学习的hello world了，我希望通过mnist来作为系列教程的第一节，来介绍如何使用ggml量化，推理一个模型。这个教程将会使用pytorch来训练一个简单的全连接神经网络，然后使用ggml量化，最后使用ggml推理这个模型。</p><p>代码开源在仓库<a href="https://github.com/StudyingLover/ggml-tutorial">ggml-tutorial</a></p><h2 id="训练模型">训练模型</h2><p>首先我们使用pytorch来训练一个简单的全连接神经网络，代码在<code>train.py</code> 文件中，训练好的模型会被保存到<code>model/mnist_model.pth</code> 文件中。代码是非常简单的torch代码</p><p>这里我们需要强调一下模型结构 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(SimpleNN, self).__init__()<br>        self.fc1 = nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">128</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">784</span>)<br>        x = torch.relu(self.fc1(x))<br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure> 模型由两个全连接层组成，第一个全连接层的输入是784维，输出是128维，第二个全连接层的输入是128维，输出是10维。我们需要知道这个结构，因为我们需要在量化模型时知道各个层的名字。</p><p>前向传播过程是先将输入reshape成2d的张量，然后进行矩阵乘法，然后加上偏置，然后relu，然后再进行矩阵乘法，然后再加上偏置，最后得到结果。</p><h2 id="量化">量化</h2><p>我们需要使用ggml对模型进行量化，代码在<code>convert-pth-to-ggml.py</code> 文件中,使用<code>python convert-pth-to-ggml.py model/mnist_model.pth</code>进行转换，量化后的模型会被保存到<code>model/mnist-ggml-model-f32.pth</code> 文件中。</p><p>这里需要对很多细节作出解释： 1. ggml量化的模型格式叫做gguf,文件开头有一个魔数标记了这个文件是gguf文件，接下来是模型的各种数据，具体细节可以查看<a href="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md">官方文档</a>。为了方便，作者提供了一个python库来读写gguf文件，使用<code>pip install gguf</code> 就可以安装。 2. 我们需要知道模型中各个层数据的名字，使用<code>model.keys()</code> 就可以知道了。知道各个层的名字之后我们就可以取出各个层的数据，并对需要的层进行量化，也就是下面这段代码，我对weights进行了量化，转换成了<code>float16</code> <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs stylus">fc1_weights = model<span class="hljs-selector-attr">[<span class="hljs-string">&quot;fc1.weight&quot;</span>]</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>()<br>fc1_weights = fc1_weights<span class="hljs-selector-class">.astype</span>(np.float16)<br>gguf_writer<span class="hljs-selector-class">.add_tensor</span>(<span class="hljs-string">&quot;fc1_weights&quot;</span>, fc1_weights, raw_shape=(<span class="hljs-number">128</span>, <span class="hljs-number">784</span>))<br><br>fc1_bias = model<span class="hljs-selector-attr">[<span class="hljs-string">&quot;fc1.bias&quot;</span>]</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>()<br>gguf_writer<span class="hljs-selector-class">.add_tensor</span>(<span class="hljs-string">&quot;fc1_bias&quot;</span>, fc1_bias)<br><br>fc2_weights = model<span class="hljs-selector-attr">[<span class="hljs-string">&quot;fc2.weight&quot;</span>]</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>()<br>fc2_weights = fc2_weights<span class="hljs-selector-class">.astype</span>(np.float16)<br>gguf_writer<span class="hljs-selector-class">.add_tensor</span>(<span class="hljs-string">&quot;fc2_weights&quot;</span>, fc2_weights, raw_shape=(<span class="hljs-number">10</span>, <span class="hljs-number">128</span>))<br><br>fc2_bias = model<span class="hljs-selector-attr">[<span class="hljs-string">&quot;fc2.bias&quot;</span>]</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>()<br>gguf_writer<span class="hljs-selector-class">.add_tensor</span>(<span class="hljs-string">&quot;fc2_bias&quot;</span>, fc2_bias)<br></code></pre></td></tr></table></figure></p><ol start="3" type="1"><li>保存模型按照代码特定顺序执行就可以了 <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs stylus">gguf_writer = gguf<span class="hljs-selector-class">.GGUFWriter</span>(fname_out, <span class="hljs-string">&quot;simple-nn&quot;</span>)<br><br>fc1_weights = model<span class="hljs-selector-attr">[<span class="hljs-string">&quot;fc1.weight&quot;</span>]</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>()<br>fc1_weights = fc1_weights<span class="hljs-selector-class">.astype</span>(np.float16)<br>gguf_writer<span class="hljs-selector-class">.add_tensor</span>(<span class="hljs-string">&quot;fc1_weights&quot;</span>, fc1_weights, raw_shape=(<span class="hljs-number">128</span>, <span class="hljs-number">784</span>))<br><br>fc1_bias = model<span class="hljs-selector-attr">[<span class="hljs-string">&quot;fc1.bias&quot;</span>]</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>()<br>gguf_writer<span class="hljs-selector-class">.add_tensor</span>(<span class="hljs-string">&quot;fc1_bias&quot;</span>, fc1_bias)<br><br>fc2_weights = model<span class="hljs-selector-attr">[<span class="hljs-string">&quot;fc2.weight&quot;</span>]</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>()<br>fc2_weights = fc2_weights<span class="hljs-selector-class">.astype</span>(np.float16)<br>gguf_writer<span class="hljs-selector-class">.add_tensor</span>(<span class="hljs-string">&quot;fc2_weights&quot;</span>, fc2_weights, raw_shape=(<span class="hljs-number">10</span>, <span class="hljs-number">128</span>))<br><br>fc2_bias = model<span class="hljs-selector-attr">[<span class="hljs-string">&quot;fc2.bias&quot;</span>]</span><span class="hljs-selector-class">.data</span><span class="hljs-selector-class">.numpy</span>()<br>gguf_writer<span class="hljs-selector-class">.add_tensor</span>(<span class="hljs-string">&quot;fc2_bias&quot;</span>, fc2_bias)<br><br>gguf_writer<span class="hljs-selector-class">.write_header_to_file</span>()<br>gguf_writer<span class="hljs-selector-class">.write_kv_data_to_file</span>()<br>gguf_writer<span class="hljs-selector-class">.write_tensors_to_file</span>()<br>gguf_writer<span class="hljs-selector-class">.close</span>()<br></code></pre></td></tr></table></figure></li></ol><p>我们可以看到，原本模型大小是399.18kb,现在的大小是199.31kb，确实是缩小了很多的。</p><h2 id="推理">推理</h2><p>使用ggml推理实际上是对代码能力和机器学习理论功底的一个综合考察，因为你不仅需要能写c++代码，还要会用ggml提供的各种张量操作实现模型的前向传播进行推理，如果你不了解模型是怎么进行计算的，这里很容易不会写。我们接下来详细来说怎么写代码。</p><p>首先按照我们torch定义的模型，我们定义一个结构体来存储模型权重 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">mnist_model</span> &#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ggml_tensor</span> * fc1_weight;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ggml_tensor</span> * fc1_bias;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ggml_tensor</span> * fc2_weight;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ggml_tensor</span> * fc2_bias;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">ggml_context</span> * ctx;<br>&#125;;<br></code></pre></td></tr></table></figure></p><p>接下来加载模型,传入两个参数，模型地址和模型结构体。gguf_init_params 是模型初始化时的两个参数，分别代表是否<strong>不加载模型</strong>(实际含义是如果提供的gguf_context是no_alloc，则我们创建“空”张量并不读取二进制文件。否则，我们还将二进制文件加载到创建的ggml_context中，并将ggml_tensor结构体的"data"成员指向二进制文件中的适当位置。)和模型的地址。gguf_init_from_file 函数会返回一个gguf_context，这个结构体包含了模型的所有信息，我们需要从中取出我们需要的张量，这里我们需要的张量是fc1_weight,fc1_bias,fc2_weight,fc2_bias(和量化模型时保持一致)。 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">mnist_model_load</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string &amp; fname, mnist_model &amp; model)</span> </span>&#123;<br>    <span class="hljs-keyword">struct</span> <span class="hljs-title class_">gguf_init_params</span> params = &#123;<br>        <span class="hljs-comment">/*.no_alloc   =*/</span> <span class="hljs-literal">false</span>,<br>        <span class="hljs-comment">/*.ctx        =*/</span> &amp;model.ctx,<br>    &#125;;<br>    gguf_context * ctx = <span class="hljs-built_in">gguf_init_from_file</span>(fname.<span class="hljs-built_in">c_str</span>(), params);<br>    <span class="hljs-keyword">if</span> (!ctx) &#123;<br>        <span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;%s: gguf_init_from_file() failed\n&quot;</span>, __func__);<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br>    model.fc1_weight = <span class="hljs-built_in">ggml_get_tensor</span>(model.ctx, <span class="hljs-string">&quot;fc1_weights&quot;</span>);<br>    model.fc1_bias = <span class="hljs-built_in">ggml_get_tensor</span>(model.ctx, <span class="hljs-string">&quot;fc1_bias&quot;</span>);<br>    model.fc2_weight = <span class="hljs-built_in">ggml_get_tensor</span>(model.ctx, <span class="hljs-string">&quot;fc2_weights&quot;</span>);<br>    model.fc2_bias = <span class="hljs-built_in">ggml_get_tensor</span>(model.ctx, <span class="hljs-string">&quot;fc2_bias&quot;</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>接下来我们写模型的前向传播,完整代码在<code>main-torch.cpp</code>。传入的参数是模型的地址，线程数，数据和是否导出计算图(这个我们先不讨论)。</p><p>首先初始化模型和数据 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">static</span> <span class="hljs-type">size_t</span> buf_size = <span class="hljs-number">100000</span> * <span class="hljs-built_in">sizeof</span>(<span class="hljs-type">float</span>) * <span class="hljs-number">4</span>;<br><span class="hljs-type">static</span> <span class="hljs-type">void</span> * buf = <span class="hljs-built_in">malloc</span>(buf_size);<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ggml_init_params</span> params = &#123;<br>    <span class="hljs-comment">/*.mem_size   =*/</span> buf_size,<br>    <span class="hljs-comment">/*.mem_buffer =*/</span> buf,<br>    <span class="hljs-comment">/*.no_alloc   =*/</span> <span class="hljs-literal">false</span>,<br>&#125;;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ggml_context</span> * ctx0 = <span class="hljs-built_in">ggml_init</span>(params);<br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ggml_cgraph</span> * gf = <span class="hljs-built_in">ggml_new_graph</span>(ctx0);<br></code></pre></td></tr></table></figure></p><p>我们先复习一下全连接层的计算。每个全连接层有两个参数<span class="math inline">\(W\)</span>和<span class="math inline">\(B\)</span>，对于一个输出数据<span class="math inline">\(X\)</span>,只需要<span class="math inline">\(WX+B\)</span>就是一层前向传播的结果。</p><p>那么我们先初始化一个4d的张量作为输入(和torch很像)，然后将数据复制到这个张量中，然后将这个张量reshape成2d的张量，然后进行矩阵乘法，然后加上偏置，然后relu，然后再进行矩阵乘法，然后再加上偏置，最后得到结果。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ggml_tensor</span> * input = <span class="hljs-built_in">ggml_new_tensor_4d</span>(ctx0, GGML_TYPE_F32, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>);<br>    <span class="hljs-built_in">memcpy</span>(input-&gt;data, digit.<span class="hljs-built_in">data</span>(), <span class="hljs-built_in">ggml_nbytes</span>(input));<br>    <span class="hljs-built_in">ggml_set_name</span>(input, <span class="hljs-string">&quot;input&quot;</span>);<br>    ggml_tensor * cur = <span class="hljs-built_in">ggml_reshape_2d</span>(ctx0, input, <span class="hljs-number">784</span>, <span class="hljs-number">1</span>);<br>    <span class="hljs-comment">// std::cout&lt;&lt;model.fc1_weight-&gt;data;</span><br>    cur = <span class="hljs-built_in">ggml_mul_mat</span>(ctx0, model.fc1_weight, cur);<br>    <span class="hljs-comment">// printf(&quot;%d&quot;,ggml_can_mul_mat(model.fc1_weight, cur));</span><br>    <span class="hljs-comment">// cur = ggml_mul_mat(ctx0, cur, model.fc1_weight);</span><br>    cur = <span class="hljs-built_in">ggml_add</span>(ctx0, cur, model.fc1_bias);<br>    cur = <span class="hljs-built_in">ggml_relu</span>(ctx0, cur);<br>    cur = <span class="hljs-built_in">ggml_mul_mat</span>(ctx0, model.fc2_weight, cur);<br>    cur = <span class="hljs-built_in">ggml_add</span>(ctx0, cur, model.fc2_bias);<br></code></pre></td></tr></table></figure><p>接下来通过计算图计算出结果，ggml已经提供了api <figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-built_in">ggml_build_forward_expand</span>(gf, result);<br><span class="hljs-built_in">ggml_graph_compute_with_ctx</span>(ctx0, gf, n_threads);<br></code></pre></td></tr></table></figure></p><p>我们需要将结果reshape成1d的张量，然后取出最大值，这个最大值就是我们的预测结果。 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">const</span> <span class="hljs-type">int</span> prediction = std::<span class="hljs-built_in">max_element</span>(probs_data, probs_data + <span class="hljs-number">10</span>) - probs_data;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> * probs_data = <span class="hljs-built_in">ggml_get_data_f32</span>(result);<br></code></pre></td></tr></table></figure></p><p>我们可以将计算图进行存储,这部分代码我们先不讨论 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">//ggml_graph_print(&amp;gf);</span><br><span class="hljs-built_in">ggml_graph_dump_dot</span>(gf, <span class="hljs-literal">NULL</span>, <span class="hljs-string">&quot;mnist-cnn.dot&quot;</span>);<br><br><span class="hljs-keyword">if</span> (fname_cgraph) &#123;<br>    <span class="hljs-comment">// export the compute graph for later use</span><br>    <span class="hljs-comment">// see the &quot;mnist-cpu&quot; example</span><br>    <span class="hljs-built_in">ggml_graph_export</span>(gf, fname_cgraph);<br><br>    <span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;%s: exported compute graph to &#x27;%s&#x27;\n&quot;</span>, __func__, fname_cgraph);<br>&#125;<br></code></pre></td></tr></table></figure></p><p>最后记得释放内存 <figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-built_in">ggml_free</span>(ctx0);<br></code></pre></td></tr></table></figure></p><h2 id="图片读取">图片读取</h2><p>我们这里要用到<code>stb_image.h</code>这个头文件，我们通过下面的代码导入 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">define</span> STB_IMAGE_IMPLEMENTATION</span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;stb_image.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> STB_IMAGE_WRITE_IMPLEMENTATION</span><br></code></pre></td></tr></table></figure></p><p>我们定义一个结构体来存储图片 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">image_u8</span> &#123;<br>    <span class="hljs-type">int</span> nx;<br>    <span class="hljs-type">int</span> ny;<br><br>    std::vector&lt;<span class="hljs-type">uint8_t</span>&gt; data;<br>&#125;;<br></code></pre></td></tr></table></figure></p><p>接下来我们写一个函数来读取图片，两个参数分别是图片地址和图片结构体 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">image_load_from_file</span><span class="hljs-params">(<span class="hljs-type">const</span> std::string &amp; fname, image_u8 &amp; img)</span> </span>&#123;<br>    <span class="hljs-type">int</span> nx, ny, nc;<br>    <span class="hljs-keyword">auto</span> data = <span class="hljs-built_in">stbi_load</span>(fname.<span class="hljs-built_in">c_str</span>(), &amp;nx, &amp;ny, &amp;nc, <span class="hljs-number">3</span>);<br>    <span class="hljs-keyword">if</span> (!data) &#123;<br>        <span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;%s: failed to load &#x27;%s&#x27;\n&quot;</span>, __func__, fname.<span class="hljs-built_in">c_str</span>());<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br><br>    img.nx = nx;<br>    img.ny = ny;<br>    img.data.<span class="hljs-built_in">resize</span>(nx * ny * <span class="hljs-number">3</span>);<br>    <span class="hljs-built_in">memcpy</span>(img.data.<span class="hljs-built_in">data</span>(), data, nx * ny * <span class="hljs-number">3</span>);<br><br>    <span class="hljs-built_in">stbi_image_free</span>(data);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>&#125;<br></code></pre></td></tr></table></figure></p><h2 id="运行">运行</h2><p>首先初始化ggml <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">ggml_time_init</span>();<br></code></pre></td></tr></table></figure></p><p>接下来加载模型 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c++">mnist_model model;<br><span class="hljs-comment">// load the model</span><br>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-type">int64_t</span> t_start_us = <span class="hljs-built_in">ggml_time_us</span>();<br>    <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">mnist_model_load</span>(argv[<span class="hljs-number">1</span>], model)) &#123;<br>        <span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;%s: failed to load model from &#x27;%s&#x27;\n&quot;</span>, __func__, argv[<span class="hljs-number">1</span>]);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>    &#125;<br>    <br><br>    <span class="hljs-type">const</span> <span class="hljs-type">int64_t</span> t_load_us = <span class="hljs-built_in">ggml_time_us</span>() - t_start_us;<br><br>    <span class="hljs-built_in">fprintf</span>(stdout, <span class="hljs-string">&quot;%s: loaded model in %8.2f ms\n&quot;</span>, __func__, t_load_us / <span class="hljs-number">1000.0f</span>);<br>&#125;<br></code></pre></td></tr></table></figure></p><p>接下来读取图片并存储为特定格式 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-comment">// read a img from a file</span><br><br>image_u8 img0;<br>std::string img_path = argv[<span class="hljs-number">2</span>];<br><span class="hljs-keyword">if</span> (!<span class="hljs-built_in">image_load_from_file</span>(img_path, img0)) &#123;<br>    <span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;%s: failed to load image from &#x27;%s&#x27;\n&quot;</span>, __func__, img_path.<span class="hljs-built_in">c_str</span>());<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>&#125;<br><span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;%s: loaded image &#x27;%s&#x27; (%d x %d)\n&quot;</span>, __func__, img_path.<span class="hljs-built_in">c_str</span>(), img0.nx, img0.ny);<br><br><br><span class="hljs-type">uint8_t</span> buf[<span class="hljs-number">784</span>];<br><br><span class="hljs-comment">// convert the image to a digit</span><br><br><span class="hljs-type">const</span> <span class="hljs-type">int64_t</span> t_start_us = <span class="hljs-built_in">ggml_time_us</span>();<br><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">784</span>; i++) &#123;<br>    buf[i] = <span class="hljs-number">255</span> - img0.data[i * <span class="hljs-number">3</span>];<br>&#125;<br><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">784</span>; i++) &#123;<br>    digit.<span class="hljs-built_in">push_back</span>(buf[i] / <span class="hljs-number">255.0f</span>);<br>&#125;<br><br><span class="hljs-type">const</span> <span class="hljs-type">int64_t</span> t_convert_us = <span class="hljs-built_in">ggml_time_us</span>() - t_start_us;<br><br><span class="hljs-built_in">fprintf</span>(stdout, <span class="hljs-string">&quot;%s: converted image to digit in %8.2f ms\n&quot;</span>, __func__, t_convert_us / <span class="hljs-number">1000.0f</span>);<br></code></pre></td></tr></table></figure></p><p>接下来进行推理 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-type">const</span> <span class="hljs-type">int</span> prediction = <span class="hljs-built_in">mnist_eval</span>(model, <span class="hljs-number">1</span>, digit, <span class="hljs-literal">nullptr</span>);<br><span class="hljs-built_in">fprintf</span>(stdout, <span class="hljs-string">&quot;%s: predicted digit is %d\n&quot;</span>, __func__, prediction);<br></code></pre></td></tr></table></figure> 最后记得释放内存 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-built_in">ggml_free</span>(model.ctx);<br></code></pre></td></tr></table></figure> ## 使用 在<code>examples/CMakeLists.txt</code>最后一行加入<code>add_subdirectory(mnist-torch)</code></p><p>然后运行<code>mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make mnist-torch -j8</code></p><p>最后运行<code>./mnist-torch /path/to/mnist-ggml-model-f32.gguf /path/to/example.png</code></p><p>记得把<code>/path/to/mnist-ggml-model-f32.gguf</code>和<code>/path/to/example.png</code>换成你的路径</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ggml教程mnist手写体识别量化推理&quot;&gt;ggml教程|mnist手写体识别量化推理&lt;/h1&gt;
&lt;p&gt;MNIST手写体识别是经典的机器学习问题，可以被称作机器学习的hello world了，我希望通过mnist来作为系列教程的第一节，来介绍如何使用ggml量化，</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>xgboost2.0最佳实践</title>
    <link href="https://studyinglover.com/2023/10/19/xgboost2.0%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>https://studyinglover.com/2023/10/19/xgboost2.0%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2023-10-19T08:30:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="xgboost2.0最佳实践">xgboost2.0最佳实践</h1><p>首先更新xgboost到2.0.0 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install xgboost -U <br></code></pre></td></tr></table></figure></p><p>在最新版本的训练中，参数可以使用字典传递。同时数据和样本需要先合并成一个<code>xgb.DMatrix</code> 对象 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 设置参数</span><br>params = &#123;<br>    <span class="hljs-string">&quot;device&quot;</span>: <span class="hljs-string">&quot;cuda&quot;</span>,<br>&#125;<br><br><span class="hljs-comment"># 创建DMatrix对象</span><br>Xy = xgb.DMatrix(X_train, y_train)<br><br><span class="hljs-comment"># 训练模型</span><br>model = xgb.train(params, Xy)<br></code></pre></td></tr></table></figure></p><p>进行分类任务是，需要传递类别数，而不是像之前版本那样自动检测类别 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 设置参数</span><br>params = &#123;<br>    <span class="hljs-string">&quot;device&quot;</span>: <span class="hljs-string">&quot;cuda&quot;</span>,<br>    <span class="hljs-string">&quot;num_class&quot;</span>: <span class="hljs-number">5</span><br>&#125;<br></code></pre></td></tr></table></figure></p><p>根据xgboost路线图<a href="https://github.com/dmlc/xgboost/issues/7547">Roadmap Phasing out the support for old binary format.</a>，在2.2版本将删除对保存旧二进制格式的支持，删除对旧 JSON 模型的支持。在2.3版本将删除对加载旧二进制格式的支持。最新保存模型的方式是 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">xgb.save(bst, <span class="hljs-string">&#x27;model_file_name.json&#x27;</span>)<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;xgboost2.0最佳实践&quot;&gt;xgboost2.0最佳实践&lt;/h1&gt;
&lt;p&gt;首先更新xgboost到2.0.0 &lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span cla</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
    <category term="机器学习" scheme="https://studyinglover.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>xgboost使用GPU最佳实践</title>
    <link href="https://studyinglover.com/2023/10/18/xgboost%E4%BD%BF%E7%94%A8GPU%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>https://studyinglover.com/2023/10/18/xgboost%E4%BD%BF%E7%94%A8GPU%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2023-10-18T18:50:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="xgboost使用gpu最佳实践">xgboost使用GPU最佳实践</h1><p>首先更新xgboost到2.0.0 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install xgboost -U <br></code></pre></td></tr></table></figure></p><p>这里给出一个使用GPU的例子，使用的是nvidia显卡 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> xgboost<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats<br><br><span class="hljs-comment"># 生成示例数据</span><br>np.random.seed(<span class="hljs-number">114514</span>)<br>X = np.random.randn(<span class="hljs-number">100</span>, <span class="hljs-number">3</span>)  <span class="hljs-comment"># 生成100个样本，每个样本有3个特征</span><br>y = stats.bernoulli.rvs(<span class="hljs-number">0.5</span>, size=<span class="hljs-number">100</span>)  <span class="hljs-comment"># 生成二分类标签，概率为0.5</span><br><br><span class="hljs-comment"># 设置参数</span><br>params = &#123;<br>    <span class="hljs-string">&quot;device&quot;</span>: <span class="hljs-string">&quot;cuda&quot;</span><br>&#125;<br><br><span class="hljs-comment"># 创建DMatrix对象</span><br>Xy = xgboost.DMatrix(X, y)<br><br><span class="hljs-comment"># 训练模型</span><br>model = xgboost.train(params, Xy)<br><br><span class="hljs-comment"># 测试模型</span><br>test_array = np.random.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>dtest = xgboost.DMatrix(test_array)<br>pred = model.predict(dtest)<br><span class="hljs-built_in">print</span>(pred)<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;xgboost使用gpu最佳实践&quot;&gt;xgboost使用GPU最佳实践&lt;/h1&gt;
&lt;p&gt;首先更新xgboost到2.0.0 &lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
    <category term="机器学习" scheme="https://studyinglover.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>马踏棋盘</title>
    <link href="https://studyinglover.com/2023/10/12/%E9%A9%AC%E8%B8%8F%E6%A3%8B%E7%9B%98/"/>
    <id>https://studyinglover.com/2023/10/12/%E9%A9%AC%E8%B8%8F%E6%A3%8B%E7%9B%98/</id>
    <published>2023-10-12T09:39:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h2 id="c代码">c代码</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdbool.h&gt;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> SIZE 8</span><br><br><span class="hljs-type">int</span> move_x[<span class="hljs-number">8</span>] = &#123;<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">-2</span>, <span class="hljs-number">-2</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>&#125;;<br><span class="hljs-type">int</span> move_y[<span class="hljs-number">8</span>] = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">-1</span>, <span class="hljs-number">-2</span>, <span class="hljs-number">-2</span>, <span class="hljs-number">-1</span>&#125;;<br><br><span class="hljs-type">bool</span> <span class="hljs-title function_">is_valid_move</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y, <span class="hljs-type">int</span> board[SIZE][SIZE])</span> &#123;<br>    <span class="hljs-keyword">if</span> (x &gt;= <span class="hljs-number">0</span> &amp;&amp; x &lt; SIZE &amp;&amp; y &gt;= <span class="hljs-number">0</span> &amp;&amp; y &lt; SIZE &amp;&amp; board[x][y] == <span class="hljs-number">-1</span>) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">print_board</span><span class="hljs-params">(<span class="hljs-type">int</span> board[SIZE][SIZE])</span> &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; SIZE; i++) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; SIZE; j++) &#123;<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%2d &quot;</span>, board[i][j]);<br>        &#125;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\n&quot;</span>);<br>    &#125;<br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">solve_knight_tour</span><span class="hljs-params">(<span class="hljs-type">int</span> start_x, <span class="hljs-type">int</span> start_y)</span> &#123;<br>    <span class="hljs-type">int</span> board[SIZE][SIZE];<br>    <span class="hljs-type">int</span> move_count = <span class="hljs-number">1</span>;<br><br>    <span class="hljs-comment">// 初始化棋盘</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; SIZE; i++) &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; SIZE; j++) &#123;<br>            board[i][j] = <span class="hljs-number">-1</span>;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-type">int</span> x = start_x;<br>    <span class="hljs-type">int</span> y = start_y;<br>    board[x][y] = move_count;<br><br>    <span class="hljs-keyword">while</span> (move_count &lt; SIZE * SIZE) &#123;<br>        <span class="hljs-type">int</span> min_deg = SIZE + <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> min_index = <span class="hljs-number">-1</span>;<br>        <span class="hljs-type">int</span> next_x, next_y;<br><br>        <span class="hljs-comment">// 尝试所有可能的移动</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">8</span>; i++) &#123;<br>            next_x = x + move_x[i];<br>            next_y = y + move_y[i];<br><br>            <span class="hljs-keyword">if</span> (is_valid_move(next_x, next_y, board)) &#123;<br>                <span class="hljs-type">int</span> deg = <span class="hljs-number">0</span>;<br><br>                <span class="hljs-comment">// 计算下一个位置的度数</span><br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">8</span>; j++) &#123;<br>                    <span class="hljs-type">int</span> new_x = next_x + move_x[j];<br>                    <span class="hljs-type">int</span> new_y = next_y + move_y[j];<br>                    <br>                    <span class="hljs-keyword">if</span> (is_valid_move(new_x, new_y, board)) &#123;<br>                        deg++;<br>                    &#125;<br>                &#125;<br><br>                <span class="hljs-comment">// 更新最小度数和对应的索引</span><br>                <span class="hljs-keyword">if</span> (deg &lt; min_deg) &#123;<br>                    min_deg = deg;<br>                    min_index = i;<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// 没有找到合适的下一步移动位置</span><br>        <span class="hljs-keyword">if</span> (min_index == <span class="hljs-number">-1</span>) &#123;<br>            <span class="hljs-keyword">break</span>;<br>        &#125;<br><br>        <span class="hljs-comment">// 移动到下一个位置</span><br>        x += move_x[min_index];<br>        y += move_y[min_index];<br>        board[x][y] = ++move_count;<br>    &#125;<br><br>    <span class="hljs-comment">// 输出结果</span><br>    print_board(board);<br>&#125;<br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> *argv[])</span> &#123;<br>    <span class="hljs-type">int</span> start_x, start_y;<br><br>    <span class="hljs-comment">// printf(&quot;请输入马的初始位置（x, y）：&quot;);</span><br>    <span class="hljs-comment">// scanf(&quot;%d %d&quot;, &amp;start_x, &amp;start_y);</span><br>    <span class="hljs-comment">// start_x = 2;</span><br>    <span class="hljs-comment">// start_y = 2;</span><br>    start_x = *argv[<span class="hljs-number">1</span>] - <span class="hljs-string">&#x27;0&#x27;</span>;<br>    start_y = *argv[<span class="hljs-number">2</span>] - <span class="hljs-string">&#x27;0&#x27;</span>;<br>    <span class="hljs-comment">// printf(&quot;%d %d&quot;,start_x,start_y);</span><br><br>    solve_knight_tour(start_x, start_y);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="思路">思路</h3><p>这段代码使用一个while循环来控制马的移动，直到访问了棋盘上的所有格子（move_count达到SIZE * SIZE）或者无法找到合适的下一步移动位置。</p><p>在每次循环迭代中，首先初始化min_deg为SIZE + 1，min_index为-1，用来记录最小度数和对应的索引。next_x和next_y是下一个可能的移动位置的坐标。</p><p>接下来，通过一个for循环尝试所有可能的移动方式。对于每一种移动方式，计算出下一个位置的坐标next_x和next_y。然后使用is_valid_move函数判断下一个位置是否是一个有效的移动位置。如果是，进入内部的计算度数的循环。</p><p>在内部的循环中，通过move_x和move_y数组计算出下一个位置的所有可能移动方式。然后使用is_valid_move函数判断每个可能的移动位置是否有效。如果是，将度数deg加一。</p><p>完成内部的循环后，比较当前位置的度数deg和最小度数min_deg的大小。如果deg小于min_deg，则更新min_deg为deg，同时更新min_index为当前移动方式的索引i。</p><p>完成所有移动方式的尝试后，判断min_index是否仍然为-1。如果是，表示无法找到合适的下一步移动位置，即无法继续遍历所有格子。在这种情况下，跳出while循环。</p><p>如果找到了合适的下一步移动位置，将马移动到该位置。更新当前位置的坐标x和y为下一个位置的坐标next_x和next_y，然后将move_count加一，并将其赋值给当前位置的board数组。这表示马已经访问了该位置。</p><p>当循环结束后，solve_knight_tour函数就完成了马踏棋盘问题的求解，棋盘上每个格子的访问顺序已经被记录在board数组中。</p><p>请注意，该算法并不能保证一定能找到马踏棋盘问题的解，因为在某些起始位置和棋盘大小的情况下，可能无法找到完整的遍历路径。</p><h3 id="度数在这里代表什么">度数在这里代表什么?</h3><p>在这里，"度数"指的是马在当前位置的下一个可能移动位置的可访问格子数量。也可以将其理解为下一个位置的邻居节点数。</p><p>在代码中，通过计算每个可能的移动位置的度数，可以评估每个位置的可达性。度数越小表示该位置的可访问格子数量越少，即相对来说更"紧凑"。在马踏棋盘问题中，选择度数最小的位置作为下一步移动的目标，有助于保持马的移动范围广阔，增加找到解的可能性。</p><p>通过选择度数最小的位置作为下一步移动目标，可以尽量避免陷入死胡同或者无法继续遍历的局面。这种策略在一定程度上增加了找到马踏棋盘问题解的概率。</p><h3 id="马踏棋盘问题中度数最小的位置是否一定是下一步移动的最佳选择">马踏棋盘问题中，度数最小的位置是否一定是下一步移动的最佳选择？</h3><p>在马踏棋盘问题中，度数最小的位置不一定是下一步移动的最佳选择。尽管选择度数最小的位置有助于保持马的移动范围广阔，但并不能保证一定能找到问题的解。</p><p>马踏棋盘问题是一个非常复杂的组合问题，具有高度的分支因子和状态空间。在某些情况下，选择度数最小的位置可能导致陷入局部最优解，从而无法找到全局最优解，或者根本找不到解。</p><p>在某些特定的起始位置和棋盘大小下，可能存在一些特殊的路径或遍历顺序，使得度数最小的位置并不是最佳的选择。因此，仅凭度数最小来确定下一步移动的位置并不能保证找到最佳解。</p><p>为了提高找到最佳解的概率，通常需要采用更加复杂的算法和启发式策略，例如回溯算法、深度优先搜索、广度优先搜索、剪枝等。这些算法可以考虑更多的因素，如节点的可达性、棋盘上的局部结构、路径的延伸性等，以更有效地搜索解空间并找到更优的解。</p><p>因此，在解决马踏棋盘问题时，度数最小的位置可以作为一种启发式指导，但不能保证一定是下一步移动的最佳选择，需要结合其他算法和策略来综合评估和确定下一步的移动位置。</p><h2 id="python代码">python代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>lines = sys.stdin.readlines()<br><br><span class="hljs-comment"># 删除换行符并转换为整数</span><br>lines = np.array([<span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, line.strip().split())) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines])<br><br><span class="hljs-comment"># lines是一个矩阵，每个点的值代表该点的访问顺序</span><br><span class="hljs-comment"># 例如，lines[0][0] = 1，代表第一个访问的点是(0, 0)</span><br><span class="hljs-comment"># lines[0][1] = 34，代表第三十四个访问的点是(0, 1)</span><br><span class="hljs-comment"># lines[1][0] = 4，代表第四个访问的点是(1, 0)</span><br><br>order_x = []<br>order_y = []<br><br>count = <span class="hljs-number">1</span><br><span class="hljs-keyword">while</span> count &lt;= <span class="hljs-built_in">len</span>(lines)**<span class="hljs-number">2</span>:<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(lines)):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(lines)):<br>            <span class="hljs-keyword">if</span> lines[i][j] == count:<br>                order_x.append(i)<br>                order_y.append(j)<br>                count += <span class="hljs-number">1</span><br><br><br><span class="hljs-comment"># 绘制棋盘</span><br>plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>))<br><br><span class="hljs-comment"># 绘制棋盘的格子</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(lines)+<span class="hljs-number">1</span>):<br>    plt.plot([i, i], [<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(lines)], color=<span class="hljs-string">&#x27;black&#x27;</span>)<br>    plt.plot([<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(lines)], [i, i], color=<span class="hljs-string">&#x27;black&#x27;</span>)<br><br>count = <span class="hljs-number">1</span><br><span class="hljs-comment"># 绘制马的行走路线</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(order_x)-<span class="hljs-number">1</span>):<br>    plt.plot([order_x[i]+<span class="hljs-number">0.5</span>, order_x[i+<span class="hljs-number">1</span>]+<span class="hljs-number">0.5</span>], [order_y[i]+<span class="hljs-number">0.5</span>, order_y[i+<span class="hljs-number">1</span>]+<span class="hljs-number">0.5</span>], color=<span class="hljs-string">&#x27;red&#x27;</span>, )<br>    plt.scatter(order_x[i]+<span class="hljs-number">0.5</span>, order_y[i]+<span class="hljs-number">0.5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br>    <span class="hljs-comment"># 加上序号</span><br>    plt.text(order_x[i]+<span class="hljs-number">0.5</span>, order_y[i]+<span class="hljs-number">0.5</span>, <span class="hljs-built_in">str</span>(count), fontsize=<span class="hljs-number">12</span>)<br>    count += <span class="hljs-number">1</span><br>    plt.pause(<span class="hljs-number">0.01</span>)<br>    <br><span class="hljs-comment"># 绘制最后一个点</span><br>plt.scatter(order_x[-<span class="hljs-number">1</span>]+<span class="hljs-number">0.5</span>, order_y[-<span class="hljs-number">1</span>]+<span class="hljs-number">0.5</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br>plt.text(order_x[-<span class="hljs-number">1</span>]+<span class="hljs-number">0.6</span>, order_y[-<span class="hljs-number">1</span>]+<span class="hljs-number">0.6</span>, <span class="hljs-built_in">str</span>(count), fontsize=<span class="hljs-number">12</span>)<br>plt.show()<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;c代码&quot;&gt;c代码&lt;/h2&gt;
&lt;figure class=&quot;highlight c&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/sp</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
  </entry>
  
  <entry>
    <title>cloudlflare推理llama2</title>
    <link href="https://studyinglover.com/2023/10/11/cloudlflare%E6%8E%A8%E7%90%86llama2/"/>
    <id>https://studyinglover.com/2023/10/11/cloudlflare%E6%8E%A8%E7%90%86llama2/</id>
    <published>2023-10-11T15:32:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cloudlflare推理llama2">cloudlflare推理llama2</h1><p>最近，cloudlfare悄悄上线了一项新功能，全球网络上的gpu加速推理，显然的，我们可以用它推理llama2,cloudflare也提供了一个库进行推理。</p><p>新建一个cloudflare,然后，代码改成下面的，就可以进行推理了 <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-keyword">import</span> &#123; <span class="hljs-title class_">Ai</span> &#125; <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;./vendor/@cloudflare/ai.js&#x27;</span>;<br><br><span class="hljs-keyword">export</span> <span class="hljs-keyword">default</span> &#123;<br>  <span class="hljs-keyword">async</span> <span class="hljs-title function_">fetch</span>(<span class="hljs-params">request, env</span>) &#123;<br>    <span class="hljs-keyword">const</span> tasks = [];<br>    <span class="hljs-keyword">const</span> ai = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Ai</span>(env.<span class="hljs-property">AI</span>);<br><br>    <span class="hljs-comment">// Get the request body</span><br>    <span class="hljs-keyword">const</span> requestBody = <span class="hljs-keyword">await</span> request.<span class="hljs-title function_">json</span>();<br><br>    <span class="hljs-comment">// messages - chat style input</span><br>    <span class="hljs-keyword">let</span> chat = &#123;<br>      <span class="hljs-attr">messages</span>: [<br>        &#123; <span class="hljs-attr">role</span>: <span class="hljs-string">&#x27;system&#x27;</span>, <span class="hljs-attr">content</span>: <span class="hljs-string">&#x27;You are a helpful, kind, honest, friendly, good at writing and never fails to answer my requests immediately and with details and precision.&#x27;</span>&#125;,<br>        &#123; <span class="hljs-attr">role</span>: <span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-attr">content</span>: requestBody.<span class="hljs-property">prompt</span> &#125;<br>      ]<br>    &#125;;<br>    <span class="hljs-keyword">let</span> response = <span class="hljs-keyword">await</span> ai.<span class="hljs-title function_">run</span>(<span class="hljs-string">&#x27;@cf/meta/llama-2-7b-chat-int8&#x27;</span>, chat);<br>    tasks.<span class="hljs-title function_">push</span>(&#123; <span class="hljs-attr">inputs</span>: chat, response &#125;);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-title class_">Response</span>.<span class="hljs-title function_">json</span>(tasks);<br>  &#125;<br>&#125;;<br></code></pre></td></tr></table></figure></p><p>我们可以测试一下,在命令行运行下面的命令，将<code>https://example.workers.dev/</code> 换成你的网址。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -X POST https://example.workers.dev/ -d <span class="hljs-string">&#x27;&#123;&quot;prompt&quot;:&quot;Write a poem that talks about the connectivity cloud&quot;&#125;&#x27;</span> <br></code></pre></td></tr></table></figure></p><p>看到类似下面的返回值代表成功 <figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs swift">[&#123;<span class="hljs-string">&quot;inputs&quot;</span>:&#123;<span class="hljs-string">&quot;messages&quot;</span>:[&#123;<span class="hljs-string">&quot;role&quot;</span>:<span class="hljs-string">&quot;system&quot;</span>,<span class="hljs-string">&quot;content&quot;</span>:<span class="hljs-string">&quot;You are a helpful, kind, honest, friendly, good at writing and never fails to answer my requests immediately and with details and precision.&quot;</span>&#125;,&#123;<span class="hljs-string">&quot;role&quot;</span>:<span class="hljs-string">&quot;user&quot;</span>,<span class="hljs-string">&quot;content&quot;</span>:<span class="hljs-string">&quot;Write a poem that talks about the connectivity cloud&quot;</span>&#125;]&#125;,<span class="hljs-string">&quot;response&quot;</span>:&#123;<span class="hljs-string">&quot;response&quot;</span>:<span class="hljs-string">&quot;In the realm of the digital sky,<span class="hljs-subst">\n</span>Where information flows, and data fly,<span class="hljs-subst">\n</span>There&#x27;s a place that brings us all together,<span class="hljs-subst">\n</span>A connectivity cloud, a true forever.<span class="hljs-subst">\n</span><span class="hljs-subst">\n</span>It&#x27;s a space that&#x27;s vast and wide,<span class="hljs-subst">\n</span>Where thoughts and ideas collide,<span class="hljs-subst">\n</span>A hub of communication and exchange,<span class="hljs-subst">\n</span>Where the world&#x27;s voices all combine and blend.<span class="hljs-subst">\n</span><span class="hljs-subst">\n</span>In this cloud of connectivity,<span class="hljs-subst">\n</span>We find our voices, our identity,<span class="hljs-subst">\n</span>A platform for sharing and growth,<span class="hljs-subst">\n</span>Where our stories are told and our dreams take flight.<span class="hljs-subst">\n</span><span class="hljs-subst">\n</span>With just a click or tap of a key,<span class="hljs-subst">\n</span>We can connect with anyone, anywhere,<span class="hljs-subst">\n</span>Sharing laughter, love, and tears,<span class="hljs-subst">\n</span>In this digital embrace, we all share.<span class="hljs-subst">\n</span><span class="hljs-subst">\n</span>So let us cherish this cloud of connectivity,<span class="hljs-subst">\n</span>This gift that brings us all sovereignty,<span class="hljs-subst">\n</span>For in its depths, we find our tribe,<span class="hljs-subst">\n</span>And our voices, heard, can never be denied.<span class="hljs-subst">\n</span><span class="hljs-subst">\n</span>In this cloud of connectivity,<span class="hljs-subst">\n</span>We are all connected, you see,<span class="hljs-subst">\n</span>A global community, united and free,<span class="hljs-subst">\n</span>In this digital age, where we all can be&quot;</span>&#125;&#125;]<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;cloudlflare推理llama2&quot;&gt;cloudlflare推理llama2&lt;/h1&gt;
&lt;p&gt;最近，cloudlfare悄悄上线了一项新功能，全球网络上的gpu加速推理，显然的，我们可以用它推理llama2,cloudflare也提供了一个库进行推理。&lt;/p&gt;</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
  </entry>
  
  <entry>
    <title>docker搭建elasticsearch并使用python连接</title>
    <link href="https://studyinglover.com/2023/10/09/docker%E6%90%AD%E5%BB%BAelasticsearch%E5%B9%B6%E4%BD%BF%E7%94%A8python%E8%BF%9E%E6%8E%A5/"/>
    <id>https://studyinglover.com/2023/10/09/docker%E6%90%AD%E5%BB%BAelasticsearch%E5%B9%B6%E4%BD%BF%E7%94%A8python%E8%BF%9E%E6%8E%A5/</id>
    <published>2023-10-09T21:48:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="docker搭建elasticsearch并使用python连接">docker搭建elasticsearch并使用python连接</h1><h2 id="搭建">搭建</h2><p>创建一个docker网络 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker network create elastic<br></code></pre></td></tr></table></figure></p><p>然后拉elasticsearch 的docker 容器 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull docker.elastic.co/elasticsearch/elasticsearch:8.10.2<br></code></pre></td></tr></table></figure></p><p>运行容器 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker run --name es01 --net elastic -p 9200:9200 -it -m 1GB docker.elastic.co/elasticsearch/elasticsearch:8.10.2<br></code></pre></td></tr></table></figure></p><p>如果遇到报错<code>Elasticsearch exited unexpectedly, with exit code 78</code> ，在终端运行<code>sudo sysctl -w vm.max_map_count=262144</code>然后删掉刚才的镜像，重新运行容器。(这个设置重启后会失效，可以在<code>/etc/sysctl.conf</code>以设置使其永久有效。)</p><p>成功运行终端会弹出很多信息，然后最后会给出密码等，如下</p><p><img src="https://cdn.studyinglover.com/pic/2023/10/415a20e102e85b136bc5831f789a10af.png" /></p><p>记得保存密码，可以将密码加到环境变量里<code>export ELASTIC_PASSWORD="your_password"</code>，他只会弹出一次。如果忘了也可以重置密码 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> -it es01 /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic<br>docker <span class="hljs-built_in">exec</span> -it es01 /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana<br></code></pre></td></tr></table></figure></p><h2 id="验证是否正常运行">验证是否正常运行</h2><p>把证书从容器中复制一份 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">cp</span> es01:/usr/share/elasticsearch/config/certs/http_ca.crt .<br></code></pre></td></tr></table></figure></p><p>然后运行命令查看restful api是否正常运行 <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus">curl <span class="hljs-attr">--cacert</span> http_ca<span class="hljs-selector-class">.crt</span> -u elastic:<span class="hljs-variable">$ELASTIC_PASSWORD</span> https:<span class="hljs-comment">//localhost:9200</span><br></code></pre></td></tr></table></figure> 如果看到类似下图的信息就成功了 <img src="https://cdn.studyinglover.com/pic/2023/10/fa51ee2db2826abe7649dc0b88865beb.png" alt="image.png" /></p><h2 id="python连接">python连接</h2><p>运行下面的代码,password改成你自己的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> elasticsearch <span class="hljs-keyword">import</span> AsyncElasticsearch<br><span class="hljs-keyword">import</span> ssl<br><span class="hljs-keyword">import</span> asyncio<br><br>ssl_context = ssl.create_default_context(cafile=<span class="hljs-string">&#x27;info/http_ca.crt&#x27;</span>)<br>es = AsyncElasticsearch(<br>    [<span class="hljs-string">&#x27;https://localhost:9200&#x27;</span>],<br>    http_auth=(<span class="hljs-string">&#x27;elastic&#x27;</span>, <span class="hljs-string">&#x27;password&#x27;</span>),<br>    scheme=<span class="hljs-string">&quot;https&quot;</span>,<br>    ssl_context=ssl_context<br>)<br><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    info = <span class="hljs-keyword">await</span> es.info()<br>    <span class="hljs-built_in">print</span>(info)<br>    <span class="hljs-keyword">await</span> es.close()<br><br><span class="hljs-comment"># 运行主函数</span><br>asyncio.run(main())<br></code></pre></td></tr></table></figure><p>看到类似下面的输出代表运行成功 <img src="https://cdn.studyinglover.com/pic/2023/10/2c951211fd5820abebf0395b779f35bd.png" alt="image.png" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;docker搭建elasticsearch并使用python连接&quot;&gt;docker搭建elasticsearch并使用python连接&lt;/h1&gt;
&lt;h2 id=&quot;搭建&quot;&gt;搭建&lt;/h2&gt;
&lt;p&gt;创建一个docker网络 &lt;figure class=&quot;highlight</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
  </entry>
  
  <entry>
    <title>FreeU-文字生成图片的免费午餐笔记</title>
    <link href="https://studyinglover.com/2023/10/01/FreeU-%E6%96%87%E5%AD%97%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87%E7%9A%84%E5%85%8D%E8%B4%B9%E5%8D%88%E9%A4%90/"/>
    <id>https://studyinglover.com/2023/10/01/FreeU-%E6%96%87%E5%AD%97%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87%E7%9A%84%E5%85%8D%E8%B4%B9%E5%8D%88%E9%A4%90/</id>
    <published>2023-10-01T15:05:00.000Z</published>
    <updated>2023-12-14T14:49:14.040Z</updated>
    
    <content type="html"><![CDATA[<h1 id="freeu-文字生成图片的免费午餐">FreeU-文字生成图片的免费午餐</h1><p>项目地址<a href="https://chenyangsi.top/FreeU/">主页</a></p><p>作者在这篇论文引入了一种对UNet的改进方式，不需要重新训练和微调。</p><figure><img src="https://cdn.studyinglover.com/pic/2023/10/c48e2f490270ef836b26f6d7ed8d7f0e.png" alt="" /><figcaption>image.png</figcaption></figure><p>在UNet中存在两种连接，一种是上一层网络传递来的基础连接，主要贡献去噪能力。一种是跳线连接，主要贡献高频细节。UNet会将这两部分的特征contat之后作为下一层输入。作者的方法就是对这两部分做调整来提升图像质量。 <img src="https://cdn.studyinglover.com/pic/2023/10/483c5afa7533a2e1dcaf2cf0273c6677.png" alt="image.png" /></p><p>从技术上讲，对于 U-Net 解码器的第 <span class="math inline">\(l\)</span> 个块，<span class="math inline">\(\boldsymbol{x}_{l}\)</span> 表示前一个块主主干的主干特征图，让 <span class="math inline">\(h_l\)</span> 表示通过相应跳过连接传播的特征图。为了调整这些特征图，作者引入了两个标量因子：<span class="math inline">\(x_l\)</span> 对应的主干特征比例因子 <span class="math inline">\(b_l\)</span> 和 <span class="math inline">\(h_l\)</span> 的跳线特征对应的比例因子 sl。具体来说，因子 <span class="math inline">\(b_l\)</span> 旨在放大主干特征图 <span class="math inline">\(x_l\)</span>，而因子 <span class="math inline">\(s_l\)</span> 旨在衰减跳过特征图 <span class="math inline">\(h_l\)</span>。对于主干特征，在实验调查中，作者发现通过与<span class="math inline">\(b_l\)</span>相乘不加区别地放大<span class="math inline">\(x_l\)</span>的所有通道，在生成的合成图像中产生过度平滑的纹理。原因是增强的U-Net在去噪时损害了图像的高频细节，所以将缩放操作限制在<span class="math inline">\(x_l\)</span>的一半通道，如下所示:<span class="math display">\[\boldsymbol{x}_{l,i}^{^{\prime}}=\begin{cases}b_l\cdot\boldsymbol{x}_{l,i},&amp;\mathrm{~if~}i&lt;C/2\\\boldsymbol{x}_{l,i},&amp;\mathrm{~otherwise}&amp;\end{cases}\]</span></p><p>其中<span class="math inline">\(\boldsymbol{x}_{l,i}\)</span> 是第<span class="math inline">\(i\)</span> 层的第<span class="math inline">\(l\)</span>个特征图，<span class="math inline">\(C\)</span>是通道数。这个方法不仅增强了主干的去噪能力，而且还避免了全局应用缩放的不良结果，从而在降噪和纹理保存之间取得更细微的平衡。</p><p>为了进一步缓解由于增强去噪而导致的过度平滑纹理问题，FreeU进一步在傅里叶域中使用光谱调制来选择性地减少跳过特征的低频分量。在数学上，此操作执行如下<span class="math display">\[\begin{aligned}\mathcal{F}(\boldsymbol{h}_{l,i})&amp; =\operatorname{FFT}(\boldsymbol{h}_{l,i})  \\\mathcal{F}^{\prime}(\boldsymbol{h}_{l,i})&amp; =\mathcal{F}(\boldsymbol{h}_{l,i})\odot\boldsymbol{\alpha}_{l,i}  \\\boldsymbol{h}_{l,i}^{\prime}&amp; =\mathrm{IFFT}(\mathcal{F}^{\prime}(\boldsymbol{h}_{l,i})) \end{aligned}\]</span></p><p><span class="math inline">\(\mathrm{FFT}(\cdot)\)</span> 和 <span class="math inline">\(\operatorname{IFFT}(\cdot)\)</span> 是傅里叶变换和反傅里叶变换，<span class="math inline">\(\odot\)</span> 是逐元素乘法。</p><p><span class="math inline">\(\boldsymbol{\alpha}_{l,i}\)</span>是一个傅里叶掩码，用于设定<span class="math inline">\(s_l\)</span>的大小，<span class="math inline">\(R\)</span>是半径，<span class="math inline">\(r_\mathrm{thresh}\)</span> 是频率阈值 <span class="math display">\[\boldsymbol{\alpha}_{l,i}(r)=\begin{cases}s_l&amp;\mathrm{~if~}r&lt;r_\mathrm{thresh},\\1&amp;\text{ otherwise.}&amp;\end{cases}\]</span></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;freeu-文字生成图片的免费午餐&quot;&gt;FreeU-文字生成图片的免费午餐&lt;/h1&gt;
&lt;p&gt;项目地址&lt;a href=&quot;https://chenyangsi.top/FreeU/&quot;&gt;主页&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;作者在这篇论文引入了一种对UNet的改进方式，不需要重新训</summary>
      
    
    
    
    <category term="笔记" scheme="https://studyinglover.com/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="文字生成图片" scheme="https://studyinglover.com/tags/%E6%96%87%E5%AD%97%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>使用xgboost的c接口推理模型</title>
    <link href="https://studyinglover.com/2023/09/10/%E4%BD%BF%E7%94%A8xgboost%E7%9A%84c%E6%8E%A5%E5%8F%A3%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/"/>
    <id>https://studyinglover.com/2023/09/10/%E4%BD%BF%E7%94%A8xgboost%E7%9A%84c%E6%8E%A5%E5%8F%A3%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/</id>
    <published>2023-09-10T21:10:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用xgboost的c接口推理模型">使用xgboost的c接口推理模型</h1><p>官方<a href="https://xgboost.readthedocs.io/en/stable/tutorials/c_api_tutorial.html">c api tutorial</a>和<a href="https://xgboost.readthedocs.io/en/stable/c.html">文档</a>，非常恶心的一点是，tutorial和文档问题很多。</p><p>也参考了不少开源项目，主要有<a href="https://github.com/R-Stalker/xgboost-c-cplusplus">xgboost-c-cplusplus</a>,<a href="https://github.com/EmbolismSoil/xgboostpp">xgboostpp</a>.</p><p>首先导入头文件<code>#include "xgboost/c_api.h"</code> ，接下来xgboost的绝大多数接口都包含在了这个头文件中。</p><p>然后我们需要一个宏，来用它获取xgboost函数使用的情况.在每次调用xgboost函数时都应该调用这个宏。 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> safe_xgboost(call) &#123;  \</span><br><span class="hljs-meta">  int err = (call); \</span><br><span class="hljs-meta">  <span class="hljs-keyword">if</span> (err != 0) &#123; \</span><br><span class="hljs-meta">    fprintf(stderr, <span class="hljs-string">&quot;%s:%d: error in %s: %s\n&quot;</span>, __FILE__, __LINE__, #call, XGBGetLastError());  \</span><br><span class="hljs-meta">    exit(1); \</span><br><span class="hljs-meta">  &#125; \</span><br><span class="hljs-meta">&#125;</span><br></code></pre></td></tr></table></figure></p><p>我们使用的模型文件为<code>xgboost_model.bin</code> ,训练数据的输入是 <strong>11</strong> 个元素。</p><p>首先我们声明一个boost模型的句柄<code>BoosterHandle booster;</code> 接着用<code>XGBoosterCreate</code> 函数创建一个模型 。 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">BoosterHandle booster;<br>safe_xgboost(XGBoosterCreate(<span class="hljs-literal">NULL</span>, <span class="hljs-number">0</span>, &amp;booster));<br></code></pre></td></tr></table></figure></p><p>设置一个字符串作为模型路径<code>const char *model_path = "../xgboost_model.bin";</code>(<code>../</code>是因为编译出来的可执行文件在build目录下) ， 通过句柄使用<code>XGBoosterLoadModel</code>函数加载模型。 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">const</span> <span class="hljs-type">char</span> *model_path = <span class="hljs-string">&quot;../xgboost_model.bin&quot;</span>;<br>XGBoosterLoadModel(booster, model_path)<br></code></pre></td></tr></table></figure></p><p>设置一组数据作为推理测试，这里我选的数据标签是1.接着将输入数据转为xgboost的DMatrix格式。 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> a[<span class="hljs-number">11</span>]= &#123;<span class="hljs-number">14.0</span>,<span class="hljs-number">2.0</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">12.0</span>,<span class="hljs-number">19010.0</span>,<span class="hljs-number">120.0</span>,<span class="hljs-number">14.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>&#125;;<br>DMatrixHandle h_test;<br>safe_xgboost(XGDMatrixCreateFromMat(a, <span class="hljs-number">1</span>, <span class="hljs-number">11</span>, <span class="hljs-number">-1</span>, &amp;h_test));<br></code></pre></td></tr></table></figure></p><p>下面就可以进行模型推理了，<code>out_len</code> 代表输出的长度(实际上是一个整型变量)，<code>f</code>的模型推理的结果。 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">bst_ulong out_len;<br><span class="hljs-type">const</span> <span class="hljs-type">float</span> *f;<br>safe_xgboost(XGBoosterPredict(booster, h_test, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, &amp;out_len, &amp;f));<br></code></pre></td></tr></table></figure></p><p>我们可以打印输出查看结果 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Value of the variable: %f\n&quot;</span>, f[<span class="hljs-number">0</span>]);<br></code></pre></td></tr></table></figure></p><p>最后记得释放内存 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">XGDMatrixFree(h_test);<br>XGBoosterFree(booster);<br></code></pre></td></tr></table></figure></p><p>完整的代码 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdint.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;math.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;xgboost/c_api.h&quot;</span></span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> safe_xgboost(call) &#123;  \</span><br><span class="hljs-meta">  int err = (call); \</span><br><span class="hljs-meta">  <span class="hljs-keyword">if</span> (err != 0) &#123; \</span><br><span class="hljs-meta">    fprintf(stderr, <span class="hljs-string">&quot;%s:%d: error in %s: %s\n&quot;</span>, __FILE__, __LINE__, #call, XGBGetLastError());  \</span><br><span class="hljs-meta">    exit(1); \</span><br><span class="hljs-meta">  &#125; \</span><br><span class="hljs-meta">&#125;</span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> <span class="hljs-type">const</span> *argv[])</span> &#123;<br>    <span class="hljs-type">const</span> <span class="hljs-type">char</span> *model_path = <span class="hljs-string">&quot;../xgboost_model.bin&quot;</span>;<br><br>    <span class="hljs-comment">// create booster handle first</span><br>    BoosterHandle booster;<br>    safe_xgboost(XGBoosterCreate(<span class="hljs-literal">NULL</span>, <span class="hljs-number">0</span>, &amp;booster));<br>    <span class="hljs-comment">// load model</span><br>    safe_xgboost(XGBoosterLoadModel(booster, model_path));<br><br>    <span class="hljs-comment">//generate random data of a a[11],every nuber from 0 to 2</span><br>    <span class="hljs-comment">// float a[11]= &#123;1.0,12.0,1.0,1.0,16134.0,20600.0,0.0,1.0,0.0,0.0,0.0&#125;; // label: 0.0</span><br>    <span class="hljs-type">float</span> a[<span class="hljs-number">11</span>]= &#123;<span class="hljs-number">14.0</span>,<span class="hljs-number">2.0</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">12.0</span>,<span class="hljs-number">19010.0</span>,<span class="hljs-number">120.0</span>,<span class="hljs-number">14.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>,<span class="hljs-number">0.0</span>&#125;; <span class="hljs-comment">// label: 1.0</span><br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">11</span>; i++) &#123;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%f, &quot;</span>, a[i]);<br>        <span class="hljs-keyword">if</span> (i == <span class="hljs-number">10</span>) &#123;<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;\n&quot;</span>);<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// convert to DMatrix</span><br>    DMatrixHandle h_test;<br>    safe_xgboost(XGDMatrixCreateFromMat(a, <span class="hljs-number">1</span>, <span class="hljs-number">11</span>, <span class="hljs-number">-1</span>, &amp;h_test));<br>    <span class="hljs-comment">// predict</span><br>    bst_ulong out_len;<br>    <span class="hljs-type">const</span> <span class="hljs-type">float</span> *f;<br>    safe_xgboost(XGBoosterPredict(booster, h_test, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, &amp;out_len, &amp;f));<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Value of the variable: %f\n&quot;</span>, f[<span class="hljs-number">0</span>]);<br><br>    XGDMatrixFree(h_test);<br>    XGBoosterFree(booster);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>使用cmake编译 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs CMakeLists.txt">cmake_minimum_required(VERSION 3.18)<br>project(project_name LANGUAGES C CXX VERSION 0.1)<br>set(xgboost_DIR &quot;/usr/include/xgboost&quot;)<br><br>include_directories($&#123;xgboost_DIR&#125;)<br>link_directories($&#123;xgboost_DIR&#125;)<br><br>add_executable(project_name test.c)<br>target_link_libraries(project_name xgboost)<br></code></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> build<br><span class="hljs-built_in">cd</span> ./build<br>cmake ..<br>make .<br>./project_name<br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;使用xgboost的c接口推理模型&quot;&gt;使用xgboost的c接口推理模型&lt;/h1&gt;
&lt;p&gt;官方&lt;a href=&quot;https://xgboost.readthedocs.io/en/stable/tutorials/c_api_tutorial.html&quot;&gt;c ap</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
    <category term="机器学习" scheme="https://studyinglover.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Archlinux使用CMake调用xgboost的c接口</title>
    <link href="https://studyinglover.com/2023/09/09/Archlinux%E4%BD%BF%E7%94%A8CMake%E8%B0%83%E7%94%A8xgboost%E7%9A%84c%E6%8E%A5%E5%8F%A3/"/>
    <id>https://studyinglover.com/2023/09/09/Archlinux%E4%BD%BF%E7%94%A8CMake%E8%B0%83%E7%94%A8xgboost%E7%9A%84c%E6%8E%A5%E5%8F%A3/</id>
    <published>2023-09-09T20:53:00.000Z</published>
    <updated>2023-12-14T14:49:14.040Z</updated>
    
    <content type="html"><![CDATA[<h1 id="archlinux使用cmake调用xgboost的c接口">Archlinux使用CMake调用xgboost的c接口</h1><p>平台Archlinux,直接<code>yay</code> 安装xgboost,相关的.h文件会被直接安装到<code>/usr/include/xgboost</code> 路径下，所有在<code>CMakeLists.txt</code> 设置<code>include_directories</code> 到该路径下即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs CMakeLists.txt">cmake_minimum_required(VERSION 3.18)<br>project(project_name LANGUAGES C CXX VERSION 0.1)<br>set(xgboost_DIR &quot;/usr/include/xgboost&quot;)<br><br>include_directories($&#123;xgboost_DIR&#125;)<br>link_directories($&#123;xgboost_DIR&#125;)<br><br>add_executable(project_name test.c)<br>target_link_libraries(project_name xgboost)<br></code></pre></td></tr></table></figure><p>在c文件中直接调用头文件 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;xgboost/c_api.h&quot;</span></span><br></code></pre></td></tr></table></figure></p><p>编译使用cmake <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> build<br><span class="hljs-built_in">cd</span> ./build<br>cmake ..<br>make <br>./project_name<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;archlinux使用cmake调用xgboost的c接口&quot;&gt;Archlinux使用CMake调用xgboost的c接口&lt;/h1&gt;
&lt;p&gt;平台Archlinux,直接&lt;code&gt;yay&lt;/code&gt; 安装xgboost,相关的.h文件会被直接安装到&lt;code&gt;/u</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
    <category term="机器学习" scheme="https://studyinglover.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>m2cgen生成机器学习c语言推理代码</title>
    <link href="https://studyinglover.com/2023/09/07/m2cgen%E7%94%9F%E6%88%90c%E8%AF%AD%E8%A8%80%E6%8E%A8%E7%90%86%E4%BB%A3%E7%A0%81/"/>
    <id>https://studyinglover.com/2023/09/07/m2cgen%E7%94%9F%E6%88%90c%E8%AF%AD%E8%A8%80%E6%8E%A8%E7%90%86%E4%BB%A3%E7%A0%81/</id>
    <published>2023-09-07T15:48:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="m2cgen生成机器学习c语言推理代码">m2cgen生成机器学习c语言推理代码</h1><p>众所周知，cubemx是一个用于生成嵌入式的代码的好东西虽然我没用过。它的原理是将原本的矩阵运算和tensor变成了一个c的数组，同时会对代码进行优化，然后进行运算。</p><p>但是如果我们需要在其他平台上使用其他语言就很尴尬了，因为我们没有cubemx来做生成和优化。感谢蓬勃发展的社区，<a href="https://github.com/BayesWitnesses/m2cgen">m2cgen</a>解决了我们的问题。</p><p>使用起来非常简单，我们使用xgboost举例，先训练一个xgboost模型 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_diabetes<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> linear_model<br><br>X, y = load_diabetes(return_X_y=<span class="hljs-literal">True</span>)<br><br>estimator = linear_model.LinearRegression()<br>estimator.fit(X, y)<br></code></pre></td></tr></table></figure></p><p>然后导出c代码 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> m2cgen <span class="hljs-keyword">as</span> m2c<br>code = m2c.export_to_c(estimator)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span> (<span class="hljs-string">&#x27;model.c&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>   f.write(code)<br></code></pre></td></tr></table></figure></p><p>我们可以看到导出的代码已经是纯c语言的代码了，是以一个函数保存的 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">double</span> <span class="hljs-title function_">score</span><span class="hljs-params">(<span class="hljs-type">double</span> * input)</span> &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">152.13348416289597</span> + input[<span class="hljs-number">0</span>] * <span class="hljs-number">-10.009866299810508</span> + input[<span class="hljs-number">1</span>] * <span class="hljs-number">-239.81564367242302</span> + input[<span class="hljs-number">2</span>] * <span class="hljs-number">519.845920054461</span> + input[<span class="hljs-number">3</span>] * <span class="hljs-number">324.38464550232334</span> + input[<span class="hljs-number">4</span>] * <span class="hljs-number">-792.1756385522302</span> + input[<span class="hljs-number">5</span>] * <span class="hljs-number">476.73902100525737</span> + input[<span class="hljs-number">6</span>] * <span class="hljs-number">101.04326793803405</span> + input[<span class="hljs-number">7</span>] * <span class="hljs-number">177.06323767134606</span> + input[<span class="hljs-number">8</span>] * <span class="hljs-number">751.2736995571034</span> + input[<span class="hljs-number">9</span>] * <span class="hljs-number">67.62669218370456</span>;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>如果你遇到了这样的一个错误 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">base_score = -math.log(1.0 / self._base_score - 1.0)<br>                           ~~~~^~~~~~~~~~~~~~~~~~<br>TypeError: unsupported operand <span class="hljs-built_in">type</span>(s) <span class="hljs-keyword">for</span> /: <span class="hljs-string">&#x27;float&#x27;</span> and <span class="hljs-string">&#x27;NoneType&#x27;</span><br></code></pre></td></tr></table></figure> 这是由于xgboost模型字段发生变化导致的，在<code>m2c.export_to_c</code>之前加入<code>model.base_score = 0</code> 就行 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> m2cgen <span class="hljs-keyword">as</span> m2c<br>model.base_score = <span class="hljs-number">0</span><br>code = m2c.export_to_c(estimator)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span> (<span class="hljs-string">&#x27;model.c&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>   f.write(code)<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;m2cgen生成机器学习c语言推理代码&quot;&gt;m2cgen生成机器学习c语言推理代码&lt;/h1&gt;
&lt;p&gt;众所周知，cubemx是一个用于生成嵌入式的代码的好东西虽然我没用过。它的原理是将原本的矩阵运算和tensor变成了一个c的数组，同时会对代码进行优化，然后进行运算。</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
    <category term="机器学习" scheme="https://studyinglover.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>xgboost模型序列化存储并推理</title>
    <link href="https://studyinglover.com/2023/09/07/xgboost%E6%A8%A1%E5%9E%8B%E5%BA%8F%E5%88%97%E5%8C%96%E5%AD%98%E5%82%A8%E5%B9%B6%E6%8E%A8%E7%90%86/"/>
    <id>https://studyinglover.com/2023/09/07/xgboost%E6%A8%A1%E5%9E%8B%E5%BA%8F%E5%88%97%E5%8C%96%E5%AD%98%E5%82%A8%E5%B9%B6%E6%8E%A8%E7%90%86/</id>
    <published>2023-09-07T15:03:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="xgboost模型序列化存储并推理">xgboost模型序列化存储并推理</h1><p>参考了博客 https://github.com/apachecn/ml-mastery-zh/blob/master/docs/xgboost/save-gradient-boosting-models-xgboost-python.md ，但是修改了一些过时的部分。</p><p>我们在 <a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes">Pima 印第安人糖尿病数据集</a> 上训练xgboost模型，训练数据集在<a href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv">GitHub</a> 下载 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv<br></code></pre></td></tr></table></figure></p><h2 id="pickle">Pickle</h2><p>Pickle是一个python序列化的标准方法。</p><p>先训练一个模型,然后将模型按照Pickle的形式存储，接下来读取模型并进行推理 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> loadtxt<br><span class="hljs-keyword">import</span> xgboost<br><span class="hljs-keyword">import</span> pickle<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> model_selection<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> model_selection <span class="hljs-keyword">as</span> cross_validation<br><span class="hljs-comment"># load data</span><br>dataset = loadtxt(<span class="hljs-string">&#x27;pima-indians-diabetes.data.csv&#x27;</span>, delimiter=<span class="hljs-string">&quot;,&quot;</span>)<br><span class="hljs-comment"># split data into X and y</span><br>X = dataset[:,<span class="hljs-number">0</span>:<span class="hljs-number">8</span>]<br>Y = dataset[:,<span class="hljs-number">8</span>]<br><span class="hljs-comment"># split data into train and test sets</span><br>seed = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>)<br>test_size = <span class="hljs-number">0.33</span><br><br>X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, Y, test_size=test_size, random_state=seed)<br><span class="hljs-comment"># fit model no training data</span><br>model = xgboost.XGBClassifier()<br>model.fit(X_train, y_train)<br><br><span class="hljs-comment"># save model to file</span><br>pickle.dump(model, <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;pima.pickle.dat&quot;</span>, <span class="hljs-string">&quot;wb&quot;</span>))<br><br></code></pre></td></tr></table></figure></p><p>读取模型并推理 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load model from file</span><br>loaded_model = pickle.load(<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;pima.pickle.dat&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>))<br><span class="hljs-comment"># train model again</span><br>loaded_model.fit(X_train, y_train)<br><br><span class="hljs-comment"># make predictions for test data</span><br>y_pred = loaded_model.predict(X_test)<br>predictions = [<span class="hljs-built_in">round</span>(value) <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> y_pred]<br><span class="hljs-comment"># evaluate predictions</span><br>accuracy = accuracy_score(y_test, predictions)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy: %.2f%%&quot;</span> % (accuracy * <span class="hljs-number">100.0</span>))<br></code></pre></td></tr></table></figure></p><h2 id="joblib">joblib</h2><p>Joblib 是一组在 Python 中提供<strong>轻量级流水线</strong>的工具，<strong>joblib 在大型 numpy 数组上通常要快得多</strong></p><p>用法实际上和pickle基本相同。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Train XGBoost model, save to file using joblib, load and make predictions</span><br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">from</span> numpy <span class="hljs-keyword">import</span> loadtxt<br><span class="hljs-keyword">import</span> xgboost<br><span class="hljs-keyword">import</span> joblib<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> model_selection<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> model_selection <span class="hljs-keyword">as</span> cross_validation<br><span class="hljs-comment"># load data</span><br>dataset = loadtxt(<span class="hljs-string">&#x27;pima-indians-diabetes.data.csv&#x27;</span>, delimiter=<span class="hljs-string">&quot;,&quot;</span>)<br><span class="hljs-comment"># split data into X and y</span><br>X = dataset[:,<span class="hljs-number">0</span>:<span class="hljs-number">8</span>]<br>Y = dataset[:,<span class="hljs-number">8</span>]<br><span class="hljs-comment"># split data into train and test sets</span><br>seed = random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>)<br>test_size = <span class="hljs-number">0.33</span><br>X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, Y, test_size=test_size, random_state=seed)<br><span class="hljs-comment"># fit model no training data</span><br>model = xgboost.XGBClassifier()<br>model.fit(X_train, y_train)<br><span class="hljs-comment"># save model to file</span><br>joblib.dump(model, <span class="hljs-string">&quot;pima.joblib.dat&quot;</span>)<br><br></code></pre></td></tr></table></figure></p><p>读取模型并推理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load model from file</span><br>loaded_model = joblib.load(<span class="hljs-string">&quot;pima.joblib.dat&quot;</span>)<br><span class="hljs-comment"># make predictions for test data</span><br>y_pred = loaded_model.predict(X_test)<br>predictions = [<span class="hljs-built_in">round</span>(value) <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> y_pred]<br><span class="hljs-comment"># evaluate predictions</span><br>accuracy = accuracy_score(y_test, predictions)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Accuracy: %.2f%%&quot;</span> % (accuracy * <span class="hljs-number">100.0</span>))<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;xgboost模型序列化存储并推理&quot;&gt;xgboost模型序列化存储并推理&lt;/h1&gt;
&lt;p&gt;参考了博客 https://github.com/apachecn/ml-mastery-zh/blob/master/docs/xgboost/save-gradient-</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
    <category term="机器学习" scheme="https://studyinglover.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>speculative-sampling笔记</title>
    <link href="https://studyinglover.com/2023/09/05/speculative-sampling%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/09/05/speculative-sampling%E7%AC%94%E8%AE%B0/</id>
    <published>2023-09-05T19:40:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="speculative-sampling笔记">speculative-sampling笔记</h1><p>speculative-sampling,投机采样是一种加速llm推理的方法。</p><p>论文<a href="https://arxiv.org/abs/2302.01318">arxiv</a> ,参考博客<a href="https://jaykmody.com/blog/speculative-sampling/">jaykmody.com</a></p><p>这个方法需要用到两个模型，一个小模型，称为 draft model，一个大模型，称为target model。</p><p>speculative-sampling使用了一种直觉，对于一些序列下一个token预测是i很明显的，小模型也可以完成。因此，如果draft model和target model在给定的很明显的序列上的分布之间存在很强的一致性，那么就允许targrt model被调用时一次输出多个token</p><p><img src="https://cdn.studyinglover.com/pic/2023/09/a74b5ced4e8f8945acc8cf6b4fbbdfb7.png" alt="image.png" /> 自回归采样，就是说给一个序列模型预测下一个token。</p><p><img src="https://cdn.studyinglover.com/pic/2023/09/5867fc09bb99e8709725e0813d4ad7cf.png" alt="image.png" /> 对于大模型来说，主要是三个部分拖慢了推理速度，线性层，注意力机制和通信。</p><p>拒绝采样的公式被修改为<span class="math display">\[\min\left(1,\frac{q(\tilde{x}_{n+1}|x_1,\ldots,x_n)}{p(\tilde{x}_{n+1}|x_1,\ldots,x_n)}\right)\]</span> 给定一个序列<span class="math inline">\(x_0,\ldots,x_t\)</span> 和一个<span class="math inline">\(K\)</span> ,用draft model先采样<span class="math inline">\(\tilde{x}_t\sim p(x|,x_1,\ldots,x_n,\tilde{x}_1,\ldots,\tilde{x}_{t-1})\)</span> ，循环<span class="math inline">\(K\)</span>词</p><p>然后并行计算<span class="math inline">\(q(x|,x_1,\ldots,x_n),~q(x|,x_1,\ldots,x_n,\tilde{x}_1),~\ldots,~q(x|,x_1,\ldots,x_n,\tilde{x}_1,\ldots,\tilde{x}_K)\)</span></p><p>采样一个<span class="math inline">\(r\sim U[0,1]\)</span> ,如果<span class="math inline">\(r&lt;\min\left(1,\frac{q(x|x_1,...,x_{n+t-1})}{p(x|x_1,...,x_{n+t-1})}\right)\)</span> 就把<span class="math inline">\({\tilde{x}_t}\)</span> 拼到序列<span class="math inline">\(x_{n+t-1}\)</span> 后面，这里的<span class="math inline">\(n\)</span> 是序列长度。</p><p>如果<span class="math inline">\(\tilde{x}_{n+1}\)</span> 被拒绝了，也就是说<span class="math inline">\(r&gt;\min\left(1,\frac{q(x|x_1,...,x_{n+t-1})}{p(x|x_1,...,x_{n+t-1})}\right)\)</span>,那么就直接按照<span class="math inline">\(x_{n+1}\sim(q(x|x_1,\ldots,x_n)-p(x|x_1,\ldots,x_n))_+\)</span>采样一个<span class="math inline">\(x_{n+1}\)</span></p><p><span class="math inline">\((.)_{+}\)</span> 被定义为<span class="math display">\[(f(x))_+=\frac{\max(0,f(x))}{\sum_x\max(0,f(x))}\]</span> 如果所有的token都被接受了，那就再采样一个拼到序列后面，然后结束。</p><p>使用标准采样方法，如核、top-k 采样和调整温度，可以在应用这种拒绝采样方案之前相应地修改概率。作者观察到整体接受率对使用的确切参数具有鲁棒性。</p><p>因为speculative-sampling没有改变transformer的结构，所以<strong>可以和其他方法结合使用</strong> ,例如量化，multi-query attention。</p><p>在选择draft model方面，可以简单地使用较小版本的目标语言模型作为草稿并获得较高的接受率。从工程和工作流程的角度来看，这也很方便，因为应该首先存在对此类模型的稳健工具来训练目标模型。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;speculative-sampling笔记&quot;&gt;speculative-sampling笔记&lt;/h1&gt;
&lt;p&gt;speculative-sampling,投机采样是一种加速llm推理的方法。&lt;/p&gt;
&lt;p&gt;论文&lt;a href=&quot;https://arxiv.org/a</summary>
      
    
    
    
    <category term="笔记" scheme="https://studyinglover.com/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="自然语言处理" scheme="https://studyinglover.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>prompt2model笔记</title>
    <link href="https://studyinglover.com/2023/09/05/prompt2model%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/09/05/prompt2model%E7%AC%94%E8%AE%B0/</id>
    <published>2023-09-05T09:15:00.000Z</published>
    <updated>2023-12-14T14:49:14.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="prompt2model笔记">prompt2model笔记</h1><p>prompt2model是一个通过提示自动生成语言模型的方法</p><p>项目地址<a href="https://github.com/neulab/prompt2model">GitHub</a></p><figure><img src="https://cdn.studyinglover.com/pic/2023/09/b125b68b936c4cce09d451a5f790cb35.png" alt="" /><figcaption>image.png</figcaption></figure><p>模型分为Prompt Parser，Dataset Retriever，Dataset Generator，Model Retriever几个部分</p><h2 id="prompt-parser">Prompt Parser</h2><figure><img src="https://cdn.studyinglover.com/pic/2023/09/b8ddca1c0daa867307144f0a5546230a.png" alt="" /><figcaption>image.png</figcaption></figure><p>作者使用具有上下文学习的 LLM 来分割用户提示，在实验中使用 OpenAI gpt-3.5-turbo-0613。如果提供的指令被识别为英语以外的语言，就使用 DeepL API.2 将其转换为英语</p><h2 id="dataset-retriever">Dataset Retriever</h2><figure><img src="https://cdn.studyinglover.com/pic/2023/09/8acdf0823c2fb3757b694f71e982a0ce.png" alt="" /><figcaption>image.png</figcaption></figure><p>给定一个提示，首先尝试发现现有的手动注释的数据，可以支持用户的任务描述。数据集检索器有几个设计决策：</p><ol type="1"><li>搜索哪些数据集。</li><li>如何索引数据集以供搜索。</li><li>3.用户任务需要哪些数据集列，应该忽略哪些列。 作者选用了 Viswanathan et al. (2023) 的方案，称为DataFinder</li></ol><p>作者利用 DataFinder 训练的双编码器检索器对最相关的数据集进行排名。一旦确定了相关数据集，下一步是确定数据集的哪些列对应于用户指定的输入和期望输出。由于自动为任何数据集诱导正确的模式可能具有挑战性，所以作者采用了 human-inthe-loop 中的方法。将前 k 个数据集（默认情况下 k = 25）呈现给用户，并允许用户要么选择最相关的数据集，要么声明没有一个非常适合他们的任务。然后，要求用户从数据集的模式中识别输入和输出的适当列。</p><h2 id="dataset-generator">Dataset Generator</h2><p><img src="https://cdn.studyinglover.com/pic/2023/09/622f2321a6504a87d67b8866a2c5c0b5.png" alt="image.png" /> 作者使用自动提示工程来生成不同的数据集，使用退火算法对生成的数据集进行排名。自一致性过滤来防止llm生成的伪标签。具体做法是通过选择最频繁的答案为每个唯一输入创建一个共识输出；在平局的情况下，启发式地选择最短的答案。使用了zeno-build做并行。</p><h2 id="model-retriever">Model Retriever</h2><figure><img src="https://cdn.studyinglover.com/pic/2023/09/413a97d48cf68b35b004601c0fbd4446.png" alt="" /><figcaption>image.png</figcaption></figure><p>这是一个检索类问题。作者选择encoder-decoder的架构，但是仍然有非常多的选择，像Salesforce/codet5-base，MaryaAI/opus-mt-ar-en-finetuned-ar-to-en，所以作为一个检索类问题使用用户的指令作为查询，搜索 Hugging Face 上模型的所有文本描述。 <img src="https://cdn.studyinglover.com/pic/2023/09/7f7790be882200d87972f87e06697d8f.png" alt="image.png" /> ，考虑到对模型的描述一般是比较稀疏并且包含大量模板文本，这里作者使用gpt-3.5-turbo生成了模型可能的描述，用 BM25 算法来计算查询模型相似度分数。</p><p>为了模型易部署，作者过滤了大于3gb的所有模型，同时引入了一个直觉，下载量越高的模型效果越好。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;prompt2model笔记&quot;&gt;prompt2model笔记&lt;/h1&gt;
&lt;p&gt;prompt2model是一个通过提示自动生成语言模型的方法&lt;/p&gt;
&lt;p&gt;项目地址&lt;a href=&quot;https://github.com/neulab/prompt2model&quot;&gt;Gi</summary>
      
    
    
    
    <category term="笔记" scheme="https://studyinglover.com/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="自然语言处理" scheme="https://studyinglover.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>RoboTAP笔记</title>
    <link href="https://studyinglover.com/2023/09/01/RoboTAP%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/09/01/RoboTAP%E7%AC%94%E8%AE%B0/</id>
    <published>2023-09-01T12:35:00.000Z</published>
    <updated>2023-12-14T14:49:14.040Z</updated>
    
    <content type="html"><![CDATA[<h1 id="robotap笔记">RoboTAP笔记</h1><p>RoboTAP是一种基于点追踪技术的少样本视觉模仿方法，可以实现机器人在多个任务和场景中的精准操作。</p><p>项目主页<a href="https://robotap.github.io/">GitHub</a></p><p>RoboTAP不需要任何特定于任务的训练或神经网络微调。由于TAP的普适性，作者发现添加新任务（包括调整超参数）只需几分钟，这比我们熟悉的任何操纵系统都快几个数量级。作者认为这种能力在大规模自主数据收集和作为解决现实任务的解决方案方面可能非常有用。RoboTAP在需要快速教授视觉运动技能并且可以轻松演示所需行为的情况下最有用。</p><p>RoboTAP存在一些重要的限制。首先，低级控制器是纯视觉的，这排除了复杂的运动规划或力控制行为。其次，目前计算运动计划一次并在没有重新规划的情况下执行它，这可能会导致单个行为失败或环境意外改变。</p><p>作者在论文中指出他有四个贡献</p><ol type="1"><li>在密集跟踪方面制定多任务操作问题</li><li>RoboTAP的具体实现是什么，在哪里以及如何以visual-saliency，temporal-alignment, 和 visual-servoing的形式解决问题</li><li>一个新的密集跟踪数据集，其中包含为RoboTAP任务量身定制的ground-truth人工注释，并在专注于真实世界机器人操作的TAP-Vid基准上进行评估</li><li>描述了RoboTAP在涉及精确多体重排、变形物体和不可逆行动的一系列操作任务中的成功和失败模式的实证结果。</li></ol><figure><img src="https://cdn.studyinglover.com/pic/2023/08/15ff4915dff842e47e91d580d0d0fe5c.png" alt="" /><figcaption>image.png</figcaption></figure><p>RoboTAP方法的核心是利用TAPIR密集地跟踪一组演示，将演示分段，并自动发现每个阶段的活动点集q，该点集覆盖在该动作阶段相关的物体上。然后，我们形成一个可以在机器人上执行的运动计划，其中包括模仿视觉运动和基本的电机原语，例如关闭和打开夹爪的阶段。通过使用TAPIR检测点q，找到最近的演示，显示如何移动这些点，并找到可以用作运动目标的单个附近帧来实现视觉伺服。将目标帧（g）和在线TAPIR检测之间的位移用作经典视觉伺服的运动目标，从而产生出奇异复杂和强健的行为。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;robotap笔记&quot;&gt;RoboTAP笔记&lt;/h1&gt;
&lt;p&gt;RoboTAP是一种基于点追踪技术的少样本视觉模仿方法，可以实现机器人在多个任务和场景中的精准操作。&lt;/p&gt;
&lt;p&gt;项目主页&lt;a href=&quot;https://robotap.github.io/&quot;&gt;GitH</summary>
      
    
    
    
    <category term="笔记" scheme="https://studyinglover.com/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="多模态" scheme="https://studyinglover.com/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/"/>
    
  </entry>
  
</feed>
