<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>plus studio</title>
  
  
  <link href="https://studyinglover.com/atom.xml" rel="self"/>
  
  <link href="https://studyinglover.com/"/>
  <updated>2023-09-05T01:18:04.360Z</updated>
  <id>https://studyinglover.com/</id>
  
  <author>
    <name>StudyingLover</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>prompt2model笔记</title>
    <link href="https://studyinglover.com/2023/09/05/prompt2model%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/09/05/prompt2model%E7%AC%94%E8%AE%B0/</id>
    <published>2023-09-05T09:15:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="prompt2model笔记">prompt2model笔记</h1><p>prompt2model是一个通过提示自动生成语言模型的方法</p><p>项目地址<a href="https://github.com/neulab/prompt2model">GitHub</a></p><figure><img src="https://cdn.studyinglover.com/pic/2023/09/b125b68b936c4cce09d451a5f790cb35.png" alt="" /><figcaption>image.png</figcaption></figure><p>模型分为Prompt Parser，Dataset Retriever，Dataset Generator，Model Retriever几个部分</p><h2 id="prompt-parser">Prompt Parser</h2><figure><img src="https://cdn.studyinglover.com/pic/2023/09/b8ddca1c0daa867307144f0a5546230a.png" alt="" /><figcaption>image.png</figcaption></figure><p>作者使用具有上下文学习的 LLM 来分割用户提示，在实验中使用 OpenAI gpt-3.5-turbo-0613。如果提供的指令被识别为英语以外的语言，就使用 DeepL API.2 将其转换为英语</p><h2 id="dataset-retriever">Dataset Retriever</h2><figure><img src="https://cdn.studyinglover.com/pic/2023/09/8acdf0823c2fb3757b694f71e982a0ce.png" alt="" /><figcaption>image.png</figcaption></figure><p>给定一个提示，首先尝试发现现有的手动注释的数据，可以支持用户的任务描述。数据集检索器有几个设计决策：</p><ol type="1"><li>搜索哪些数据集。</li><li>如何索引数据集以供搜索。</li><li>3.用户任务需要哪些数据集列，应该忽略哪些列。 作者选用了 Viswanathan et al. (2023) 的方案，称为DataFinder</li></ol><p>作者利用 DataFinder 训练的双编码器检索器对最相关的数据集进行排名。一旦确定了相关数据集，下一步是确定数据集的哪些列对应于用户指定的输入和期望输出。由于自动为任何数据集诱导正确的模式可能具有挑战性，所以作者采用了 human-inthe-loop 中的方法。将前 k 个数据集（默认情况下 k = 25）呈现给用户，并允许用户要么选择最相关的数据集，要么声明没有一个非常适合他们的任务。然后，要求用户从数据集的模式中识别输入和输出的适当列。</p><h2 id="dataset-generator">Dataset Generator</h2><p><img src="https://cdn.studyinglover.com/pic/2023/09/622f2321a6504a87d67b8866a2c5c0b5.png" alt="image.png" /> 作者使用自动提示工程来生成不同的数据集，使用退火算法对生成的数据集进行排名。自一致性过滤来防止llm生成的伪标签。具体做法是通过选择最频繁的答案为每个唯一输入创建一个共识输出；在平局的情况下，启发式地选择最短的答案。使用了zeno-build做并行。</p><h2 id="model-retriever">Model Retriever</h2><figure><img src="https://cdn.studyinglover.com/pic/2023/09/413a97d48cf68b35b004601c0fbd4446.png" alt="" /><figcaption>image.png</figcaption></figure><p>这是一个检索类问题。作者选择encoder-decoder的架构，但是仍然有非常多的选择，像Salesforce/codet5-base，MaryaAI/opus-mt-ar-en-finetuned-ar-to-en，所以作为一个检索类问题使用用户的指令作为查询，搜索 Hugging Face 上模型的所有文本描述。 <img src="https://cdn.studyinglover.com/pic/2023/09/7f7790be882200d87972f87e06697d8f.png" alt="image.png" /> ，考虑到对模型的描述一般是比较稀疏并且包含大量模板文本，这里作者使用gpt-3.5-turbo生成了模型可能的描述，用 BM25 算法来计算查询模型相似度分数。</p><p>为了模型易部署，作者过滤了大于3gb的所有模型，同时引入了一个直觉，下载量越高的模型效果越好。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;prompt2model笔记&quot;&gt;prompt2model笔记&lt;/h1&gt;
&lt;p&gt;prompt2model是一个通过提示自动生成语言模型的方法&lt;/p&gt;
&lt;p&gt;项目地址&lt;a href=&quot;https://github.com/neulab/prompt2model&quot;&gt;Gi</summary>
      
    
    
    
    <category term="笔记" scheme="https://studyinglover.com/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="自然语言处理" scheme="https://studyinglover.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>RoboTAP笔记</title>
    <link href="https://studyinglover.com/2023/09/01/RoboTAP%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/09/01/RoboTAP%E7%AC%94%E8%AE%B0/</id>
    <published>2023-09-01T12:35:00.000Z</published>
    <updated>2023-09-05T01:18:04.356Z</updated>
    
    <content type="html"><![CDATA[<h1 id="robotap笔记">RoboTAP笔记</h1><p>RoboTAP是一种基于点追踪技术的少样本视觉模仿方法，可以实现机器人在多个任务和场景中的精准操作。</p><p>项目主页<a href="https://robotap.github.io/">GitHub</a></p><p>RoboTAP不需要任何特定于任务的训练或神经网络微调。由于TAP的普适性，作者发现添加新任务（包括调整超参数）只需几分钟，这比我们熟悉的任何操纵系统都快几个数量级。作者认为这种能力在大规模自主数据收集和作为解决现实任务的解决方案方面可能非常有用。RoboTAP在需要快速教授视觉运动技能并且可以轻松演示所需行为的情况下最有用。</p><p>RoboTAP存在一些重要的限制。首先，低级控制器是纯视觉的，这排除了复杂的运动规划或力控制行为。其次，目前计算运动计划一次并在没有重新规划的情况下执行它，这可能会导致单个行为失败或环境意外改变。</p><p>作者在论文中指出他有四个贡献</p><ol type="1"><li>在密集跟踪方面制定多任务操作问题</li><li>RoboTAP的具体实现是什么，在哪里以及如何以visual-saliency，temporal-alignment, 和 visual-servoing的形式解决问题</li><li>一个新的密集跟踪数据集，其中包含为RoboTAP任务量身定制的ground-truth人工注释，并在专注于真实世界机器人操作的TAP-Vid基准上进行评估</li><li>描述了RoboTAP在涉及精确多体重排、变形物体和不可逆行动的一系列操作任务中的成功和失败模式的实证结果。</li></ol><figure><img src="https://cdn.studyinglover.com/pic/2023/08/15ff4915dff842e47e91d580d0d0fe5c.png" alt="" /><figcaption>image.png</figcaption></figure><p>RoboTAP方法的核心是利用TAPIR密集地跟踪一组演示，将演示分段，并自动发现每个阶段的活动点集q，该点集覆盖在该动作阶段相关的物体上。然后，我们形成一个可以在机器人上执行的运动计划，其中包括模仿视觉运动和基本的电机原语，例如关闭和打开夹爪的阶段。通过使用TAPIR检测点q，找到最近的演示，显示如何移动这些点，并找到可以用作运动目标的单个附近帧来实现视觉伺服。将目标帧（g）和在线TAPIR检测之间的位移用作经典视觉伺服的运动目标，从而产生出奇异复杂和强健的行为。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;robotap笔记&quot;&gt;RoboTAP笔记&lt;/h1&gt;
&lt;p&gt;RoboTAP是一种基于点追踪技术的少样本视觉模仿方法，可以实现机器人在多个任务和场景中的精准操作。&lt;/p&gt;
&lt;p&gt;项目主页&lt;a href=&quot;https://robotap.github.io/&quot;&gt;GitH</summary>
      
    
    
    
    <category term="笔记" scheme="https://studyinglover.com/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="多模态" scheme="https://studyinglover.com/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>自建obsidian同步服务</title>
    <link href="https://studyinglover.com/2023/08/31/%E8%87%AA%E5%BB%BAobsidian%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1/"/>
    <id>https://studyinglover.com/2023/08/31/%E8%87%AA%E5%BB%BAobsidian%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1/</id>
    <published>2023-08-31T15:47:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="自建obsidian同步服务">自建obsidian同步服务</h1><p>最近GitHub上有这样一个项目<a href="https://github.com/acheong08/rev-obsidian-sync">rev-obsidian-sync</a> ,他逆向了obsidian的同步服务，使其可以在本地运行。</p><h2 id="服务端">服务端</h2><h3 id="安装">安装</h3><p>首先安装服务端， <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/acheong08/rev-obsidian-sync<br><span class="hljs-built_in">cd</span> obsidian-sync<br>go run cmd/obsidian-sync/main.go<br></code></pre></td></tr></table></figure> go会下载一堆依赖，然后你会在最下面看到这个 <img src="https://cdn.studyinglover.com/pic/2023/08/c41aa8aca8c8033d319317ee2dbc3643.png" alt="image.png" /></p><p>当然你也可以自定义域名，设置环境变量，<code>DOMAIN_NAME</code> 设置域名，<code>ADDR_HTTP</code>设置监听端口，<code>DATA_DIR</code> 设置数据保存的文件夹，<code>SIGNUP_KEY</code> 设置注册的密钥。</p><h3 id="创建用户">创建用户</h3><p>需要新建一个用户给自己 <code>go run cmd/signup/main.go</code> 在命令行按照提示输入邮箱密码。</p><p>或者使用http请求的方式 <figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">curl <span class="hljs-params">--request</span> POST \<br>  <span class="hljs-params">--url</span> https:<span class="hljs-string">//yourdomain.com/user/signup</span> \<br>  <span class="hljs-params">--header</span> &#x27;Content-Type: application/json&#x27; \<br>  <span class="hljs-params">--data</span> &#x27;&#123;<br><span class="hljs-string">&quot;email&quot;</span>: <span class="hljs-string">&quot;example@example.com&quot;</span>,<br><span class="hljs-string">&quot;password&quot;</span>: <span class="hljs-string">&quot;example_password&quot;</span>,<br><span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;Example User&quot;</span>,<br><span class="hljs-string">&quot;signup_key&quot;</span>: <span class="hljs-string">&quot;&lt;SIGNUP_KEY&gt;&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure></p><h2 id="客户端">客户端</h2><p>在obsidian仓库打开命令行，然后 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /path/to/vault/.obsidian<br><span class="hljs-built_in">mkdir</span> -p plugins/custom-sync-plugin &amp;&amp; <span class="hljs-built_in">cd</span> plugins/custom-sync-plugin<br>wget https://github.com/acheong08/rev-obsidian-sync-plugin/raw/master/main.js https://github.com/acheong08/rev-obsidian-sync-plugin/raw/master/manifest.json<br></code></pre></td></tr></table></figure> 打开obsidian设置界面，选择第三方插件，启用<code>Custom Native Sync</code> <img src="https://cdn.studyinglover.com/pic/2023/08/0a124be82a4a2fe13b1943ab320c839d.png" alt="image.png" /></p><p>设置服务端地址 <img src="https://cdn.studyinglover.com/pic/2023/08/9b7c177f4b69baed6686fffca3a04df5.png" alt="image.png" /></p><p>同时打开核心插件的同步 <img src="https://cdn.studyinglover.com/pic/2023/08/e3944c723e5b4ea0740f729fdd4a1c73.png" alt="image.png" /> 在点击左侧出现的同步按钮，输入前面设置的账号密码，就可以体验到官方的同步功能了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;自建obsidian同步服务&quot;&gt;自建obsidian同步服务&lt;/h1&gt;
&lt;p&gt;最近GitHub上有这样一个项目&lt;a href=&quot;https://github.com/acheong08/rev-obsidian-sync&quot;&gt;rev-obsidian-sync&lt;/a</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>MediaPipe即将推出图像生成服务</title>
    <link href="https://studyinglover.com/2023/08/23/MediaPipe%E5%8D%B3%E5%B0%86%E6%8E%A8%E5%87%BA%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%9C%8D%E5%8A%A1/"/>
    <id>https://studyinglover.com/2023/08/23/MediaPipe%E5%8D%B3%E5%B0%86%E6%8E%A8%E5%87%BA%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%9C%8D%E5%8A%A1/</id>
    <published>2023-08-23T20:42:00.000Z</published>
    <updated>2023-09-05T01:18:04.356Z</updated>
    
    <content type="html"><![CDATA[<h1 id="mediapipe即将推出图像生成服务">MediaPipe即将推出图像生成服务</h1><p>今天我逛GitHub Trending的时候突然发现MediaPipe的示例库被顶到了前排 <img src="https://cdn.studyinglover.com/pic/2023/08/0bc3379fab3273262e8b6f14799b629a.png" alt="image.png" /></p><p>这不对劲，我赶紧去mediapipe的储存库，发现7个小时前Google推送了新的内容 <a href="https://github.com/google/mediapipe/commit/2ebdb01d4326c934e0628e7ff45cadda6575d23f">ImageGenerator Java API</a> <img src="https://cdn.studyinglover.com/pic/2023/08/b744863d78b3347dc0cfb23c7a0cd29d.png" alt="image.png" /></p><p>原来MediaPipe也要推出文字生成图片内容啊，还是移动端设备上的，这让我想起来GitHub最近有人开始写stable-diffusion.cpp，一个使用了ggml量化加速的sd。</p><p>顺藤摸瓜我们可以找到MediaPipe的<a href="https://developers.google.com/mediapipe/solutions/vision/image_generator">文档</a>。 <img src="https://cdn.studyinglover.com/pic/2023/08/6c50982c58e1d65562e230b0bb601d15.png" alt="image.png" /></p><p>还是即将推出状态，但是给了一个简单示例。</p><p>用法超级简单，就是下载下面几个模型中的一个 - <a href="https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/v1-5-pruned-emaonly.ckpt">runwayml/stable-diffusion-v1-5</a> - <a href="https://huggingface.co/justinpinkney/miniSD/blob/main/miniSD.ckpt">justinpinkney/miniSD</a> - <a href="https://huggingface.co/hakurei/waifu-diffusion-v1-4/blob/main/models/wd-1-3-penultimate-ucg-cont.ckpt">hakurei/waifu-diffusion-v1-4</a> - <a href="https://huggingface.co/Fictiverse/Stable_Diffusion_PaperCut_Model/blob/main/PaperCut_v1.ckpt">Fictiverse/Stable_Diffusion_PaperCut_Model</a></p><p>安装依赖 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install torch typing_extensions numpy Pillow requests pytorch_lightning absl-py<br></code></pre></td></tr></table></figure> 把这个文件copy下来,<a href="https://github.com/googlesamples/mediapipe/blob/main/tools/image_generator_converter/convert.py">地址</a></p><p>然后 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 convert.py --ckpt_path &lt;ckpt_path&gt; --output_path &lt;output_path&gt;<br></code></pre></td></tr></table></figure></p><p>接着将文件夹内容<code>&lt;output_path&gt;</code>推送到 Android 设备。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">adb shell <span class="hljs-built_in">rm</span> -r /data/local/tmp/image_generator/ <br><br>adb shell <span class="hljs-built_in">mkdir</span> -p /data/local/tmp/image_generator/<br><br>adb push &lt;output_path&gt;/. /data/local/tmp/image_generator/bins<br></code></pre></td></tr></table></figure> 安装 Android 演示应用程序,在<a href="https://storage.googleapis.com/mediapipe-tasks/image_generator/imagegenerator.apk">这里</a>下载 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">adb install imagegenerator.apk<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;mediapipe即将推出图像生成服务&quot;&gt;MediaPipe即将推出图像生成服务&lt;/h1&gt;
&lt;p&gt;今天我逛GitHub Trending的时候突然发现MediaPipe的示例库被顶到了前排 &lt;img src=&quot;https://cdn.studyinglover.c</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Dual-Stream Diffusion Net for Text-to-Video Generation笔记</title>
    <link href="https://studyinglover.com/2023/08/23/DSDN%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/08/23/DSDN%E7%AC%94%E8%AE%B0/</id>
    <published>2023-08-23T10:32:00.000Z</published>
    <updated>2023-09-05T01:18:04.356Z</updated>
    
    <content type="html"><![CDATA[<h1 id="dual-stream-diffusion-net-for-text-to-video-generation笔记">Dual-Stream Diffusion Net for Text-to-Video Generation笔记</h1><p>这篇论文提出的模型架构是Dual-Stream Diffusion Net（DSDN），它是一种双流扩散网络。</p><figure><img src="https://cdn.studyinglover.com/pic/2023/08/3021b6624ee4f2093c6166b6a80cd643.png" alt="" /><figcaption>image.png</figcaption></figure><p>首先，视频内容通过一个一个编码器编码成内容特征和一个动作编码器编码成动作特征，并通过一个增量学习模块进行更新。前向扩散过程没有使用DDPM而是使用了 Hierarchical Text-Conditional Image Generation with CLIP Latents 这篇论文提出的方法。</p><p>为了对齐生成的内容和运动，设计了一个双流转换交互模块来通过交叉注意力实现两个分支之间的信息交互和对齐。</p><p>最后引入了运动合成器来简化运动信息的操作。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;dual-stream-diffusion-net-for-text-to-video-generation笔记&quot;&gt;Dual-Stream Diffusion Net for Text-to-Video Generation笔记&lt;/h1&gt;
&lt;p&gt;这篇论文提出的模型</summary>
      
    
    
    
    <category term="笔记" scheme="https://studyinglover.com/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="文字生成图片" scheme="https://studyinglover.com/tags/%E6%96%87%E5%AD%97%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>ViT在DDPM取代UNet(DiT)</title>
    <link href="https://studyinglover.com/2023/08/20/ViT%E5%9C%A8DDPM%E5%8F%96%E4%BB%A3UNet(DiT)/"/>
    <id>https://studyinglover.com/2023/08/20/ViT%E5%9C%A8DDPM%E5%8F%96%E4%BB%A3UNet(DiT)/</id>
    <published>2023-08-20T09:43:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="vit在ddpm取代unetdit">ViT在DDPM取代UNet(DiT)</h1><p><a href="https://www.wpeebles.com/DiT.html">项目主页</a></p><p>这篇论文主要是尝试使用ViT取代DDPM中的UNet，叫做Diffusion Transformer-DiT，作者训练了DiT-S、DiT-B、DiT-L 和 DiT-XL四种模型，每种模型的patch取8,4,2, 一共训练了12个模型。</p><p>作者探索的完整 DiT 设计空间是补丁大小、变压器块架构和模型大小。</p><p>模型第一层是对 sequences of patches 进行操作(就是ViT把图片看成<span class="math inline">\(16*16\)</span>的的单词之后单词构成的序列) 。 <img src="https://cdn.studyinglover.com/pic/2023/08/d9b9a168f177471d890c1bd3e3f2cc2d.png" alt="image.png" /></p><p>如图所示，给定的patch是<span class="math inline">\(p\times p\)</span> ,VAE采样出来的噪声大小是<span class="math inline">\(I\times I\times C\)</span> ,那么patches会变成长度为<span class="math inline">\(T=(I/\hat{p})^{2}\)</span> 的一个序列,每个patch维度是<span class="math inline">\(d\)</span> ,位置嵌入用的是sine-cosine。</p><p>接下来就是diffusion transformers的设计。 <img src="https://cdn.studyinglover.com/pic/2023/08/f68c4f271029a484e97822dbb9fb2569.png" alt="image.png" /></p><p>作者提到了一点，就是获取到path序列之后应该在后面加上去噪步数和类别标签，并在最后一个DiT块之后删掉。</p><p>在最终的 DiT 块之后，需要将输出解码为噪声预测和对角协方差预测。这两个输出的形状都等于整个模型的输入。作者使用标准线性解码器来做到这一点。如果使用 adaLN 自适应就应用最后一层范数，并将每个标记线性解码为 <span class="math inline">\(p\times p\times2C\)</span> 张量，其中 <span class="math inline">\(C\)</span> 是输入到DiT的空间大小。最后，将解码的token重新排列到其原始空间布局中，得到预测的噪声和协方差。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;vit在ddpm取代unetdit&quot;&gt;ViT在DDPM取代UNet(DiT)&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://www.wpeebles.com/DiT.html&quot;&gt;项目主页&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这篇论文主要是尝试使用ViT取代DDPM中的UNe</summary>
      
    
    
    
    <category term="笔记" scheme="https://studyinglover.com/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="文字生成图片" scheme="https://studyinglover.com/tags/%E6%96%87%E5%AD%97%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>arch4edu搞崩了我的flutter</title>
    <link href="https://studyinglover.com/2023/08/19/arch4edu%E6%90%9E%E5%B4%A9%E4%BA%86%E6%88%91%E7%9A%84flutter/"/>
    <id>https://studyinglover.com/2023/08/19/arch4edu%E6%90%9E%E5%B4%A9%E4%BA%86%E6%88%91%E7%9A%84flutter/</id>
    <published>2023-08-19T21:36:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="arch4edu搞崩了我的flutter">arch4edu搞崩了我的flutter</h1><p>今天是快乐的一天，适合滚包 <figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">yay</span><br></code></pre></td></tr></table></figure> 一切安好，arch4edu说我的flutter需要更新 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">==&gt; 要排除的包: (示例: <span class="hljs-string">&quot;1 2 3&quot;</span>, <span class="hljs-string">&quot;1-3&quot;</span>, <span class="hljs-string">&quot;^4&quot;</span> 或软件库名称)<br> -&gt; 排除软件包可能会导致不完整的升级并破坏系统<br>==&gt; <br><br></code></pre></td></tr></table></figure> 没什么需要排除的，接下来就是愉快的自动安装</p><p>突然我看到了这个</p><figure><img src="https://cdn.studyinglover.com/pic/2023/08/d257220b6c5bc01465f92fdd72320344.png" alt="" /><figcaption>image.png</figcaption></figure><p>警告啦，没啥好担心的啦，待会跑一下看好着没</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">flutter doctor                     <br>Found an existing Pub cache at /home/zjh/.pub-cache.<br>It can be repaired by running `dart pub cache repair`.<br>It can be reset by running `dart pub cache clean`.<br>Found an existing Dart Analysis Server cache at /home/zjh/.dartServer.<br>It can be reset by deleting /home/zjh/.dartServer.<br>Flutter failed to write to a file at <span class="hljs-string">&quot;/opt/flutter/packages/flutter_tools/.dart_tool/version&quot;</span>.<br>Please ensure that the SDK and/or project is installed <span class="hljs-keyword">in</span> a location that has <span class="hljs-built_in">read</span>/write<br>permissions <span class="hljs-keyword">for</span> the current user.<br>Try running:<br>  sudo <span class="hljs-built_in">chown</span> -R $(<span class="hljs-built_in">whoami</span>) /opt/flutter/packages/flutter_tools/.dart_tool/version<br><br></code></pre></td></tr></table></figure><p>好的他炸了</p><p>看着问题不大，就是读写权限的问题，的问题？鬼知道会有啥问题，我决定让arch4edu滚蛋</p><p>先<code>sudo pacman -Rns flutter</code>把arch4edu的flutter删掉，然后去<code>/etc/pacman.conf</code> 删除了arch4edu镜像，再<code>sudo pacman -Syu</code>滚一遍包，最后<code>yay flutter</code></p><p>中间会有一个问题 <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">错误：无法提交处理 (有冲突的文件)<br>flutter: 文件系统中已存在 <span class="hljs-regexp">/opt/</span>flutter<span class="hljs-regexp">/bin/</span>cache/flutter_version_check.stamp <br>发生错误，没有软件包被更新。<br></code></pre></td></tr></table></figure> ok,sudo直接删就行，反正是cache</p><p>最后<code>flutter docker</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">Doctor summary (to see all details, run flutter doctor -v):<br>[✓] Flutter (Channel stable, 3.13.0, on Arch Linux 6.4.10-arch1-1, locale zh_CN.UTF-8)<br>[✓] Android toolchain - develop <span class="hljs-keyword">for</span> Android devices (Android SDK version 34.0.0)<br>[✓] Chrome - develop <span class="hljs-keyword">for</span> the web<br>[✓] Linux toolchain - develop <span class="hljs-keyword">for</span> Linux desktop<br>[✓] Android Studio (version 2022.2)<br>[✓] Connected device (2 available)<br>[✓] Network resources<br><br>• No issues found!<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;arch4edu搞崩了我的flutter&quot;&gt;arch4edu搞崩了我的flutter&lt;/h1&gt;
&lt;p&gt;今天是快乐的一天，适合滚包 &lt;figure class=&quot;highlight ebnf&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>LISA(推理分割)笔记</title>
    <link href="https://studyinglover.com/2023/08/18/LISA(%E6%8E%A8%E7%90%86%E5%88%86%E5%89%B2)%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/08/18/LISA(%E6%8E%A8%E7%90%86%E5%88%86%E5%89%B2)%E7%AC%94%E8%AE%B0/</id>
    <published>2023-08-18T15:05:00.000Z</published>
    <updated>2023-09-05T01:18:04.356Z</updated>
    
    <content type="html"><![CDATA[<h1 id="lisa推理分割笔记">LISA(推理分割)笔记</h1><h2 id="简介">简介</h2><p>这篇论文题目中文翻译是 基于大型语言模型的语义分割， 提出了一个新任务-推理分割。大概就是给一张图和一段话，模型使用大语言模型分割出目标。作者给了一个例子，从图片中分割出富含维生素C的物品。</p><p>作者说这篇论文有三个贡献，提出了推理分割的任务，建立了一个推理分割基准，ReasonSeg， 还有训练了一个模型。</p><p>项目主页<a href="https://github.com/dvlab-research/LISA">GitHub</a></p><p>LISA可以完成四种任务 1) complex reasoning; 2) world knowledge; 3) explanatory answers; 4) multi-turn conversation</p><h2 id="模型架构">模型架构</h2><h3 id="生成mask">生成mask</h3><p>这里作者提出了一些问题，就是大部分llm是不具备视觉能力，有视觉能力的泛化型不好还不好训练。相比之下，训练 LISA-7B 在 8 个 NVIDIA 24G 3090 GPU 上只需要 10,000 个训练步骤。(嗯8块3090)</p><p><img src="https://cdn.studyinglover.com/pic/2023/08/ded90e7e3f84739b187dd679c39bd8dd.png" alt="image.png" /> 模型结构就是上面这张图，右下角标了火花的就说明是需要训练或者微调的。首先扩充词表，加入<code>&lt;SEG&gt;</code> ,接下来给出一张图片<span class="math inline">\(x_{img}\)</span>和一段文本<span class="math inline">\(x_{txt}\)</span>, 将他们送入大语言模型<span class="math inline">\(\mathcal{F}\)</span> ,写成公式就是<span class="math display">\[\hat{\boldsymbol{y}}_{txt}=\mathcal{F}(x_{img},\boldsymbol{x}_{txt}).\]</span> 当LLM倾向于生成二进制分割掩码时，输出<span class="math inline">\(\hat{\boldsymbol{y}}_{txt}\)</span>应该包含一个<code>&lt;SEG&gt;</code>令牌。所以提取最后一层嵌入<span class="math inline">\(\hat{h}_{seg}\)</span> (因为他和<code>&lt;SEG&gt;</code> token 是相关的)， 并用一个MLP <span class="math inline">\(\gamma\)</span> 将其投影到<span class="math inline">\(h_{seg}\)</span>。</p><p>同时，视觉编码器<span class="math inline">\(\mathcal{F_{enc}}\)</span> 会从图片中提取出视觉特征<span class="math inline">\(\text{f}\)</span> 。</p><p>最后<span class="math inline">\(h_{seg}\)</span>和<span class="math inline">\(\text{f}\)</span> 会被送入一个和SAM有相同架构的解码器，获得最后的mask.</p><p>整个过程表示出来就是<span class="math display">\[\begin{gathered}\boldsymbol{h}_{seg}=\gamma(\hat{\boldsymbol{h}}_{seg}),\quad\boldsymbol{f}=\mathcal{F}_{enc}(\boldsymbol{x}_{img}),\\\hat{\boldsymbol{M}}=\mathcal{F}_{dec}(\boldsymbol{h}_{seg},\boldsymbol{f}).\end{gathered}\]</span> ### 训练目标 训练目标是文本生成损失 <span class="math inline">\(\mathcal{L}_{txt}\)</span> 和分割掩码损失 <span class="math inline">\(\mathcal{L}_{mask}\)</span> 进行端到端训练。总体目标 <span class="math inline">\(L\)</span> 是这些损失的加权和，由 <span class="math inline">\(\lambda_{txt}\)</span> 和 <span class="math inline">\(\lambda_{mask}\)</span> 确定<span class="math display">\[\mathcal{L}=\lambda_{txt}\mathcal{L}_{txt}+\lambda_{mask}\mathcal{L}_{mask}.\]</span> ## 训练 ### 数据集 训练数据由三部分组成，都是开源数据集 1. Semantic Segmentation Dataset 2. Vanilla Referring Segmentation Dataset 3. Visual Question Answering Dataset</p><p><strong>值得注意的是，LISA具有zero-shot能力，因为训练集不包含任何推理分割的内容。</strong></p><h3 id="需要训练的参数">需要训练的参数</h3><p>为了保持llm的泛化能力作者用了lora,解码器可以被微调，llm的词嵌入和投影最后一层潜入的mlp也可以微调</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;lisa推理分割笔记&quot;&gt;LISA(推理分割)笔记&lt;/h1&gt;
&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;这篇论文题目中文翻译是 基于大型语言模型的语义分割， 提出了一个新任务-推理分割。大概就是给一张图和一段话，模型使用大语言模型分割出目标。作者给了一个例子，从</summary>
      
    
    
    
    <category term="笔记" scheme="https://studyinglover.com/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="多模态" scheme="https://studyinglover.com/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>在终端绘制GPU显存使用曲线</title>
    <link href="https://studyinglover.com/2023/08/13/%E5%9C%A8%E7%BB%88%E7%AB%AF%E7%BB%98%E5%88%B6GPU%E6%98%BE%E5%AD%98%E4%BD%BF%E7%94%A8%E6%9B%B2%E7%BA%BF/"/>
    <id>https://studyinglover.com/2023/08/13/%E5%9C%A8%E7%BB%88%E7%AB%AF%E7%BB%98%E5%88%B6GPU%E6%98%BE%E5%AD%98%E4%BD%BF%E7%94%A8%E6%9B%B2%E7%BA%BF/</id>
    <published>2023-08-13T11:44:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="在终端绘制gpu显存使用曲线">在终端绘制GPU显存使用曲线</h1><p>这个东西的灵感来自于写torch的时候想实时看到loss和gpu使用情况，突然想到可以在终端实时显示，经过与ai的一番激烈讨，最终有了这个代码。</p><p>我们首先要获取GPU的显存使用数据，先检查是否安装了<code>nvidia-smi</code>, 在终端输入有正常输出即可。</p><p>首先导入所有需要的库 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> subprocess<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> asciichartpy<br><span class="hljs-keyword">import</span> platform<br></code></pre></td></tr></table></figure></p><p>通过<code>nvidia-smi</code> 的命令获取已经使用的显存和所有现存 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_gpu_used_memory</span>():<br>output = subprocess.check_output([<span class="hljs-string">&#x27;nvidia-smi&#x27;</span>, <span class="hljs-string">&#x27;--query-gpu=memory.used&#x27;</span>, <span class="hljs-string">&#x27;--format=csv,nounits&#x27;</span>])<br>output = output.decode(<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>lines = output.strip().split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>used_memory = <span class="hljs-built_in">int</span>(lines[<span class="hljs-number">1</span>])<br><span class="hljs-keyword">return</span> used_memory<br>  <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_gpu_total_memory</span>():<br>output = subprocess.check_output([<span class="hljs-string">&#x27;nvidia-smi&#x27;</span>, <span class="hljs-string">&#x27;--query-gpu=memory.total&#x27;</span>, <span class="hljs-string">&#x27;--format=csv,nounits&#x27;</span>])<br>output = output.decode(<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>lines = output.strip().split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>total_memory = <span class="hljs-built_in">int</span>(lines[<span class="hljs-number">1</span>])<br><span class="hljs-keyword">return</span> total_memory<br></code></pre></td></tr></table></figure></p><p><code>asciichartpy</code> 是一个 Python 库，用于在终端中绘制 ASCII 图表。我们用他来在终端绘制图标。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">draw_gpu_memory</span>(<span class="hljs-params">gpu_memory_history</span>):<br>    used_memory = get_gpu_used_memory()<br>    total_memory = get_gpu_total_memory()<br><br>    used_percentage = used_memory / total_memory * <span class="hljs-number">100</span><br>    gpu_memory_history.append(used_percentage)<br><br>    <span class="hljs-comment"># 绘制字符图表</span><br>    chart = asciichartpy.plot(gpu_memory_history, &#123;<span class="hljs-string">&#x27;height&#x27;</span>: <span class="hljs-number">20</span>, <span class="hljs-string">&#x27;width&#x27;</span>: <span class="hljs-number">10</span>, <span class="hljs-string">&#x27;timestamp&#x27;</span>: <span class="hljs-literal">True</span>&#125;)<br>    <br>    <span class="hljs-comment"># 清空终端屏幕</span><br>    <span class="hljs-keyword">if</span> platform.system() == <span class="hljs-string">&#x27;Windows&#x27;</span>:<br>        subprocess.call(<span class="hljs-string">&#x27;cls&#x27;</span>, shell=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">else</span>:<br>        subprocess.call(<span class="hljs-string">&#x27;clear&#x27;</span>, shell=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-built_in">print</span>(chart)<br></code></pre></td></tr></table></figure></p><p>最后运行上面的代码 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    <span class="hljs-keyword">try</span>:<br>        gpu_memory_history = []<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            draw_gpu_memory(gpu_memory_history)<br>            time.sleep(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">except</span> KeyboardInterrupt:<br>        <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure> 运行效果 <img src="https://cdn.studyinglover.com/pic/2023/08/c320d69a8169e36fab4c82f1725c298b.png" alt="image.png" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;在终端绘制gpu显存使用曲线&quot;&gt;在终端绘制GPU显存使用曲线&lt;/h1&gt;
&lt;p&gt;这个东西的灵感来自于写torch的时候想实时看到loss和gpu使用情况，突然想到可以在终端实时显示，经过与ai的一番激烈讨，最终有了这个代码。&lt;/p&gt;
&lt;p&gt;我们首先要获取GPU的显存</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>GPTBot介绍</title>
    <link href="https://studyinglover.com/2023/08/11/GPTBot%E4%BB%8B%E7%BB%8D/"/>
    <id>https://studyinglover.com/2023/08/11/GPTBot%E4%BB%8B%E7%BB%8D/</id>
    <published>2023-08-11T20:58:00.000Z</published>
    <updated>2023-09-05T01:18:04.356Z</updated>
    
    <content type="html"><![CDATA[<h1 id="gptbot介绍">GPTBot介绍</h1><p>最近，openai公布了<a href="https://platform.openai.com/docs/gptbot/gptbot">GPTBot</a> 的相关信息，并给出了禁止GPTBot的方法。以下是全文翻译。</p><p>GPTBot是OpenAI的网络爬虫，可以通过以下User agent和字符串来识别。 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">User</span> agent token: GPTBot<br><span class="hljs-attribute">Full</span> user-agent string: Mozilla/<span class="hljs-number">5</span>.<span class="hljs-number">0</span> AppleWebKit/<span class="hljs-number">537</span>.<span class="hljs-number">36</span> (KHTML, like Gecko; compatible; GPTBot/<span class="hljs-number">1</span>.<span class="hljs-number">0</span>; +https://openai.com/gptbot)<br></code></pre></td></tr></table></figure></p><h2 id="使用">使用</h2><p>使用 GPTBot 用户代理爬取的网页可能会用于改进未来的模型，并且会过滤掉需要付费访问、已知收集个人身份信息（PII）或含有违反我们政策的文本的来源。允许 GPTBot 访问您的网站可以帮助 AI 模型变得更准确，提高它们的一般能力和安全性。在下面，我们还分享了如何禁止 GPTBot 访问您的网站。</p><h3 id="禁止-gptbot">禁止 GPTBot</h3><p>要禁止 GPTBot 访问您的网站，您可以将 GPTBot 添加到您网站的 robots.txt： <figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs http"><span class="hljs-attribute">User-agent</span><span class="hljs-punctuation">: </span>GPTBot<br><span class="hljs-attribute">Disallow</span><span class="hljs-punctuation">: </span>/<br></code></pre></td></tr></table></figure></p><h3 id="自定义-gptbot-访问">自定义 GPTBot 访问</h3><p>要允许 GPTBot 仅访问您网站的部分内容，您可以将 GPTBot 令牌添加到您网站的 robots.txt，如下所示： <figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arcade">User-agent: GPTBot<br>Allow: <span class="hljs-regexp">/directory-1/</span><br>Disallow: <span class="hljs-regexp">/directory-2/</span><br></code></pre></td></tr></table></figure></p><h3 id="ip-出口范围">IP 出口范围</h3><p>对于 OpenAI 的爬虫，它会从 <a href="https://openai.com/gptbot-ranges.txt">OpenAI 网站</a>上记录的 IP 地址段向网站发出请求。</p><p>这里我给出IP 地址段 <figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">20.15.240.64</span>/<span class="hljs-number">28</span><br><span class="hljs-number">20.15.240.80</span>/<span class="hljs-number">28</span><br><span class="hljs-number">20.15.240.96</span>/<span class="hljs-number">28</span><br><span class="hljs-number">20.15.240.176</span>/<span class="hljs-number">28</span><br><span class="hljs-number">20.15.241.0</span>/<span class="hljs-number">28</span><br><span class="hljs-number">20.15.242.128</span>/<span class="hljs-number">28</span><br><span class="hljs-number">20.15.242.144</span>/<span class="hljs-number">28</span><br><span class="hljs-number">20.15.242.192</span>/<span class="hljs-number">28</span><br><span class="hljs-number">40.83.2.64</span>/<span class="hljs-number">28</span><br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;gptbot介绍&quot;&gt;GPTBot介绍&lt;/h1&gt;
&lt;p&gt;最近，openai公布了&lt;a href=&quot;https://platform.openai.com/docs/gptbot/gptbot&quot;&gt;GPTBot&lt;/a&gt; 的相关信息，并给出了禁止GPTBot的方法。以下是</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>arch蓝牙无法连接</title>
    <link href="https://studyinglover.com/2023/08/10/arch%E8%93%9D%E7%89%99%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5/"/>
    <id>https://studyinglover.com/2023/08/10/arch%E8%93%9D%E7%89%99%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5/</id>
    <published>2023-08-10T17:18:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="arch蓝牙无法连接">arch蓝牙无法连接</h1><p>在arcchlinux成功安装并且已经安装蓝牙的相关包之后，在设置打开蓝牙发现需要先开启蓝牙。</p><p>没啥好的解决办法，运行 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">systemctl <span class="hljs-built_in">enable</span>  --now bluetooth <br></code></pre></td></tr></table></figure> 问题解决。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;arch蓝牙无法连接&quot;&gt;arch蓝牙无法连接&lt;/h1&gt;
&lt;p&gt;在arcchlinux成功安装并且已经安装蓝牙的相关包之后，在设置打开蓝牙发现需要先开启蓝牙。&lt;/p&gt;
&lt;p&gt;没啥好的解决办法，运行 &lt;figure class=&quot;highlight bash&quot;&gt;&lt;ta</summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>GPU部署llama-cpp-python(llama.cpp通用)</title>
    <link href="https://studyinglover.com/2023/08/06/GPU%E9%83%A8%E7%BD%B2llama-cpp-python(llama.cpp%E9%80%9A%E7%94%A8)/"/>
    <id>https://studyinglover.com/2023/08/06/GPU%E9%83%A8%E7%BD%B2llama-cpp-python(llama.cpp%E9%80%9A%E7%94%A8)/</id>
    <published>2023-08-06T23:01:00.000Z</published>
    <updated>2023-09-05T01:18:04.356Z</updated>
    
    <content type="html"><![CDATA[<h1 id="gpu部署llama-cpp-pythonllama.cpp通用">GPU部署llama-cpp-python(llama.cpp通用)</h1><h2 id="通用流程">通用流程</h2><p>我们的安装平台是Ubuntu20.04，Python 3.8.10，cuda 11.6。</p><p>首先确保自己是否已经安装了cuda,输入 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc -V<br></code></pre></td></tr></table></figure></p><p>有类似下面的输出即可 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">nvcc</span>: NVIDIA (R) Cuda compiler driver<br><span class="hljs-attribute">Copyright</span> (c) <span class="hljs-number">2005</span>-<span class="hljs-number">2021</span> NVIDIA Corporation<br><span class="hljs-attribute">Built</span> <span class="hljs-literal">on</span> Fri_Dec_17_18:<span class="hljs-number">16</span>:<span class="hljs-number">03</span>_PST_2021<br><span class="hljs-attribute">Cuda</span> compilation tools, release <span class="hljs-number">11</span>.<span class="hljs-number">6</span>, V11.<span class="hljs-number">6</span>.<span class="hljs-number">55</span><br><span class="hljs-attribute">Build</span> cuda_11.<span class="hljs-number">6</span>.r11.<span class="hljs-number">6</span>/compiler.<span class="hljs-number">30794723</span>_0<br></code></pre></td></tr></table></figure></p><p>我们选用 <code>cuBLAS</code> 加速后端代理。直接按照下面命令安装 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> LLAMA_CUBLAS=1<br>CMAKE_ARGS=<span class="hljs-string">&quot;-DLLAMA_CUBLAS=on&quot;</span> FORCE_CMAKE=1 pip install llama-cpp-python<br></code></pre></td></tr></table></figure></p><p>不出意外的话就安装好了，但是你会出现很多意外，请你努力在一堆红色的报错中找出关键出错点，然后搜索，在最后我给出了几个我遇到的。</p><h2 id="运行">运行</h2><p>运行和CPU直接运行相似，只是需要加入几个参数. <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 -m llama_cpp.server --model llama-2-70b-chat.ggmlv3.q5_K_M.bin --n_threads 30 --n_gpu_layers 200<br></code></pre></td></tr></table></figure></p><p><code>n_threads</code> 是一个CPU也有的参数，代表最多使用多少线程。</p><p><code>n_gpu_layers</code> 是一个GPU部署非常重要的一步，代表大语言模型有多少层在GPU运算，如果你的显存出现 <code>out of memory</code> 那就减小 <code>n_gpu_layers</code></p><h2 id="关于多卡">关于多卡</h2><p>亲测多卡没有遇到什么大坑，只要<code>torch.cuda.is_available()</code> 和<code>torch.cuda.device_count()</code>正常就可以跑起来。</p><p>两张 Tesla T4 的卡推理70B大概半分钟就可以出结果。</p><h2 id="报错解决">报错解决</h2><h3 id="check-for-working-cuda-compiler-usrlocalcudabinnvcc---skipped">Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped</h3><p>参考 https://github.com/ggerganov/llama.cpp/issues/1832 系统安装过程中没找到你的cuda在哪里，所以在pip安装之前先设置一个环境变量,<strong>把/usr/local/cuda-x.y改成你的cuda路径</strong> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> CUDA_PATH=/usr/local/cuda-x.y<br></code></pre></td></tr></table></figure></p><h3 id="f16c-expected-a-number">'f16c': expected a number</h3><p>这是你的cuda版本太低了，升级到较新版本(11.6可用)。</p><p>或者参考 https://github.com/ggerganov/llama.cpp/issues/1467 和 https://github.com/marella/ctransformers/issues/53 中提到的命令和构建(我没有尝试，有谁试了可以请我结果)。</p><h3 id="value-sm_30-is-not-defined-for-option-gpu-name-tesla-t">Value 'sm_30' is not defined for option 'gpu-name' Tesla T</h3><p>先运行下面的命令 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">apt-cache policy nvidia-cuda-toolkit<br></code></pre></td></tr></table></figure> 如果版本是<strong>1.0</strong> 那么请运行 <code>sudo apt remove nvidia-cuda-toolkit</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;gpu部署llama-cpp-pythonllama.cpp通用&quot;&gt;GPU部署llama-cpp-python(llama.cpp通用)&lt;/h1&gt;
&lt;h2 id=&quot;通用流程&quot;&gt;通用流程&lt;/h2&gt;
&lt;p&gt;我们的安装平台是Ubuntu20.04，Python 3.8.</summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>花式求GCD</title>
    <link href="https://studyinglover.com/2023/08/02/%E8%8A%B1%E5%BC%8F%E6%B1%82GCD/"/>
    <id>https://studyinglover.com/2023/08/02/%E8%8A%B1%E5%BC%8F%E6%B1%82GCD/</id>
    <published>2023-08-02T18:46:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="花式求gcd">花式求GCD</h1><p>今天学校实验室纳新群有同学提到了<code>a^=b^=a^=b​</code> 交换两个数的操作，我突然想到之前在知乎看到通过异或实现gcd的方法，一番翻找后没啥结果，便去问了下认识的oi大佬有没有一行求gcd的算法。</p><p>大佬很快给出了一个函数<code>int gcd(int a,int b)&#123;return y?gcd(y,x%y):x;&#125;</code> 真的就是一行，完整的代码就是下面这个</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">gcd</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> </span>&#123; <span class="hljs-keyword">return</span> y ? <span class="hljs-built_in">gcd</span>(y, x % y) : x; &#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-type">int</span> a,b;<br>a=<span class="hljs-number">10</span>;<br>b=<span class="hljs-number">20</span>;<br>a = <span class="hljs-built_in">gcd</span>(a,b);<br>cout&lt;&lt;a&lt;&lt;endl;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>但是我一像不对啊，我的异或呢？我又问了一下，大佬给了我一个截图 <img src="https://cdn.studyinglover.com/pic/2023/08/07b57e65da92d9c19bb82d740132f07c.png" /></p><p>就是这个神奇的写法</p><p>这段代码的实现方式是，使用异或运算符（^）和取模运算符（%）来交换变量a和b的值。具体来说，代码中的while循环会一直执行，直到b的值为0为止。在每次循环中，代码会先将a对b取模，然后将结果赋值给a，接着将b对a取模，然后将结果赋值给b，最后使用异或运算符交换a和b的值。这样，当循环结束时，a和b的值就被成功地交换了。(来自copilot chat)</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-type">int</span> a,b;<br>a=<span class="hljs-number">10</span>;<br>b=<span class="hljs-number">20</span>;<br><span class="hljs-keyword">while</span>(b^=a^=b^=a%=b);<br>cout&lt;&lt;a&lt;&lt;endl;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;花式求gcd&quot;&gt;花式求GCD&lt;/h1&gt;
&lt;p&gt;今天学校实验室纳新群有同学提到了&lt;code&gt;a^=b^=a^=b​&lt;/code&gt; 交换两个数的操作，我突然想到之前在知乎看到通过异或实现gcd的方法，一番翻找后没啥结果，便去问了下认识的oi大佬有没有一行求gcd的算法</summary>
      
    
    
    
    
    <category term="算法" scheme="https://studyinglover.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>使用llama构建一个蜜罐(前端)</title>
    <link href="https://studyinglover.com/2023/08/01/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%89%8D%E7%AB%AF)/"/>
    <id>https://studyinglover.com/2023/08/01/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%89%8D%E7%AB%AF)/</id>
    <published>2023-08-01T00:12:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用llama构建一个蜜罐前端">使用llama构建一个蜜罐(前端)</h1><p><img src="https://cdn.studyinglover.com/pic/2023/07/e9a49d4a404ed9bc4b0f119249194e3d.png" /> 在<a href="https://studyinglover.com/2023/07/29/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%90%8E%E7%AB%AF)/">使用llama构建一个蜜罐(后端)</a> 中我们通过llama和flask构建了一个蜜罐的后端，通过将shell命令作为字段的一部分，让llama假装执行命令来防止蜜罐被攻破。那有了后端我们还需要一个前端命令行来让用户登陆并执行命令。</p><p>完整项目开源在了<a href="https://github.com/StudyingLover/llama-honeypot-python">GitHub</a></p><p>接下来，让我们来实现一个模拟ssh服务器，或者说实现一个ssh mock 然后执行命令的时候不让他真的执行同时改一下输出。</p><p><strong>等等？我们真的需要一个ssh mock 吗？</strong> 还是说，我们需要的是一个<strong>跑在终端的，长得很像终端的，能输入输出的，一个可交互的代码？</strong></p><p>哦，好像我们需要的只是一个可交互的代码，难道攻击方ssh上来了还能验证一下这是不是真的是终端？(我用了三天才想通这个问题)</p><p>so,工作量一下子减少了太多了 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> requests<br>  <br><span class="hljs-comment"># 禁用 Ctrl Z stty susp undef</span><br><span class="hljs-comment"># 启用 Ctrl Z stty susp ^Z</span><br><br>admin_key = <span class="hljs-string">&quot;123456&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_responce</span>(<span class="hljs-params">command</span>):<br><span class="hljs-keyword">if</span> (command == admin_key):<br>exit()<br>output = requests.post(<span class="hljs-string">&quot;http://127.0.0.1:9000/admin/&quot;</span>+command).json()<br><span class="hljs-keyword">return</span> output[<span class="hljs-string">&quot;message&quot;</span>]<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">attact_warning</span>():<br><span class="hljs-keyword">pass</span><br>  <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">anti_attact</span>():<br><span class="hljs-keyword">pass</span><br>  <br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>attact_warning()<br>anti_attact()<br><span class="hljs-keyword">try</span>:<br>command = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;[root@ubuntu ~]$ &quot;</span>)<br><span class="hljs-built_in">print</span>(get_responce(command))<br>  <br><span class="hljs-keyword">except</span> KeyboardInterrupt:<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span>)<br></code></pre></td></tr></table></figure></p><p>这里有几个点需要注意 1. 代码<strong>不能直接用于生产环境！！！请先完善细节并大量测试。本项目仅为学习使用，未经过专业人员测试</strong> 1. <code>admin_key</code>，这个变量的作用是让管理员能用终端，<strong>记得修改</strong>。如果你认为这种方法太low了或者可能被作为突破口，请修改或PR。 2. 接口地址，我这里是<code>http://127.0.0.1:9000/admin/</code> ，这里需要改成你的，建议先用postman或者apifox或者啥的测一下。 3. 入侵检测和反击模块需要你<strong>自己实现</strong>，毕竟这只是一个让你的蜜罐更安全的项目。</p><p>在三个终端分别运行llama服务器(图右终端)，蜜罐后端(图左终端)和蜜罐前端(图中终端)</p><figure><img src="https://cdn.studyinglover.com/pic/2023/07/dd31f63365b8a8657b1459f7fe883a36.png" alt="" /><figcaption>image.png</figcaption></figure><p>项目还有很多改进之处，在后面我也会进一步优化prompt和模型来获得更好的终端对话体验。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;使用llama构建一个蜜罐前端&quot;&gt;使用llama构建一个蜜罐(前端)&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.studyinglover.com/pic/2023/07/e9a49d4a404ed9bc4b0f119249194e3d.png&quot;</summary>
      
    
    
    
    
    <category term="网络安全" scheme="https://studyinglover.com/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>使用llama构建一个蜜罐(后端)</title>
    <link href="https://studyinglover.com/2023/07/29/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%90%8E%E7%AB%AF)/"/>
    <id>https://studyinglover.com/2023/07/29/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%90%8E%E7%AB%AF)/</id>
    <published>2023-07-29T17:52:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用llama构建一个蜜罐后端">使用llama构建一个蜜罐(后端)</h1><p><img src="https://cdn.studyinglover.com/pic/2023/07/e9a49d4a404ed9bc4b0f119249194e3d.png" /></p><p>完整项目开源在了<a href="https://github.com/StudyingLover/llama-honeypot-python">GitHub</a></p><p>众所周知，蜜罐是一个很有趣的东西，他是一种网络安全机制，旨在诱使攻击者攻击虚假的系统或应用程序，以便安全专业人员可以监视攻击者的行为并收集攻击者的信息。蜜罐通常是一台虚拟机或一台计算机，它看起来像一个真实的系统，但实际上是一个特意构建的系统，用于诱骗攻击者。攻击者在攻击蜜罐时，安全专业人员可以收集攻击者的信息，例如攻击者使用的工具、攻击者的IP地址、攻击者的攻击技术等等。这些信息可以帮助安全专业人员更好地了解攻击者的行为和意图，并采取相应的措施来保护真实的系统。</p><p>但是缺点很明显，不管我怎么做蜜罐终究是跑在真实的服务器上的，还是很可能被攻破，所以，我们能不能让ai模仿一个linux主机作为蜜罐？</p><p>今天早上看到了这个视频 https://b23.tv/pXiGNIK ， 他开源了一个使用chatGPT作为终端的代码，开源在<a href="gitee.com/cutecuteyu/chatgpt-honeypot">gitee</a> ，不幸的是我openai账户没钱了，但是，昨天我才写了<a href="https://studyinglover.com/2023/07/28/llama-cpp-python%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/#%E6%90%AD%E5%BB%BA%E4%B8%8Eopenai%E6%8E%A5%E5%8F%A3%E5%85%BC%E5%AE%B9%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A5%E5%8F%A3">搭建与openai接口兼容的服务器接口</a>, 那么我就可以改造一下他的代码，使用llama作为后端</p><p>首先clone他的仓库 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> gitee.com/cutecuteyu/chatgpt-honeypot<br><span class="hljs-built_in">cd</span> ./chatgpt-honeypot<br></code></pre></td></tr></table></figure></p><p>同时安装依赖 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install openai<br></code></pre></td></tr></table></figure></p><p>接下来我们在<code>chatgpt-honeypot</code>目录下创建一个 <code>.env</code> 文件，写上接口路径 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs .env">export OPENAI_API_BASE = http://localhost:8000/v1<br></code></pre></td></tr></table></figure></p><p>然后修改<code>myopenaiapikey.py</code> 文件，在第二行的<code>api=""</code> 中双引号随便填入一点东西。</p><p>下面修改<code>honeypot.py</code> ，因为我们的后端换成了llama,那么我们的prompt也需要更改,这里借鉴了<a href="https://github.com/Coldwave96/llama-honeypot">这个项目</a> ,将<code>chat2</code> 函数改成下面的内容 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat2</span>(<span class="hljs-params">query</span>):<br>response = openai.ChatCompletion.create(<br>model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>,<br>messages=[<br>&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>,<br><span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">I want you to act as a Linux terminal. I will provide commands and history, then you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. Do no write explanations. Do not type commands unless I instruct you to do so.\n\n### Command:\n&#123;command&#125;\n\n### History:\n&#123;history&#125;\n### Response:\n</span><br><span class="hljs-string">&quot;&quot;&quot;</span>&#125;,<br>&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query&#125;],<br>)<br>message = response[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>]<br><span class="hljs-keyword">return</span> message<br></code></pre></td></tr></table></figure></p><p>启动项目，正常IDE运行或者在命令行 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3  honeypot.py<br></code></pre></td></tr></table></figure></p><p>启动llama后端,将/path/to改成你的路径 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 -m llama_cpp.server --model  /path/to/llama-2-13b-chat.ggmlv3.q4_1.bin<br></code></pre></td></tr></table></figure></p><p>在浏览器访问<code>http://127.0.0.1:9000/admin/ls</code>,看到浏览器显示<code>/home/user/Documents/project</code> 类似的内容说明运行成功。</p><p>项目当然还有很多可以改进的地方，例如使用更好的prompt,或者微调llama作为后端，留给大家继续探索。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;使用llama构建一个蜜罐后端&quot;&gt;使用llama构建一个蜜罐(后端)&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.studyinglover.com/pic/2023/07/e9a49d4a404ed9bc4b0f119249194e3d.png&quot;</summary>
      
    
    
    
    
    <category term="网络安全" scheme="https://studyinglover.com/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>llama-cpp-python快速上手</title>
    <link href="https://studyinglover.com/2023/07/28/llama-cpp-python%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"/>
    <id>https://studyinglover.com/2023/07/28/llama-cpp-python%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</id>
    <published>2023-07-28T17:23:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="llama-cpp-python快速上手">llama-cpp-python快速上手</h1><h2 id="搭建环境">搭建环境</h2><p>项目地址<a href="https://github.com/abetlen/llama-cpp-python">GitHub</a>,有能力的话可以直接阅读原始文档。</p><p>首先按照文档，安装llama-cpp-python <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install llama-cpp-python<br></code></pre></td></tr></table></figure></p><p>接下来，你可能缺一些依赖，这一点在文档中没有涉及但是我整理了我缺少的依赖，依次运行即可。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install uvicorn<br>pip install anyio<br>pip install starlette<br>pip install fastapi<br>pip install pydantic_settings<br>pip install sse_starlette<br></code></pre></td></tr></table></figure></p><h2 id="高级api和低级api">高级API和低级API</h2><h3 id="高级api">高级API</h3><p>高级 API 通过<code>Llama</code>类提供简单的托管接口。请将<code>./models/7B/ggml-model.bin</code> 换成你的模型的路径，下同。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> llama_cpp <span class="hljs-keyword">import</span> Llama<br>llm = Llama(model_path=<span class="hljs-string">&quot;./models/7B/ggml-model.bin&quot;</span>)<br>output = llm(<span class="hljs-string">&quot;Q: Name the planets in the solar system? A: &quot;</span>, max_tokens=<span class="hljs-number">32</span>, stop=[<span class="hljs-string">&quot;Q:&quot;</span>, <span class="hljs-string">&quot;\n&quot;</span>], echo=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure> 返回值如下 <figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs arcade">&#123;<br>  <span class="hljs-string">&quot;id&quot;</span>: <span class="hljs-string">&quot;cmpl-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx&quot;</span>,<br>  <span class="hljs-string">&quot;object&quot;</span>: <span class="hljs-string">&quot;text_completion&quot;</span>,<br>  <span class="hljs-string">&quot;created&quot;</span>: <span class="hljs-number">1679561337</span>,<br>  <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;./models/7B/ggml-model.bin&quot;</span>,<br>  <span class="hljs-string">&quot;choices&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;Q: Name the planets in the solar system? A: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune and Pluto.&quot;</span>,<br>      <span class="hljs-string">&quot;index&quot;</span>: <span class="hljs-number">0</span>,<br>      <span class="hljs-string">&quot;logprobs&quot;</span>: <span class="hljs-built_in">None</span>,<br>      <span class="hljs-string">&quot;finish_reason&quot;</span>: <span class="hljs-string">&quot;stop&quot;</span><br>    &#125;<br>  ],<br>  <span class="hljs-string">&quot;usage&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;prompt_tokens&quot;</span>: <span class="hljs-number">14</span>,<br>    <span class="hljs-string">&quot;completion_tokens&quot;</span>: <span class="hljs-number">28</span>,<br>    <span class="hljs-string">&quot;total_tokens&quot;</span>: <span class="hljs-number">42</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></p><h3 id="低级api">低级API</h3><p>低级 API 直接<a href="https://docs.python.org/3/library/ctypes.html"><code>ctypes</code></a>绑定到<code>llama.cpp</code>. 整个低级 API 可以在<a href="https://github.com/abetlen/llama-cpp-python/blob/master/llama_cpp/llama_cpp.py">llama_cpp/llama_cpp.py</a>中找到，并直接镜像<a href="https://github.com/ggerganov/llama.cpp/blob/master/llama.h">llama.h</a>中的 C API 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> llama_cpp<br><span class="hljs-keyword">import</span> ctypes<br>params = llama_cpp.llama_context_default_params()<br><span class="hljs-comment"># use bytes for char * params</span><br>ctx = llama_cpp.llama_init_from_file(<span class="hljs-string">b&quot;./models/7b/ggml-model.bin&quot;</span>, params)<br>max_tokens = params.n_ctx<br><span class="hljs-comment"># use ctypes arrays for array params</span><br>tokens = (llama_cpp.llama_token * <span class="hljs-built_in">int</span>(max_tokens))()<br>n_tokens = llama_cpp.llama_tokenize(ctx, <span class="hljs-string">b&quot;Q: Name the planets in the solar system? A: &quot;</span>, tokens, max_tokens, add_bos=llama_cpp.c_bool(<span class="hljs-literal">True</span>))<br>llama_cpp.llama_free(ctx)<br></code></pre></td></tr></table></figure><h2 id="搭建与openai接口兼容的服务器接口">搭建与openai接口兼容的服务器接口</h2><p><code>llama-cpp-python</code>提供一个 Web 服务器，旨在作为 OpenAI API 的直接替代品。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 -m llama_cpp.server --model models/7B/ggml-model.bin<br></code></pre></td></tr></table></figure> 你可以在上面的命令运行成功后访问<a href="http://localhost:8000/docs">文档</a></p><p>文档是全英的，想要对话接口的话我用python写了个示例 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br>  <br>url = <span class="hljs-string">&#x27;http://localhost:8000/v1/chat/completions&#x27;</span><br>headers = &#123;<br><span class="hljs-string">&#x27;accept&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>,<br><span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span><br>&#125;<br>data = &#123;<br><span class="hljs-string">&#x27;messages&#x27;</span>: [<br>&#123;<br><span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;You are a helpful assistant.&#x27;</span>,<br><span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;system&#x27;</span><br>&#125;,<br>&#123;<br><span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;What is the capital of France?&#x27;</span>,<br><span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;user&#x27;</span><br>&#125;<br>]<br>&#125;<br>  <br>response = requests.post(url, headers=headers, json=data)<br><span class="hljs-built_in">print</span>(response.json())<br><span class="hljs-built_in">print</span>(response.json()[<span class="hljs-string">&#x27;choices&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;message&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>])<br></code></pre></td></tr></table></figure></p><p>如果你想自建一个接口，请在遵守相关法律法规的情况下，在自己的服务器上启动相关服务，并反向代理<code>http://localhost:8000</code> 地址。例如你反向代理到了<code>https://example.com</code>,那你的对话地址就是<code>https://example.com/v1/chat/completions</code>。当你想用gpt的时候就不用看openai的脸色了，直接部署一个自己的接口自己请求，或者调用openai库的时候apibase写自己的接口。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;llama-cpp-python快速上手&quot;&gt;llama-cpp-python快速上手&lt;/h1&gt;
&lt;h2 id=&quot;搭建环境&quot;&gt;搭建环境&lt;/h2&gt;
&lt;p&gt;项目地址&lt;a href=&quot;https://github.com/abetlen/llama-cpp-python&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>快速上手llama2.c(更新版)</title>
    <link href="https://studyinglover.com/2023/07/28/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c(%E6%9B%B4%E6%96%B0%E7%89%88)/"/>
    <id>https://studyinglover.com/2023/07/28/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c(%E6%9B%B4%E6%96%B0%E7%89%88)/</id>
    <published>2023-07-28T16:31:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="快速上手llama2.c更新版">快速上手llama2.c(更新版)</h1><p>在上一次我同时在我的博客和知乎发布了<a href="https://studyinglover.com/2023/07/25/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c/">快速上手llama2.c</a> 之后，我一个小透明也收获了不少收藏，并收到了人生中第一个这样的留言(其实我感觉是机器人)。 <img src="https://cdn.studyinglover.com/pic/2023/07/2eda3b2dcb8d68fc01169f5366c8157c.jpg" /></p><p>当然，之前的llama2.c也有一些不好的地方，例如不能添加自己的prompt,所以我提了这样的一个<a href="https://github.com/karpathy/llama2.c/issues/64">issue</a>,今天收到了贡献者的回复说是可以用了。那我们来看一下。</p><p>首先还是克隆整个仓库，编译并下载模型，这里以15m参数的模型作为示例 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/karpathy/llama2.c.git<br><span class="hljs-built_in">cd</span> llama2.c<br>make run<br>wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin<br></code></pre></td></tr></table></figure></p><p>接下来我们就可以使用编译出来的<code>run</code> 运行了,要使用自己的prompt,需要指定温度和 步长，这里温度设置成1.0,步长设置256,prompt在双引号写，我这里写的是<code>One day morning , I don't want to go to school</code> . <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./run stories15M.bin 1.0 256 <span class="hljs-string">&quot;One day morning , I don&#x27;t want to go to school&quot;</span><br></code></pre></td></tr></table></figure></p><p>这里给出我的运行结果，也就3秒种不到 <figure class="highlight tp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs tp">&lt;s&gt;<br>One day morning , I don<span class="hljs-string">&#x27;t want to go to school, so he packed his trunk lid to pack. memorized his chores, he thought about what his mom would like him to stay home and not do all day. She wanted him to in a very competitive way.</span><br><span class="hljs-string">&quot;Come and play in the puddle, it&#x27;</span>ll be more fun<span class="hljs-comment">!&quot;He begged.</span><br><span class="hljs-comment">Mom shook her head. &quot;No, we haven&#x27;t seen coming for sure,&quot; she said thought. </span><br><span class="hljs-comment">Thumper and Mom just shrugged.</span><br><span class="hljs-comment">&quot;See,&quot; she said. &quot;Come on now. Let&#x27;s go and find some fun ways to clean the world!&quot;</span><br><span class="hljs-comment">The little boy was relieved and ran out to the yard. He had found a great idea to share his day with his mom instead. They scattered around the yard and had fun playing until their tired eyes were aching.</span><br><span class="hljs-comment">&lt;s&gt;</span><br><span class="hljs-comment">Once upon a time, there was a little boy named Tim. Tim was very excited because he was going on a trip with his family. He saw a big bus that helped them get off at their destination.</span><br><span class="hljs-comment">As the bus drove along, Tim noticed an unusual looking man sitting next to it. Tim asked the</span><br><span class="hljs-comment">achieved tok/s: 175.378267</span><br><span class="hljs-comment"></span><br></code></pre></td></tr></table></figure></p><p>当然为了获得更好的效果，我们可以使用更大模型</p><p>下载42m参数模型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin<br></code></pre></td></tr></table></figure></p><p>下载110m参数模型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;快速上手llama2.c更新版&quot;&gt;快速上手llama2.c(更新版)&lt;/h1&gt;
&lt;p&gt;在上一次我同时在我的博客和知乎发布了&lt;a href=&quot;https://studyinglover.com/2023/07/25/%E5%BF%AB%E9%80%9F%E4%B8%</summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>Paper Gestalt笔记</title>
    <link href="https://studyinglover.com/2023/07/27/Paper%20Gestalt%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/07/27/Paper%20Gestalt%E7%AC%94%E8%AE%B0/</id>
    <published>2023-07-27T10:57:00.000Z</published>
    <updated>2023-09-05T01:18:04.356Z</updated>
    
    <content type="html"><![CDATA[<h1 id="paper-gestalt笔记">Paper Gestalt笔记</h1><p>最近读到了一篇CVPR2010非常优秀的论文，叫做<a href="https://bbabenko.github.io/assets/papers/paper_gestalt.pdf">Paper Gestalt</a> ,他考虑到近年来(2010年的近年来)CVPR的投稿两出现了大量增长，但是作者很可能接触到一个不优秀的审稿人，所以训练了一个视觉分类器来判断一篇CVPR的论文是否应该被接受来辅助审稿。当然模型效果非常优秀了，在误分类15%的goog paper (应该被接受)的情况下可以筛选掉50% bad paper。</p><p>在这项工作中，作者构建了一种简单的直觉，即一篇论文的质量可以通过浏览总体的视觉效果来估计，并使用这种直觉来构建一个系统，该系统使用基本的计算机视觉技术来预测论文是否应该被接受或拒绝。这个任务中具有判别能力的视觉特征集就被称为Paper Gestalt。</p><p>最有意思的一点是，作者训练出来的默认为认为他的论文有88.4%的可能被接受。</p><p>作者将这个任务认为是一个二分类任务<span class="math inline">\(\{(x_1,y_1),(x_2,y_2),...(x_n,y_n)\}\)</span> ,其中<span class="math inline">\(x_i\)</span> 是一个图片的视觉特征，<span class="math inline">\(y_i\)</span> 则是对论文的一个标签。</p><p>给定一篇论文的图像，需要计算可插入分类系统的视觉特征的数量。作者选择了一些标准的计算机视觉特征来捕捉渐变、纹理、颜色和纹理信息。特别是作者是基于LUV直方图、直方图的定向梯度和梯度幅度来计算特征。</p><p>作者选用了AdaBoost作为分类器，公式是<span class="math display">\[h(x)=\sum_{t=1}^T\alpha_th_t(x)\]</span> <span class="math inline">\(h_t\)</span>就是一个弱分类器，这里选用的是决策树<span class="math inline">\(h_t(x)=\mathbf{1}[f_t(x)&gt;\theta]\)</span> ,<span class="math inline">\(\theta\)</span> 是阈值，<span class="math inline">\(f_t\)</span> 是图像特征，整体的训练流程如图所示。(实话实话，对于我这种2020年才接触深度学习的人来说AdaBoost真的是老古董技术了(ง •̀_•́)ง，只在计算机视觉课上听过这种技术用于人脸检测) <img src="https://cdn.studyinglover.com/pic/2023/07/7230c1fa1d43d4fb676127135aef728f.png" alt="image.png" /></p><p>AdaBoost有许多吸引人的理论特性。例如，众所周知，经验误差是有界的<span class="math display">\[\epsilon(h)\leq\prod_{t=1}^T2\sqrt{\epsilon_t(1-\epsilon_t)}\]</span> 虽然这个公式摆在这没有任何用，但是作者发现数学公式多了有利于论文被接受，所以他又摆上了 Maxwell’s equations <span class="math display">\[\begin{array}{rcl}\oint\vec{E}\cdot d\vec{A}&amp;=&amp;\frac{Q_{enc}}{\epsilon_0}\\&amp;&amp;\\\oint\vec{B}\cdot d\vec{A}&amp;=&amp;0\\&amp;&amp;&amp;\\\oint\vec{E}\cdot d\vec{s}&amp;=&amp;-\frac{d\phi_B}{dt}\\\oint\vec{B}\cdot d\vec{s}&amp;=&amp;\mu_0\epsilon_0\frac{d\phi_E}{dt}+\mu_0i_{enc}\end{array}\]</span> 哦你问视觉分类器跟Maxwell’s equations 到底有啥关系？这就是这篇论文的结论部分了，作者使用了一些论文作为例子分析了效果。 <img src="https://cdn.studyinglover.com/pic/2023/07/c29f925390f8307701c7206b71e177bb.png" alt="image.png" /> <img src="https://cdn.studyinglover.com/pic/2023/07/698b7a4ae9b5fa5751a2b562f4bad18a.png" alt="image.png" /> 我们从作者给出的图可以发现，一篇被接受的论文有数学公式，有图表还有图像，而被拒的论文有令人困惑的大表格，缺少页数还有缺少五颜六色的图片。</p><p>说到令人困惑的大表格不知道你有没有想到一篇论文，对就是我们巨有钱的OPENAI做的CLIP。这表格属实看的人眼睛疼，被显卡的钱亮瞎了狗眼。 <img src="https://cdn.jsdelivr.net/gh/StudyingLover/anything/20230420145907.png" alt="image.png" /></p><p> 作者还不忘了夸一下他的论文，说他的固然存在缺页/空白页的问题，但其色彩斑斓的图表和令人印象深刻的数学公式构成非常漂亮。问题是你这图也不对呀，有的图片位置都和最终论文不一样。  <img src="https://cdn.studyinglover.com/pic/2023/07/86016048d0e76fde6f121419d1a3f0a4.png" alt="image.png" /></p><p>还有一点需要指出的是，作者的模型分析一篇论文只需要0.5秒。</p><p>在我找原文的时候，我发现arXiv上挂了一篇18年的文章<a href="https://arxiv.org/abs/1812.08775">Deep Paper Gestalt</a> ,据说他训练的模型把自己拒掉了。按照这个趋势我是不是可以搞一篇论文叫做Paper Gestalt with Latent Space?</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;paper-gestalt笔记&quot;&gt;Paper Gestalt笔记&lt;/h1&gt;
&lt;p&gt;最近读到了一篇CVPR2010非常优秀的论文，叫做&lt;a href=&quot;https://bbabenko.github.io/assets/papers/paper_gestalt.pd</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>DINO-v2笔记</title>
    <link href="https://studyinglover.com/2023/07/27/DINO-v2%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/07/27/DINO-v2%E7%AC%94%E8%AE%B0/</id>
    <published>2023-07-27T00:04:00.000Z</published>
    <updated>2023-09-05T01:18:04.356Z</updated>
    
    <content type="html"><![CDATA[<h1 id="dino-v2笔记">DINO-v2笔记</h1><p>DINO-v2一种无监督学习的预训练方法，可以生成具有强大泛化能力的视觉特征，适用于各种图像分布和任务，而无需进行微调。这篇论文重点介绍了数据和模型规模方面的技术贡献，包括自动构建一个多样化和精心筛选的图像数据集、在多个层级上进行训练、使用Sinkhorn-Knopp居中方法和KoLeo正则化等。实验结果表明，该方法在多个图像理解任务上的表现超过了目前公开的最佳无监督和半监督方法。</p><p>作者实际上花了大量的篇幅减少了数据如何创建，如何进行预训练和如何优化训练过程。</p><p><a href="https://dinov2.metademolab.com/">项目主页</a>,项目开源在<a href="https://github.com/facebookresearch/dinov2">GitHub</a></p><h2 id="数据集准备">数据集准备</h2><p>作者通过从一个大型未筛选数据池中检索与几个精选数据集中的图像接近的图像来组装他们的LVD-142M数据集。作者描述了数据处理流程的主要组成部分，包括精选/未筛选数据源，图像去重步骤和检索系统。整个流程不需要任何元数据或文本，直接使用图像。</p><p>整个处理分布在一个由20个节点组成的计算集群上，该集群配备了8个V100-32GB GPU，生成LVD-142M数据集不到两天。</p><h3 id="数据来源">数据来源</h3><p>作者在包含 ImageNet-22k，ImageNet-1k、Google Landmarks 和几个细粒度数据集的的数据集进行选择。对于不安全的数据源，爬取公开可用的网络数据存储库中收集了原始未过滤的图像数据集。从存储库中的每个网页中，作者从<img>标签中提取图像的 URL 链接。作者在构建数据集过程中丢弃了不受域限制或限制的 URL，并对下载的图像（PCA 哈希重复数据删除、NSFW 过滤和模糊可识别人脸）进行后处理。这导致 1.2B 个独特的图像。</p><h3 id="消除重复数据">消除重复数据</h3><p>作者将使用了A Self-Supervised Descriptor for Image Copy Detection 这篇论文中的方法来处理未经处理的数据，并去除接近重复的图像。这减少了冗余并增加了图像之间的多样性。此外还删除了这个工作中使用的任何基准测试或验证集中包含的几乎重复的图像。</p><h3 id="自监督的图像检索">自监督的图像检索</h3><p>首先使用在ImageNet-22k上预训练的自监督ViT-H/16网络来计算图像嵌入，并使用余弦相似性作为图像之间的距离度量。接下来对未分级的数据进行k-means聚类。给定要检索的查询数据集，如果它足够大，那么就为每个查询图像检索N个（通常是4个）最近的邻居。如果它很小，就从与每个查询图像相对应的聚类中采样M个图像。可以通过目视检查检索结果来调整N和M。</p><h2 id="判别式自监督的预培训">判别式自监督的预培训</h2><h3 id="图像级目标">图像级目标</h3><p>同一图像的不同裁剪中获得不同的部分，使用ViT进行编码，用过去迭代的指数移动平均值构建教师模型，从学生和教师网络中提取的特征之间的交叉熵损失学习学生模型的参数</p><h3 id="patch级目标">patch级目标</h3><p>随即屏蔽给学生的一些输入补丁，但不屏蔽给老师的。然后，我们在每个屏蔽补丁上的两个网络的补丁特征之间添加交叉熵损失。这种损失与图像级别的损失相结合。</p><h3 id="解绑两个目标的权重联系">解绑两个目标的权重联系</h3><p>将上面两个目标相关的权重捆绑在一起会使模型在patch上欠拟合，而在图像级别上过拟合。解开这些权重可以解决这个问题，并提高两个目标的性能。</p><h3 id="sinkhorn-knopp-centering">Sinkhorn-Knopp centering</h3><p>这是一种替代DINO和iBot模型中的teacher softmax-centering步骤的方法，即使用SwAV模型的Sinkhorn-Knopp（SK）批量归一化。作者在这个方法中运行了3次Sinkhorn-Knopp算法步骤，并对学生应用softmax归一化。这个方法的目的是提高自监督学习模型的性能。</p><h3 id="koleo-regularizer">KoLeo regularizer</h3><p>KoLeo正则化器源自Kozachenko-Leonenko差分熵估计器，它鼓励批处理中特征的均匀跨度。给定一组n个向量(x1, . . . , xn)，它被定义为<span class="math inline">\(\mathcal{L}_\text{koleo}=-\frac1n\sum_{i=1}^n\log(d_{n,i})\)</span> ，其中<span class="math inline">\(d_{n,i}=\min_{j\neq i}\left\|x_i-x_j\right\|\)</span>是<span class="math inline">\(x_i\)</span>和批处理中任何其他点之间的最小距离。在计算这个正则化器之前，我们还要对特征进行L2-归一化。</p><h3 id="adapting-the-resolution">Adapting the resolution</h3><p>在像素级别的下游任务中，如分割或检测，提高图像分辨率是非常重要的，因为低分辨率下小物体容易消失。但是高分辨率的训练需要更多的时间和内存，所以作者提出了一种方法，在预训练的最后一段时间内将图像的分辨率提高到518×518。</p><h2 id="有效的实施">有效的实施</h2><p>作者对于训练大规模模型的几个改进措施，包括使用A100 GPU和PyTorch 2.0进行训练，提供代码和预训练模型，并在附录的Table 17中详细描述了模型的细节。</p><p>另外，与iBOT实现相比，DINOv2的代码在相同硬件条件下，运行速度提高了2倍，内存使用量减少了三分之一。</p><h3 id="快速高效的注意力">快速高效的注意力</h3><p>作者自己实现了一个fastattention,需要注意的是<strong>作者的ViT-g架构略有不同，采用1536的嵌入维度和24个头（每个头64维），而不是1408的嵌入维度和16个头（每个头88维），以最大化计算效率</strong>。</p><h3 id="自注意中的嵌套张量">自注意中的嵌套张量</h3><p>作者使用了一种新的技术，可以在同一个正向传递中运行全局裁剪和局部裁剪（具有不同数量的补丁标记），与之前的实现相比，可以获得显着的计算效率提升。此外，作者提到他们使用的基础组件已经在xFormers库中提供。</p><h3 id="有效的随机深度">有效的随机深度</h3><p>作者使用了一种改进的随机深度（stochastic depth）方法，相比于传统的掩码方法，该方法跳过了被丢弃的残差计算，从而在一定程度上节省了内存和计算资源。在本次实验中，使用高丢弃率（d=40%）时，这种方法使计算效率和内存使用效率得到了显著提高。具体实现方法是通过在批处理维度上随机重新排列B个样本，并在块计算中仅对前<span class="math inline">\((1-d)×B\)</span>个样本进行计算。</p><h3 id="完全共享数据并行fsdp">完全共享数据并行（FSDP）</h3><p>通过将模型副本分配到多个GPU中，可以将模型大小限制在GPU节点总内存的范围内。此外，FSDP的实现方式可以将权重片段存储为float32，但在传播权重和梯度时使用float16，从而降低跨GPU通信成本。相较于DistributedDataParallel（DDP）中使用的float32梯度all-reduce操作，使用Pytorch-FSDP混合精度训练的通信成本减少了约50％，在扩展GPU节点数量时训练过程更加高效。总的来说，Pytorch-FSDP混合精度训练在几乎所有情况下都优于使用autocast的DDP。</p><h3 id="模型蒸馏">模型蒸馏</h3><p>作者发现即使对于一个规模较大的ViT-L模型，他们的预训练方法也能够取得比从头开始训练更好的性能。此外，他们还提出了一种知识蒸馏方法，与A simple recipe for competitive low-compute self supervised vision models. arXiv preprint arXiv:2301.09451 所描述的方法相似，但没有修改蒸馏的损失项，并评估了学生模型的指数移动平均值。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;dino-v2笔记&quot;&gt;DINO-v2笔记&lt;/h1&gt;
&lt;p&gt;DINO-v2一种无监督学习的预训练方法，可以生成具有强大泛化能力的视觉特征，适用于各种图像分布和任务，而无需进行微调。这篇论文重点介绍了数据和模型规模方面的技术贡献，包括自动构建一个多样化和精心筛选的图像</summary>
      
    
    
    
    <category term="文字生成图片" scheme="https://studyinglover.com/categories/%E6%96%87%E5%AD%97%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87/"/>
    
    
  </entry>
  
  <entry>
    <title>快速上手llama2.c</title>
    <link href="https://studyinglover.com/2023/07/25/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c/"/>
    <id>https://studyinglover.com/2023/07/25/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c/</id>
    <published>2023-07-25T16:19:00.000Z</published>
    <updated>2023-09-05T01:18:04.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="快速上手llama2.c">快速上手llama2.c</h1><p><a href="https://github.com/karpathy/llama2.c.git">llama2.c</a>一个完整的解决方案，可以使用PyTorch从头开始训练的Llama 2 LLM（Lightweight Language Model）模型，并将权重导出为二进制文件，然后加载到一个简单的500行C文件（run.c）中进行推理。另外，你也可以加载、微调和推理Meta的Llama 2模型（但这部分仍在积极开发中）。因此，这个仓库提供了一个"全栈"的训练和推理方案，专注于极简和简洁性。你可能会认为只有拥有数十亿参数的LLM才能实现有用的功能，但事实上，如果领域足够狭窄，非常小的LLM也可以表现出惊人的性能。建议参考TinyStories论文以获得灵感。</p><p>需要注意的是，这个项目最初只是一个有趣的周末项目：作者在之前的nanoGPT基础上进行了调整，实现了Llama-2架构而不是GPT-2，并且主要的工作是编写了C推理引擎（run.c）。因此，这个项目还比较年轻，并且在快速发展中。特别感谢llama.cpp项目为此项目提供了灵感。作者希望保持超级简洁，所以选择了硬编码Llama 2架构，采用fp32精度，并仅使用纯C编写一个没有依赖项的推理文件。</p><p>首先clone整个仓库并编译 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/karpathy/llama2.c.git<br><span class="hljs-built_in">cd</span> llama.c<br>gcc -O3 -o run run.c -lm<br></code></pre></td></tr></table></figure></p><p>接下来下载模型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://karpathy.ai/llama2c/model.bin -P out<br></code></pre></td></tr></table></figure></p><p>或者下载更大的一个模型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://karpathy.ai/llama2c/model44m.bin -P out44m<br></code></pre></td></tr></table></figure></p><p>接下来进行推理 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./run out/model.bin<br></code></pre></td></tr></table></figure></p><p>我们将会看到这样一段输出就代表运行成功 <figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">&lt;s&gt;<br> One day, <span class="hljs-keyword">a</span> little otter named Ollie went <span class="hljs-built_in">to</span> play <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> river. Ollie was very compassionate. He loved <span class="hljs-built_in">to</span> help his friends <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> town.<br>While playing, Ollie saw <span class="hljs-keyword">a</span> big fish. The fish was stuck <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> mud. <span class="hljs-string">&quot;Help me, please!&quot;</span> said <span class="hljs-keyword">the</span> fish. Ollie wanted <span class="hljs-built_in">to</span> help <span class="hljs-keyword">the</span> fish. He swam away, looking <span class="hljs-keyword">for</span> something <span class="hljs-built_in">to</span> break <span class="hljs-keyword">the</span> mud.<br>Ollie found <span class="hljs-keyword">a</span> small stick. He used <span class="hljs-keyword">the</span> stick <span class="hljs-built_in">to</span> break <span class="hljs-keyword">the</span> mud. The fish was free! <span class="hljs-string">&quot;Thank you, Ollie!&quot;</span> <span class="hljs-keyword">the</span> fish said. The fish was happy <span class="hljs-keyword">and</span> swam away.<br>Ollie felt good <span class="hljs-keyword">for</span> helping <span class="hljs-keyword">the</span> fish. He went back <span class="hljs-built_in">to</span> play <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> river. Ollie knew that helping others made him feel good. And <span class="hljs-built_in">from</span> that day, Ollie was always compassionate <span class="hljs-built_in">to</span> everyone.<br>&lt;s&gt;<br> Tom was <span class="hljs-keyword">a</span> big boy who liked <span class="hljs-built_in">to</span> help his mom. He saw his mom doing laundry <span class="hljs-keyword">and</span> asked <span class="hljs-keyword">if</span> he could join. His mom said yes, but he had <span class="hljs-built_in">to</span> be careful <span class="hljs-keyword">with</span> <span class="hljs-keyword">the</span> iron. The iron was hot <span class="hljs-keyword">and</span> had <span class="hljs-keyword">a</span> button <span class="hljs-keyword">on</span> <span class="hljs-title">it</span>.<br>Tom took <span class="hljs-keyword">the</span> iron <span class="hljs-keyword">and</span> ran <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> house. He wanted <span class="hljs-built_in">to</span> iron his shirt<br>achieved tok/s: <span class="hljs-number">178.148921</span><br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;快速上手llama2.c&quot;&gt;快速上手llama2.c&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/karpathy/llama2.c.git&quot;&gt;llama2.c&lt;/a&gt;一个完整的解决方案，可以使用PyTorch从头开始训练的Llama </summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
</feed>
