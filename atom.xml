<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>plus studio</title>
  
  
  <link href="https://studyinglover.com/atom.xml" rel="self"/>
  
  <link href="https://studyinglover.com/"/>
  <updated>2023-08-06T15:02:45.494Z</updated>
  <id>https://studyinglover.com/</id>
  
  <author>
    <name>StudyingLover</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>花式求GCD</title>
    <link href="https://studyinglover.com/2023/08/06/GPU%E9%83%A8%E7%BD%B2llama-cpp-python(llama.cpp%E9%80%9A%E7%94%A8)/"/>
    <id>https://studyinglover.com/2023/08/06/GPU%E9%83%A8%E7%BD%B2llama-cpp-python(llama.cpp%E9%80%9A%E7%94%A8)/</id>
    <published>2023-08-06T23:01:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="gpu部署llama-cpp-pythonllama.cpp通用">GPU部署llama-cpp-python(llama.cpp通用)</h1><h2 id="通用流程">通用流程</h2><p>我们的安装平台是Ubuntu20.04，Python 3.8.10，cuda 11.6。</p><p>首先确保自己是否已经安装了cuda,输入 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc -V<br></code></pre></td></tr></table></figure></p><p>有类似下面的输出即可 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">nvcc</span>: NVIDIA (R) Cuda compiler driver<br><span class="hljs-attribute">Copyright</span> (c) <span class="hljs-number">2005</span>-<span class="hljs-number">2021</span> NVIDIA Corporation<br><span class="hljs-attribute">Built</span> <span class="hljs-literal">on</span> Fri_Dec_17_18:<span class="hljs-number">16</span>:<span class="hljs-number">03</span>_PST_2021<br><span class="hljs-attribute">Cuda</span> compilation tools, release <span class="hljs-number">11</span>.<span class="hljs-number">6</span>, V11.<span class="hljs-number">6</span>.<span class="hljs-number">55</span><br><span class="hljs-attribute">Build</span> cuda_11.<span class="hljs-number">6</span>.r11.<span class="hljs-number">6</span>/compiler.<span class="hljs-number">30794723</span>_0<br></code></pre></td></tr></table></figure></p><p>我们选用 <code>cuBLAS</code> 加速后端代理。直接按照下面命令安装 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> LLAMA_CUBLAS=1<br>CMAKE_ARGS=<span class="hljs-string">&quot;-DLLAMA_CUBLAS=on&quot;</span> FORCE_CMAKE=1 pip install llama-cpp-python<br></code></pre></td></tr></table></figure></p><p>不出意外的话就安装好了，但是你会出现很多意外，请你努力在一堆红色的报错中找出关键出错点，然后搜索，这里我给给出了几个我遇到的。</p><h2 id="报错解决">报错解决</h2><h3 id="check-for-working-cuda-compiler-usrlocalcudabinnvcc---skipped">Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped</h3><p>参考 https://github.com/ggerganov/llama.cpp/issues/1832 系统安装过程中没找到你的cuda在哪里，所以在pip安装之前先设置一个环境变量,<strong>把/usr/local/cuda-x.y改成你的cuda路径</strong> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> CUDA_PATH=/usr/local/cuda-x.y<br></code></pre></td></tr></table></figure> ### 'f16c': expected a number 这是你的cuda版本太低了，升级到较新版本(11.6可用)。</p><p>或者参考 https://github.com/ggerganov/llama.cpp/issues/1467 和 https://github.com/marella/ctransformers/issues/53 中提到的命令和构建(我没有尝试，有谁试了可以请我结果)。</p><h3 id="value-sm_30-is-not-defined-for-option-gpu-name-tesla-t">Value 'sm_30' is not defined for option 'gpu-name' Tesla T</h3><p>先运行下面的命令 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">apt-cache policy nvidia-cuda-toolkit<br></code></pre></td></tr></table></figure> 如果版本是<strong>1.0</strong> 那么请运行 <code>sudo apt remove nvidia-cuda-toolkit</code></p><h2 id="运行">运行</h2><p>运行和CPU直接运行相似，只是需要加入几个参数 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 -m llama_cpp.server --model llama-2-70b-chat.ggmlv3.q5_K_M.bin --n_threads 30 --n_gpu_layers 200<br></code></pre></td></tr></table></figure></p><p><code>n_threads</code> 是一个CPU也有的参数，代表最多使用多少县城。</p><p><code>n_gpu_layers</code> 是一个GPU部署非常重要的一步，代表大语言模型有多少层在GPU运算，如果你的显存出现 <code>out of memory</code> 那就减小 <code>n_gpu_layers</code></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;gpu部署llama-cpp-pythonllama.cpp通用&quot;&gt;GPU部署llama-cpp-python(llama.cpp通用)&lt;/h1&gt;
&lt;h2 id=&quot;通用流程&quot;&gt;通用流程&lt;/h2&gt;
&lt;p&gt;我们的安装平台是Ubuntu20.04，Python 3.8.</summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>花式求GCD</title>
    <link href="https://studyinglover.com/2023/08/02/%E8%8A%B1%E5%BC%8F%E6%B1%82GCD/"/>
    <id>https://studyinglover.com/2023/08/02/%E8%8A%B1%E5%BC%8F%E6%B1%82GCD/</id>
    <published>2023-08-02T18:46:00.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="花式求gcd">花式求GCD</h1><p>今天学校实验室纳新群有同学提到了<code>a^=b^=a^=b​</code> 交换两个数的操作，我突然想到之前在知乎看到通过异或实现gcd的方法，一番翻找后没啥结果，便去问了下认识的oi大佬有没有一行求gcd的算法。</p><p>大佬很快给出了一个函数<code>int gcd(int a,int b)&#123;return y?gcd(y,x%y):x;&#125;</code> 真的就是一行，完整的代码就是下面这个</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">gcd</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> </span>&#123; <span class="hljs-keyword">return</span> y ? <span class="hljs-built_in">gcd</span>(y, x % y) : x; &#125;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-type">int</span> a,b;<br>a=<span class="hljs-number">10</span>;<br>b=<span class="hljs-number">20</span>;<br>a = <span class="hljs-built_in">gcd</span>(a,b);<br>cout&lt;&lt;a&lt;&lt;endl;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>但是我一像不对啊，我的异或呢？我又问了一下，大佬给了我一个截图 <img src="https://cdn.studyinglover.com/pic/2023/08/07b57e65da92d9c19bb82d740132f07c.png" /></p><p>就是这个神奇的写法</p><p>这段代码的实现方式是，使用异或运算符（^）和取模运算符（%）来交换变量a和b的值。具体来说，代码中的while循环会一直执行，直到b的值为0为止。在每次循环中，代码会先将a对b取模，然后将结果赋值给a，接着将b对a取模，然后将结果赋值给b，最后使用异或运算符交换a和b的值。这样，当循环结束时，a和b的值就被成功地交换了。(来自copilot chat)</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bits/stdc++.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-type">int</span> a,b;<br>a=<span class="hljs-number">10</span>;<br>b=<span class="hljs-number">20</span>;<br><span class="hljs-keyword">while</span>(b^=a^=b^=a%=b);<br>cout&lt;&lt;a&lt;&lt;endl;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;花式求gcd&quot;&gt;花式求GCD&lt;/h1&gt;
&lt;p&gt;今天学校实验室纳新群有同学提到了&lt;code&gt;a^=b^=a^=b​&lt;/code&gt; 交换两个数的操作，我突然想到之前在知乎看到通过异或实现gcd的方法，一番翻找后没啥结果，便去问了下认识的oi大佬有没有一行求gcd的算法</summary>
      
    
    
    
    
    <category term="算法" scheme="https://studyinglover.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>使用llama构建一个蜜罐(前端)</title>
    <link href="https://studyinglover.com/2023/08/01/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%89%8D%E7%AB%AF)/"/>
    <id>https://studyinglover.com/2023/08/01/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%89%8D%E7%AB%AF)/</id>
    <published>2023-08-01T00:12:00.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用llama构建一个蜜罐前端">使用llama构建一个蜜罐(前端)</h1><p><img src="https://cdn.studyinglover.com/pic/2023/07/e9a49d4a404ed9bc4b0f119249194e3d.png" /> 在<a href="https://studyinglover.com/2023/07/29/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%90%8E%E7%AB%AF)/">使用llama构建一个蜜罐(后端)</a> 中我们通过llama和flask构建了一个蜜罐的后端，通过将shell命令作为字段的一部分，让llama假装执行命令来防止蜜罐被攻破。那有了后端我们还需要一个前端命令行来让用户登陆并执行命令。</p><p>完整项目开源在了<a href="https://github.com/StudyingLover/llama-honeypot-python">GitHub</a></p><p>接下来，让我们来实现一个模拟ssh服务器，或者说实现一个ssh mock 然后执行命令的时候不让他真的执行同时改一下输出。</p><p><strong>等等？我们真的需要一个ssh mock 吗？</strong> 还是说，我们需要的是一个<strong>跑在终端的，长得很像终端的，能输入输出的，一个可交互的代码？</strong></p><p>哦，好像我们需要的只是一个可交互的代码，难道攻击方ssh上来了还能验证一下这是不是真的是终端？(我用了三天才想通这个问题)</p><p>so,工作量一下子减少了太多了 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> requests<br>  <br><span class="hljs-comment"># 禁用 Ctrl Z stty susp undef</span><br><span class="hljs-comment"># 启用 Ctrl Z stty susp ^Z</span><br><br>admin_key = <span class="hljs-string">&quot;123456&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_responce</span>(<span class="hljs-params">command</span>):<br><span class="hljs-keyword">if</span> (command == admin_key):<br>exit()<br>output = requests.post(<span class="hljs-string">&quot;http://127.0.0.1:9000/admin/&quot;</span>+command).json()<br><span class="hljs-keyword">return</span> output[<span class="hljs-string">&quot;message&quot;</span>]<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">attact_warning</span>():<br><span class="hljs-keyword">pass</span><br>  <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">anti_attact</span>():<br><span class="hljs-keyword">pass</span><br>  <br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>attact_warning()<br>anti_attact()<br><span class="hljs-keyword">try</span>:<br>command = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;[root@ubuntu ~]$ &quot;</span>)<br><span class="hljs-built_in">print</span>(get_responce(command))<br>  <br><span class="hljs-keyword">except</span> KeyboardInterrupt:<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span>)<br></code></pre></td></tr></table></figure></p><p>这里有几个点需要注意 1. 代码<strong>不能直接用于生产环境！！！请先完善细节并大量测试。本项目仅为学习使用，未经过专业人员测试</strong> 1. <code>admin_key</code>，这个变量的作用是让管理员能用终端，<strong>记得修改</strong>。如果你认为这种方法太low了或者可能被作为突破口，请修改或PR。 2. 接口地址，我这里是<code>http://127.0.0.1:9000/admin/</code> ，这里需要改成你的，建议先用postman或者apifox或者啥的测一下。 3. 入侵检测和反击模块需要你<strong>自己实现</strong>，毕竟这只是一个让你的蜜罐更安全的项目。</p><p>在三个终端分别运行llama服务器(图右终端)，蜜罐后端(图左终端)和蜜罐前端(图中终端)</p><figure><img src="https://cdn.studyinglover.com/pic/2023/07/dd31f63365b8a8657b1459f7fe883a36.png" alt="" /><figcaption>image.png</figcaption></figure><p>项目还有很多改进之处，在后面我也会进一步优化prompt和模型来获得更好的终端对话体验。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;使用llama构建一个蜜罐前端&quot;&gt;使用llama构建一个蜜罐(前端)&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.studyinglover.com/pic/2023/07/e9a49d4a404ed9bc4b0f119249194e3d.png&quot;</summary>
      
    
    
    
    
    <category term="网络安全" scheme="https://studyinglover.com/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>使用llama构建一个蜜罐(后端)</title>
    <link href="https://studyinglover.com/2023/07/29/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%90%8E%E7%AB%AF)/"/>
    <id>https://studyinglover.com/2023/07/29/%E4%BD%BF%E7%94%A8llama%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%9C%9C%E7%BD%90(%E5%90%8E%E7%AB%AF)/</id>
    <published>2023-07-29T17:52:00.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用llama构建一个蜜罐后端">使用llama构建一个蜜罐(后端)</h1><p><img src="https://cdn.studyinglover.com/pic/2023/07/e9a49d4a404ed9bc4b0f119249194e3d.png" /></p><p>完整项目开源在了<a href="https://github.com/StudyingLover/llama-honeypot-python">GitHub</a></p><p>众所周知，蜜罐是一个很有趣的东西，他是一种网络安全机制，旨在诱使攻击者攻击虚假的系统或应用程序，以便安全专业人员可以监视攻击者的行为并收集攻击者的信息。蜜罐通常是一台虚拟机或一台计算机，它看起来像一个真实的系统，但实际上是一个特意构建的系统，用于诱骗攻击者。攻击者在攻击蜜罐时，安全专业人员可以收集攻击者的信息，例如攻击者使用的工具、攻击者的IP地址、攻击者的攻击技术等等。这些信息可以帮助安全专业人员更好地了解攻击者的行为和意图，并采取相应的措施来保护真实的系统。</p><p>但是缺点很明显，不管我怎么做蜜罐终究是跑在真实的服务器上的，还是很可能被攻破，所以，我们能不能让ai模仿一个linux主机作为蜜罐？</p><p>今天早上看到了这个视频 https://b23.tv/pXiGNIK ， 他开源了一个使用chatGPT作为终端的代码，开源在<a href="gitee.com/cutecuteyu/chatgpt-honeypot">gitee</a> ，不幸的是我openai账户没钱了，但是，昨天我才写了<a href="https://studyinglover.com/2023/07/28/llama-cpp-python%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/#%E6%90%AD%E5%BB%BA%E4%B8%8Eopenai%E6%8E%A5%E5%8F%A3%E5%85%BC%E5%AE%B9%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A5%E5%8F%A3">搭建与openai接口兼容的服务器接口</a>, 那么我就可以改造一下他的代码，使用llama作为后端</p><p>首先clone他的仓库 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> gitee.com/cutecuteyu/chatgpt-honeypot<br><span class="hljs-built_in">cd</span> ./chatgpt-honeypot<br></code></pre></td></tr></table></figure></p><p>同时安装依赖 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install openai<br></code></pre></td></tr></table></figure></p><p>接下来我们在<code>chatgpt-honeypot</code>目录下创建一个 <code>.env</code> 文件，写上接口路径 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs .env">export OPENAI_API_BASE = http://localhost:8000/v1<br></code></pre></td></tr></table></figure></p><p>然后修改<code>myopenaiapikey.py</code> 文件，在第二行的<code>api=""</code> 中双引号随便填入一点东西。</p><p>下面修改<code>honeypot.py</code> ，因为我们的后端换成了llama,那么我们的prompt也需要更改,这里借鉴了<a href="https://github.com/Coldwave96/llama-honeypot">这个项目</a> ,将<code>chat2</code> 函数改成下面的内容 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat2</span>(<span class="hljs-params">query</span>):<br>response = openai.ChatCompletion.create(<br>model=<span class="hljs-string">&quot;gpt-3.5-turbo-0613&quot;</span>,<br>messages=[<br>&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;assistant&quot;</span>,<br><span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">I want you to act as a Linux terminal. I will provide commands and history, then you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. Do no write explanations. Do not type commands unless I instruct you to do so.\n\n### Command:\n&#123;command&#125;\n\n### History:\n&#123;history&#125;\n### Response:\n</span><br><span class="hljs-string">&quot;&quot;&quot;</span>&#125;,<br>&#123;<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query&#125;],<br>)<br>message = response[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>]<br><span class="hljs-keyword">return</span> message<br></code></pre></td></tr></table></figure></p><p>启动项目，正常IDE运行或者在命令行 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3  honeypot.py<br></code></pre></td></tr></table></figure></p><p>启动llama后端,将/path/to改成你的路径 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 -m llama_cpp.server --model  /path/to/llama-2-13b-chat.ggmlv3.q4_1.bin<br></code></pre></td></tr></table></figure></p><p>在浏览器访问<code>http://127.0.0.1:9000/admin/ls</code>,看到浏览器显示<code>/home/user/Documents/project</code> 类似的内容说明运行成功。</p><p>项目当然还有很多可以改进的地方，例如使用更好的prompt,或者微调llama作为后端，留给大家继续探索。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;使用llama构建一个蜜罐后端&quot;&gt;使用llama构建一个蜜罐(后端)&lt;/h1&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.studyinglover.com/pic/2023/07/e9a49d4a404ed9bc4b0f119249194e3d.png&quot;</summary>
      
    
    
    
    
    <category term="网络安全" scheme="https://studyinglover.com/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>llama-cpp-python快速上手</title>
    <link href="https://studyinglover.com/2023/07/28/llama-cpp-python%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"/>
    <id>https://studyinglover.com/2023/07/28/llama-cpp-python%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</id>
    <published>2023-07-28T17:23:00.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="llama-cpp-python快速上手">llama-cpp-python快速上手</h1><h2 id="搭建环境">搭建环境</h2><p>项目地址<a href="https://github.com/abetlen/llama-cpp-python">GitHub</a>,有能力的话可以直接阅读原始文档。</p><p>首先按照文档，安装llama-cpp-python <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install llama-cpp-python<br></code></pre></td></tr></table></figure></p><p>接下来，你可能缺一些依赖，这一点在文档中没有涉及但是我整理了我缺少的依赖，依次运行即可。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install uvicorn<br>pip install anyio<br>pip install starlette<br>pip install fastapi<br>pip install pydantic_settings<br>pip install sse_starlette<br></code></pre></td></tr></table></figure></p><h2 id="高级api和低级api">高级API和低级API</h2><h3 id="高级api">高级API</h3><p>高级 API 通过<code>Llama</code>类提供简单的托管接口。请将<code>./models/7B/ggml-model.bin</code> 换成你的模型的路径，下同。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> llama_cpp <span class="hljs-keyword">import</span> Llama<br>llm = Llama(model_path=<span class="hljs-string">&quot;./models/7B/ggml-model.bin&quot;</span>)<br>output = llm(<span class="hljs-string">&quot;Q: Name the planets in the solar system? A: &quot;</span>, max_tokens=<span class="hljs-number">32</span>, stop=[<span class="hljs-string">&quot;Q:&quot;</span>, <span class="hljs-string">&quot;\n&quot;</span>], echo=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></td></tr></table></figure> 返回值如下 <figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs arcade">&#123;<br>  <span class="hljs-string">&quot;id&quot;</span>: <span class="hljs-string">&quot;cmpl-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx&quot;</span>,<br>  <span class="hljs-string">&quot;object&quot;</span>: <span class="hljs-string">&quot;text_completion&quot;</span>,<br>  <span class="hljs-string">&quot;created&quot;</span>: <span class="hljs-number">1679561337</span>,<br>  <span class="hljs-string">&quot;model&quot;</span>: <span class="hljs-string">&quot;./models/7B/ggml-model.bin&quot;</span>,<br>  <span class="hljs-string">&quot;choices&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;Q: Name the planets in the solar system? A: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune and Pluto.&quot;</span>,<br>      <span class="hljs-string">&quot;index&quot;</span>: <span class="hljs-number">0</span>,<br>      <span class="hljs-string">&quot;logprobs&quot;</span>: <span class="hljs-built_in">None</span>,<br>      <span class="hljs-string">&quot;finish_reason&quot;</span>: <span class="hljs-string">&quot;stop&quot;</span><br>    &#125;<br>  ],<br>  <span class="hljs-string">&quot;usage&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;prompt_tokens&quot;</span>: <span class="hljs-number">14</span>,<br>    <span class="hljs-string">&quot;completion_tokens&quot;</span>: <span class="hljs-number">28</span>,<br>    <span class="hljs-string">&quot;total_tokens&quot;</span>: <span class="hljs-number">42</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure></p><h3 id="低级api">低级API</h3><p>低级 API 直接<a href="https://docs.python.org/3/library/ctypes.html"><code>ctypes</code></a>绑定到<code>llama.cpp</code>. 整个低级 API 可以在<a href="https://github.com/abetlen/llama-cpp-python/blob/master/llama_cpp/llama_cpp.py">llama_cpp/llama_cpp.py</a>中找到，并直接镜像<a href="https://github.com/ggerganov/llama.cpp/blob/master/llama.h">llama.h</a>中的 C API 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> llama_cpp<br><span class="hljs-keyword">import</span> ctypes<br>params = llama_cpp.llama_context_default_params()<br><span class="hljs-comment"># use bytes for char * params</span><br>ctx = llama_cpp.llama_init_from_file(<span class="hljs-string">b&quot;./models/7b/ggml-model.bin&quot;</span>, params)<br>max_tokens = params.n_ctx<br><span class="hljs-comment"># use ctypes arrays for array params</span><br>tokens = (llama_cpp.llama_token * <span class="hljs-built_in">int</span>(max_tokens))()<br>n_tokens = llama_cpp.llama_tokenize(ctx, <span class="hljs-string">b&quot;Q: Name the planets in the solar system? A: &quot;</span>, tokens, max_tokens, add_bos=llama_cpp.c_bool(<span class="hljs-literal">True</span>))<br>llama_cpp.llama_free(ctx)<br></code></pre></td></tr></table></figure><h2 id="搭建与openai接口兼容的服务器接口">搭建与openai接口兼容的服务器接口</h2><p><code>llama-cpp-python</code>提供一个 Web 服务器，旨在作为 OpenAI API 的直接替代品。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 -m llama_cpp.server --model models/7B/ggml-model.bin<br></code></pre></td></tr></table></figure> 你可以在上面的命令运行成功后访问<a href="http://localhost:8000/docs">文档</a></p><p>文档是全英的，想要对话接口的话我用python写了个示例 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br>  <br>url = <span class="hljs-string">&#x27;http://localhost:8000/v1/chat/completions&#x27;</span><br>headers = &#123;<br><span class="hljs-string">&#x27;accept&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>,<br><span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span><br>&#125;<br>data = &#123;<br><span class="hljs-string">&#x27;messages&#x27;</span>: [<br>&#123;<br><span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;You are a helpful assistant.&#x27;</span>,<br><span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;system&#x27;</span><br>&#125;,<br>&#123;<br><span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;What is the capital of France?&#x27;</span>,<br><span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;user&#x27;</span><br>&#125;<br>]<br>&#125;<br>  <br>response = requests.post(url, headers=headers, json=data)<br><span class="hljs-built_in">print</span>(response.json())<br><span class="hljs-built_in">print</span>(response.json()[<span class="hljs-string">&#x27;choices&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;message&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>])<br></code></pre></td></tr></table></figure></p><p>如果你想自建一个接口，请在遵守相关法律法规的情况下，在自己的服务器上启动相关服务，并反向代理<code>http://localhost:8000</code> 地址。例如你反向代理到了<code>https://example.com</code>,那你的对话地址就是<code>https://example.com/v1/chat/completions</code>。当你想用gpt的时候就不用看openai的脸色了，直接部署一个自己的接口自己请求，或者调用openai库的时候apibase写自己的接口。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;llama-cpp-python快速上手&quot;&gt;llama-cpp-python快速上手&lt;/h1&gt;
&lt;h2 id=&quot;搭建环境&quot;&gt;搭建环境&lt;/h2&gt;
&lt;p&gt;项目地址&lt;a href=&quot;https://github.com/abetlen/llama-cpp-python&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>快速上手llama2.c(更新版)</title>
    <link href="https://studyinglover.com/2023/07/28/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c(%E6%9B%B4%E6%96%B0%E7%89%88)/"/>
    <id>https://studyinglover.com/2023/07/28/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c(%E6%9B%B4%E6%96%B0%E7%89%88)/</id>
    <published>2023-07-28T16:31:00.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="快速上手llama2.c更新版">快速上手llama2.c(更新版)</h1><p>在上一次我同时在我的博客和知乎发布了<a href="https://studyinglover.com/2023/07/25/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c/">快速上手llama2.c</a> 之后，我一个小透明也收获了不少收藏，并收到了人生中第一个这样的留言(其实我感觉是机器人)。 <img src="https://cdn.studyinglover.com/pic/2023/07/2eda3b2dcb8d68fc01169f5366c8157c.jpg" /></p><p>当然，之前的llama2.c也有一些不好的地方，例如不能添加自己的prompt,所以我提了这样的一个<a href="https://github.com/karpathy/llama2.c/issues/64">issue</a>,今天收到了贡献者的回复说是可以用了。那我们来看一下。</p><p>首先还是克隆整个仓库，编译并下载模型，这里以15m参数的模型作为示例 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/karpathy/llama2.c.git<br><span class="hljs-built_in">cd</span> llama2.c<br>make run<br>wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin<br></code></pre></td></tr></table></figure></p><p>接下来我们就可以使用编译出来的<code>run</code> 运行了,要使用自己的prompt,需要指定温度和 步长，这里温度设置成1.0,步长设置256,prompt在双引号写，我这里写的是<code>One day morning , I don't want to go to school</code> . <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./run stories15M.bin 1.0 256 <span class="hljs-string">&quot;One day morning , I don&#x27;t want to go to school&quot;</span><br></code></pre></td></tr></table></figure></p><p>这里给出我的运行结果，也就3秒种不到 <figure class="highlight tp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs tp">&lt;s&gt;<br>One day morning , I don<span class="hljs-string">&#x27;t want to go to school, so he packed his trunk lid to pack. memorized his chores, he thought about what his mom would like him to stay home and not do all day. She wanted him to in a very competitive way.</span><br><span class="hljs-string">&quot;Come and play in the puddle, it&#x27;</span>ll be more fun<span class="hljs-comment">!&quot;He begged.</span><br><span class="hljs-comment">Mom shook her head. &quot;No, we haven&#x27;t seen coming for sure,&quot; she said thought. </span><br><span class="hljs-comment">Thumper and Mom just shrugged.</span><br><span class="hljs-comment">&quot;See,&quot; she said. &quot;Come on now. Let&#x27;s go and find some fun ways to clean the world!&quot;</span><br><span class="hljs-comment">The little boy was relieved and ran out to the yard. He had found a great idea to share his day with his mom instead. They scattered around the yard and had fun playing until their tired eyes were aching.</span><br><span class="hljs-comment">&lt;s&gt;</span><br><span class="hljs-comment">Once upon a time, there was a little boy named Tim. Tim was very excited because he was going on a trip with his family. He saw a big bus that helped them get off at their destination.</span><br><span class="hljs-comment">As the bus drove along, Tim noticed an unusual looking man sitting next to it. Tim asked the</span><br><span class="hljs-comment">achieved tok/s: 175.378267</span><br><span class="hljs-comment"></span><br></code></pre></td></tr></table></figure></p><p>当然为了获得更好的效果，我们可以使用更大模型</p><p>下载42m参数模型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin<br></code></pre></td></tr></table></figure></p><p>下载110m参数模型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;快速上手llama2.c更新版&quot;&gt;快速上手llama2.c(更新版)&lt;/h1&gt;
&lt;p&gt;在上一次我同时在我的博客和知乎发布了&lt;a href=&quot;https://studyinglover.com/2023/07/25/%E5%BF%AB%E9%80%9F%E4%B8%</summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>Paper Gestalt笔记</title>
    <link href="https://studyinglover.com/2023/07/27/Paper%20Gestalt%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/07/27/Paper%20Gestalt%E7%AC%94%E8%AE%B0/</id>
    <published>2023-07-27T10:57:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="paper-gestalt笔记">Paper Gestalt笔记</h1><p>最近读到了一篇CVPR2010非常优秀的论文，叫做<a href="https://bbabenko.github.io/assets/papers/paper_gestalt.pdf">Paper Gestalt</a> ,他考虑到近年来(2010年的近年来)CVPR的投稿两出现了大量增长，但是作者很可能接触到一个不优秀的审稿人，所以训练了一个视觉分类器来判断一篇CVPR的论文是否应该被接受来辅助审稿。当然模型效果非常优秀了，在误分类15%的goog paper (应该被接受)的情况下可以筛选掉50% bad paper。</p><p>在这项工作中，作者构建了一种简单的直觉，即一篇论文的质量可以通过浏览总体的视觉效果来估计，并使用这种直觉来构建一个系统，该系统使用基本的计算机视觉技术来预测论文是否应该被接受或拒绝。这个任务中具有判别能力的视觉特征集就被称为Paper Gestalt。</p><p>最有意思的一点是，作者训练出来的默认为认为他的论文有88.4%的可能被接受。</p><p>作者将这个任务认为是一个二分类任务<span class="math inline">\(\{(x_1,y_1),(x_2,y_2),...(x_n,y_n)\}\)</span> ,其中<span class="math inline">\(x_i\)</span> 是一个图片的视觉特征，<span class="math inline">\(y_i\)</span> 则是对论文的一个标签。</p><p>给定一篇论文的图像，需要计算可插入分类系统的视觉特征的数量。作者选择了一些标准的计算机视觉特征来捕捉渐变、纹理、颜色和纹理信息。特别是作者是基于LUV直方图、直方图的定向梯度和梯度幅度来计算特征。</p><p>作者选用了AdaBoost作为分类器，公式是<span class="math display">\[h(x)=\sum_{t=1}^T\alpha_th_t(x)\]</span> <span class="math inline">\(h_t\)</span>就是一个弱分类器，这里选用的是决策树<span class="math inline">\(h_t(x)=\mathbf{1}[f_t(x)&gt;\theta]\)</span> ,<span class="math inline">\(\theta\)</span> 是阈值，<span class="math inline">\(f_t\)</span> 是图像特征，整体的训练流程如图所示。(实话实话，对于我这种2020年才接触深度学习的人来说AdaBoost真的是老古董技术了(ง •̀_•́)ง，只在计算机视觉课上听过这种技术用于人脸检测) <img src="https://cdn.studyinglover.com/pic/2023/07/7230c1fa1d43d4fb676127135aef728f.png" alt="image.png" /></p><p>AdaBoost有许多吸引人的理论特性。例如，众所周知，经验误差是有界的<span class="math display">\[\epsilon(h)\leq\prod_{t=1}^T2\sqrt{\epsilon_t(1-\epsilon_t)}\]</span> 虽然这个公式摆在这没有任何用，但是作者发现数学公式多了有利于论文被接受，所以他又摆上了 Maxwell’s equations <span class="math display">\[\begin{array}{rcl}\oint\vec{E}\cdot d\vec{A}&amp;=&amp;\frac{Q_{enc}}{\epsilon_0}\\&amp;&amp;\\\oint\vec{B}\cdot d\vec{A}&amp;=&amp;0\\&amp;&amp;&amp;\\\oint\vec{E}\cdot d\vec{s}&amp;=&amp;-\frac{d\phi_B}{dt}\\\oint\vec{B}\cdot d\vec{s}&amp;=&amp;\mu_0\epsilon_0\frac{d\phi_E}{dt}+\mu_0i_{enc}\end{array}\]</span> 哦你问视觉分类器跟Maxwell’s equations 到底有啥关系？这就是这篇论文的结论部分了，作者使用了一些论文作为例子分析了效果。 <img src="https://cdn.studyinglover.com/pic/2023/07/c29f925390f8307701c7206b71e177bb.png" alt="image.png" /> <img src="https://cdn.studyinglover.com/pic/2023/07/698b7a4ae9b5fa5751a2b562f4bad18a.png" alt="image.png" /> 我们从作者给出的图可以发现，一篇被接受的论文有数学公式，有图表还有图像，而被拒的论文有令人困惑的大表格，缺少页数还有缺少五颜六色的图片。</p><p>说到令人困惑的大表格不知道你有没有想到一篇论文，对就是我们巨有钱的OPENAI做的CLIP。这表格属实看的人眼睛疼，被显卡的钱亮瞎了狗眼。 <img src="https://cdn.jsdelivr.net/gh/StudyingLover/anything/20230420145907.png" alt="image.png" /></p><p> 作者还不忘了夸一下他的论文，说他的固然存在缺页/空白页的问题，但其色彩斑斓的图表和令人印象深刻的数学公式构成非常漂亮。问题是你这图也不对呀，有的图片位置都和最终论文不一样。  <img src="https://cdn.studyinglover.com/pic/2023/07/86016048d0e76fde6f121419d1a3f0a4.png" alt="image.png" /></p><p>还有一点需要指出的是，作者的模型分析一篇论文只需要0.5秒。</p><p>在我找原文的时候，我发现arXiv上挂了一篇18年的文章<a href="https://arxiv.org/abs/1812.08775">Deep Paper Gestalt</a> ,据说他训练的模型把自己拒掉了。按照这个趋势我是不是可以搞一篇论文叫做Paper Gestalt with Latent Space?</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;paper-gestalt笔记&quot;&gt;Paper Gestalt笔记&lt;/h1&gt;
&lt;p&gt;最近读到了一篇CVPR2010非常优秀的论文，叫做&lt;a href=&quot;https://bbabenko.github.io/assets/papers/paper_gestalt.pd</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>DINO-v2笔记</title>
    <link href="https://studyinglover.com/2023/07/27/DINO-v2%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/07/27/DINO-v2%E7%AC%94%E8%AE%B0/</id>
    <published>2023-07-27T00:04:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="dino-v2笔记">DINO-v2笔记</h1><p>DINO-v2一种无监督学习的预训练方法，可以生成具有强大泛化能力的视觉特征，适用于各种图像分布和任务，而无需进行微调。这篇论文重点介绍了数据和模型规模方面的技术贡献，包括自动构建一个多样化和精心筛选的图像数据集、在多个层级上进行训练、使用Sinkhorn-Knopp居中方法和KoLeo正则化等。实验结果表明，该方法在多个图像理解任务上的表现超过了目前公开的最佳无监督和半监督方法。</p><p>作者实际上花了大量的篇幅减少了数据如何创建，如何进行预训练和如何优化训练过程。</p><p><a href="https://dinov2.metademolab.com/">项目主页</a>,项目开源在<a href="https://github.com/facebookresearch/dinov2">GitHub</a></p><h2 id="数据集准备">数据集准备</h2><p>作者通过从一个大型未筛选数据池中检索与几个精选数据集中的图像接近的图像来组装他们的LVD-142M数据集。作者描述了数据处理流程的主要组成部分，包括精选/未筛选数据源，图像去重步骤和检索系统。整个流程不需要任何元数据或文本，直接使用图像。</p><p>整个处理分布在一个由20个节点组成的计算集群上，该集群配备了8个V100-32GB GPU，生成LVD-142M数据集不到两天。</p><h3 id="数据来源">数据来源</h3><p>作者在包含 ImageNet-22k，ImageNet-1k、Google Landmarks 和几个细粒度数据集的的数据集进行选择。对于不安全的数据源，爬取公开可用的网络数据存储库中收集了原始未过滤的图像数据集。从存储库中的每个网页中，作者从<img>标签中提取图像的 URL 链接。作者在构建数据集过程中丢弃了不受域限制或限制的 URL，并对下载的图像（PCA 哈希重复数据删除、NSFW 过滤和模糊可识别人脸）进行后处理。这导致 1.2B 个独特的图像。</p><h3 id="消除重复数据">消除重复数据</h3><p>作者将使用了A Self-Supervised Descriptor for Image Copy Detection 这篇论文中的方法来处理未经处理的数据，并去除接近重复的图像。这减少了冗余并增加了图像之间的多样性。此外还删除了这个工作中使用的任何基准测试或验证集中包含的几乎重复的图像。</p><h3 id="自监督的图像检索">自监督的图像检索</h3><p>首先使用在ImageNet-22k上预训练的自监督ViT-H/16网络来计算图像嵌入，并使用余弦相似性作为图像之间的距离度量。接下来对未分级的数据进行k-means聚类。给定要检索的查询数据集，如果它足够大，那么就为每个查询图像检索N个（通常是4个）最近的邻居。如果它很小，就从与每个查询图像相对应的聚类中采样M个图像。可以通过目视检查检索结果来调整N和M。</p><h2 id="判别式自监督的预培训">判别式自监督的预培训</h2><h3 id="图像级目标">图像级目标</h3><p>同一图像的不同裁剪中获得不同的部分，使用ViT进行编码，用过去迭代的指数移动平均值构建教师模型，从学生和教师网络中提取的特征之间的交叉熵损失学习学生模型的参数</p><h3 id="patch级目标">patch级目标</h3><p>随即屏蔽给学生的一些输入补丁，但不屏蔽给老师的。然后，我们在每个屏蔽补丁上的两个网络的补丁特征之间添加交叉熵损失。这种损失与图像级别的损失相结合。</p><h3 id="解绑两个目标的权重联系">解绑两个目标的权重联系</h3><p>将上面两个目标相关的权重捆绑在一起会使模型在patch上欠拟合，而在图像级别上过拟合。解开这些权重可以解决这个问题，并提高两个目标的性能。</p><h3 id="sinkhorn-knopp-centering">Sinkhorn-Knopp centering</h3><p>这是一种替代DINO和iBot模型中的teacher softmax-centering步骤的方法，即使用SwAV模型的Sinkhorn-Knopp（SK）批量归一化。作者在这个方法中运行了3次Sinkhorn-Knopp算法步骤，并对学生应用softmax归一化。这个方法的目的是提高自监督学习模型的性能。</p><h3 id="koleo-regularizer">KoLeo regularizer</h3><p>KoLeo正则化器源自Kozachenko-Leonenko差分熵估计器，它鼓励批处理中特征的均匀跨度。给定一组n个向量(x1, . . . , xn)，它被定义为<span class="math inline">\(\mathcal{L}_\text{koleo}=-\frac1n\sum_{i=1}^n\log(d_{n,i})\)</span> ，其中<span class="math inline">\(d_{n,i}=\min_{j\neq i}\left\|x_i-x_j\right\|\)</span>是<span class="math inline">\(x_i\)</span>和批处理中任何其他点之间的最小距离。在计算这个正则化器之前，我们还要对特征进行L2-归一化。</p><h3 id="adapting-the-resolution">Adapting the resolution</h3><p>在像素级别的下游任务中，如分割或检测，提高图像分辨率是非常重要的，因为低分辨率下小物体容易消失。但是高分辨率的训练需要更多的时间和内存，所以作者提出了一种方法，在预训练的最后一段时间内将图像的分辨率提高到518×518。</p><h2 id="有效的实施">有效的实施</h2><p>作者对于训练大规模模型的几个改进措施，包括使用A100 GPU和PyTorch 2.0进行训练，提供代码和预训练模型，并在附录的Table 17中详细描述了模型的细节。</p><p>另外，与iBOT实现相比，DINOv2的代码在相同硬件条件下，运行速度提高了2倍，内存使用量减少了三分之一。</p><h3 id="快速高效的注意力">快速高效的注意力</h3><p>作者自己实现了一个fastattention,需要注意的是<strong>作者的ViT-g架构略有不同，采用1536的嵌入维度和24个头（每个头64维），而不是1408的嵌入维度和16个头（每个头88维），以最大化计算效率</strong>。</p><h3 id="自注意中的嵌套张量">自注意中的嵌套张量</h3><p>作者使用了一种新的技术，可以在同一个正向传递中运行全局裁剪和局部裁剪（具有不同数量的补丁标记），与之前的实现相比，可以获得显着的计算效率提升。此外，作者提到他们使用的基础组件已经在xFormers库中提供。</p><h3 id="有效的随机深度">有效的随机深度</h3><p>作者使用了一种改进的随机深度（stochastic depth）方法，相比于传统的掩码方法，该方法跳过了被丢弃的残差计算，从而在一定程度上节省了内存和计算资源。在本次实验中，使用高丢弃率（d=40%）时，这种方法使计算效率和内存使用效率得到了显著提高。具体实现方法是通过在批处理维度上随机重新排列B个样本，并在块计算中仅对前<span class="math inline">\((1-d)×B\)</span>个样本进行计算。</p><h3 id="完全共享数据并行fsdp">完全共享数据并行（FSDP）</h3><p>通过将模型副本分配到多个GPU中，可以将模型大小限制在GPU节点总内存的范围内。此外，FSDP的实现方式可以将权重片段存储为float32，但在传播权重和梯度时使用float16，从而降低跨GPU通信成本。相较于DistributedDataParallel（DDP）中使用的float32梯度all-reduce操作，使用Pytorch-FSDP混合精度训练的通信成本减少了约50％，在扩展GPU节点数量时训练过程更加高效。总的来说，Pytorch-FSDP混合精度训练在几乎所有情况下都优于使用autocast的DDP。</p><h3 id="模型蒸馏">模型蒸馏</h3><p>作者发现即使对于一个规模较大的ViT-L模型，他们的预训练方法也能够取得比从头开始训练更好的性能。此外，他们还提出了一种知识蒸馏方法，与A simple recipe for competitive low-compute self supervised vision models. arXiv preprint arXiv:2301.09451 所描述的方法相似，但没有修改蒸馏的损失项，并评估了学生模型的指数移动平均值。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;dino-v2笔记&quot;&gt;DINO-v2笔记&lt;/h1&gt;
&lt;p&gt;DINO-v2一种无监督学习的预训练方法，可以生成具有强大泛化能力的视觉特征，适用于各种图像分布和任务，而无需进行微调。这篇论文重点介绍了数据和模型规模方面的技术贡献，包括自动构建一个多样化和精心筛选的图像</summary>
      
    
    
    
    <category term="文字生成图片" scheme="https://studyinglover.com/categories/%E6%96%87%E5%AD%97%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87/"/>
    
    
  </entry>
  
  <entry>
    <title>快速上手llama2.c</title>
    <link href="https://studyinglover.com/2023/07/25/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c/"/>
    <id>https://studyinglover.com/2023/07/25/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8Bllama2.c/</id>
    <published>2023-07-25T16:19:00.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="快速上手llama2.c">快速上手llama2.c</h1><p><a href="https://github.com/karpathy/llama2.c.git">llama2.c</a>一个完整的解决方案，可以使用PyTorch从头开始训练的Llama 2 LLM（Lightweight Language Model）模型，并将权重导出为二进制文件，然后加载到一个简单的500行C文件（run.c）中进行推理。另外，你也可以加载、微调和推理Meta的Llama 2模型（但这部分仍在积极开发中）。因此，这个仓库提供了一个"全栈"的训练和推理方案，专注于极简和简洁性。你可能会认为只有拥有数十亿参数的LLM才能实现有用的功能，但事实上，如果领域足够狭窄，非常小的LLM也可以表现出惊人的性能。建议参考TinyStories论文以获得灵感。</p><p>需要注意的是，这个项目最初只是一个有趣的周末项目：作者在之前的nanoGPT基础上进行了调整，实现了Llama-2架构而不是GPT-2，并且主要的工作是编写了C推理引擎（run.c）。因此，这个项目还比较年轻，并且在快速发展中。特别感谢llama.cpp项目为此项目提供了灵感。作者希望保持超级简洁，所以选择了硬编码Llama 2架构，采用fp32精度，并仅使用纯C编写一个没有依赖项的推理文件。</p><p>首先clone整个仓库并编译 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/karpathy/llama2.c.git<br><span class="hljs-built_in">cd</span> llama.c<br>gcc -O3 -o run run.c -lm<br></code></pre></td></tr></table></figure></p><p>接下来下载模型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://karpathy.ai/llama2c/model.bin -P out<br></code></pre></td></tr></table></figure></p><p>或者下载更大的一个模型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://karpathy.ai/llama2c/model44m.bin -P out44m<br></code></pre></td></tr></table></figure></p><p>接下来进行推理 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./run out/model.bin<br></code></pre></td></tr></table></figure></p><p>我们将会看到这样一段输出就代表运行成功 <figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">&lt;s&gt;<br> One day, <span class="hljs-keyword">a</span> little otter named Ollie went <span class="hljs-built_in">to</span> play <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> river. Ollie was very compassionate. He loved <span class="hljs-built_in">to</span> help his friends <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> town.<br>While playing, Ollie saw <span class="hljs-keyword">a</span> big fish. The fish was stuck <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> mud. <span class="hljs-string">&quot;Help me, please!&quot;</span> said <span class="hljs-keyword">the</span> fish. Ollie wanted <span class="hljs-built_in">to</span> help <span class="hljs-keyword">the</span> fish. He swam away, looking <span class="hljs-keyword">for</span> something <span class="hljs-built_in">to</span> break <span class="hljs-keyword">the</span> mud.<br>Ollie found <span class="hljs-keyword">a</span> small stick. He used <span class="hljs-keyword">the</span> stick <span class="hljs-built_in">to</span> break <span class="hljs-keyword">the</span> mud. The fish was free! <span class="hljs-string">&quot;Thank you, Ollie!&quot;</span> <span class="hljs-keyword">the</span> fish said. The fish was happy <span class="hljs-keyword">and</span> swam away.<br>Ollie felt good <span class="hljs-keyword">for</span> helping <span class="hljs-keyword">the</span> fish. He went back <span class="hljs-built_in">to</span> play <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> river. Ollie knew that helping others made him feel good. And <span class="hljs-built_in">from</span> that day, Ollie was always compassionate <span class="hljs-built_in">to</span> everyone.<br>&lt;s&gt;<br> Tom was <span class="hljs-keyword">a</span> big boy who liked <span class="hljs-built_in">to</span> help his mom. He saw his mom doing laundry <span class="hljs-keyword">and</span> asked <span class="hljs-keyword">if</span> he could join. His mom said yes, but he had <span class="hljs-built_in">to</span> be careful <span class="hljs-keyword">with</span> <span class="hljs-keyword">the</span> iron. The iron was hot <span class="hljs-keyword">and</span> had <span class="hljs-keyword">a</span> button <span class="hljs-keyword">on</span> <span class="hljs-title">it</span>.<br>Tom took <span class="hljs-keyword">the</span> iron <span class="hljs-keyword">and</span> ran <span class="hljs-built_in">to</span> <span class="hljs-keyword">the</span> house. He wanted <span class="hljs-built_in">to</span> iron his shirt<br>achieved tok/s: <span class="hljs-number">178.148921</span><br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;快速上手llama2.c&quot;&gt;快速上手llama2.c&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/karpathy/llama2.c.git&quot;&gt;llama2.c&lt;/a&gt;一个完整的解决方案，可以使用PyTorch从头开始训练的Llama </summary>
      
    
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/tags/%E8%B8%A9%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>AnyDoor笔记</title>
    <link href="https://studyinglover.com/2023/07/24/AnyDoor%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/07/24/AnyDoor%E7%AC%94%E8%AE%B0/</id>
    <published>2023-07-24T19:39:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="anydoor笔记">AnyDoor笔记</h1><p>在这项工作中，香港大学，阿里联合提出了提出了 AnyDoor，这是一种基于扩散的生成器，可以进行对象隐形传态。这项研究的核心贡献是使用判别 ID 提取器和频率感知细节提取器来表征目标对象。在视频和图像数据的不同组合上进行训练，我们在场景图像的特定位置合成对象。AnyDoor 为一般区域到区域的映射任务提供了通用解决方案，并且可以为各种应用有利可图。</p><p><a href="https://damo-vilab.github.io/AnyDoor-Page/">项目地址</a></p><p>AnyDoor的模型架构图如下图所示，看起来还是比较清晰的，我们一部分一部分来看 <img src="https://cdn.studyinglover.com/pic/2023/07/84e8fadaba321d5eb9be47f710d22997.png" alt="image.png" /></p><h2 id="id特征提取器">ID特征提取器</h2><p>一般都选择CLIP的图像编码器编码一个图像对象。但是CLIP 是由粗略描述的文本对训练而来的，所以CLIP 只能给出一些语义上的描述，但是很难对每个物体的特征做出分辨。所以作者做出了两点更新，背景移除和自监督的表示。</p><p>对应到整个pipeline就是这部分 <img src="https://cdn.studyinglover.com/pic/2023/07/e22b104405f6f2e4ace7a680c6d44e23.png" alt="image.png" /></p><h3 id="背景移除">背景移除</h3><p>背景移除就是使用一个分割模型将背景删除，然后将目标物体和背景中心对齐。可以使用一些自动的模型(例如Segment Anything),和可交互式的模型</p><h3 id="自监督的表示">自监督的表示</h3><p>作者说在这个工作中他们发现自监督的模型可以很好的保留物体的判别特征。在大规模数据集上进行预训练，自监督模型自然配备了实例检索能力，可以将对象投影到增强不变的特征空间(augmentation-invariant feature space，经过抱大佬大腿，这个特征空间是说经过图像增强语义不变)中。作者采用了DINO2作为编码器，得到了一个全局的特征<span class="math inline">\(\mathbf{T}_{\mathrm{g}}^{1 \times 1536}\)</span> 和一个局部的特征<span class="math inline">\(\mathbf{T}_{\mathrm{p}}^{256 \times 1536}\)</span> ,使用一个线性层将这两个向量投影到UNet需要的维度，然后合并俩个向量使用，最后的向量是<span class="math inline">\(\mathbf{T}_{\text {ID }}^{257 \times 1024}\)</span></p><h2 id="细节特征提取">细节特征提取</h2><p>作者认为，由于 ID 令牌会丢失空间分辨率，因此它们很难充分保持目标对象的精细细节。所以使用互补的细节作为生成过程中额外的指导。</p><p>使用拼贴作为控件可以提供强大的先验，作者尝试将“背景移除的对象”缝合到场景图像的给定位置。通过这个拼贴，可以观察到生成保真度的显着改进，但生成的结果与缺乏多样性的给定目标过于相似。面对这个问题，作者探索设置信息瓶颈以防止拼贴给出太多外观约束。实际上就是设计了一个高频映射来表示对象，它可以保持精细细节，但允许通用的局部变体，如手势、照明、方向等。</p><p>对应pipeline的这部分， <img src="https://cdn.studyinglover.com/pic/2023/07/02e880c65b826610ff0afc47e939fc40.png" alt="image.png" /></p><p>作者使用了这样一个公式来提取高频图<span class="math display">\[\mathbf{I}_h=\left(\mathbf{I} \otimes \mathbf{K}_h+\mathbf{I} \otimes \mathbf{K}_v\right) \odot \mathbf{I} \odot \mathbf{M}_{\text {erode }}\]</span> <span class="math inline">\(\mathbf{I}\)</span> 是一张RGB的图像(上一步背景移除得到的图片),<span class="math inline">\(\mathbf{K}_h\)</span> 和<span class="math inline">\(\mathbf{K}_v\)</span> 是水平和垂直Sobel kernel，这里被用作高频滤波器，<span class="math inline">\(\otimes\)</span>代表卷积,<span class="math inline">\(\odot\)</span>代表逐元素乘法。侵蚀掩码 <span class="math inline">\(\mathbf{M}_{\text {erode }}\)</span> 来过滤目标对象外部轮廓附近的信息。</p><p>在得到高频图后，根据给定的位置将其拼接到场景图像上，然后将拼贴传递给细节提取器。细节提取器是一个 ControlNet 中的UNet 编码器，它生成一系列具有分层分辨率的细节图。</p><h2 id="特征注入">特征注入</h2><p>在获得 ID 标记和细节图后，将它们注入到预训练的文本到图像扩散模型中以指导生成。作者选择了stable diffusion，它将图像投影到潜在空间中，并使用UNet进行概率采样。我们注意到预训练的 UNet 为 <span class="math inline">\(\hat{\mathbf{x}}_\theta\)</span> ，它从初始潜在噪声 <span class="math inline">\(\epsilon \sim \mathcal{U}([0,1])\)</span>开始去噪，并将文本嵌入 c 作为生成新图像潜在 的条件。训练监督是均方误差损失为<span class="math display">\[\mathbb{E}_{\mathbf{x},\mathbf{c},\epsilon,t}(\|\hat{\mathbf{x}}_\theta(\alpha_t\mathbf{x}+\sigma_t\epsilon,\mathbf{c})-\mathbf{x}\|_2^2)\]</span> <span class="math inline">\(\mathbf{x}\)</span> 是ground-truth,t是反向过程的步数,<span class="math inline">\(\alpha_t\)</span> <span class="math inline">\(\sigma_t\)</span> 是去噪的超参数。</p><p>在这项工作中，文本嵌入 c 被替换为前面的 ID 标记，这些标记通过交叉注意注入到每个 UNet 层。对于细节图，将它们与每个分辨率的 UNet 解码器特征连接起来。在训练期间，模型冻结 UNet 编码器的预训练参数以保留先验并调整 UNet 解码器以适应我们的新任务。</p><h2 id="训练策略">训练策略</h2><h3 id="图像文本对">图像文本对</h3><p>理想的训练样本是“不同场景中同一对象”的图像对，但是这些数据集不能直接由现有数据集提供。作为替代方案，以前的工作利用单个图像并应用旋转、翻转和弹性变换等增强。然而，这些幼稚的增强不能很好地代表姿势和视图的真实变体。</p><p>为了解决这个问题，在这项工作中，作者使用视频数据集来捕获包含相同对象的不同帧。</p><h3 id="自适应的训练步长">自适应的训练步长</h3><p>虽然视频数据有利于学习外观变化，但由于分辨率低或运动模糊，帧质量通常不能令人满意。相比之下，图像可以提供高质量的细节和通用的场景，但缺乏外观变化。</p><p>为了利用视频数据和图像数据，作者开发了自适应时间步采样，使不同模态的数据有利于去噪训练的不同阶段。stable dissusion为每个训练数据均匀地采样时间步长 (T)。然而，观察到初始去噪步骤主要集中在生成整体结构、姿势和视图；后面的步骤涵盖了纹理和颜色等精细细节 。因此，对于视频数据，可以增加了在训练期间采样早期去噪步骤（大 T）以更好地学习外观变化的可能性。对于图像，增加了后期步骤（小 T）的概率来学习如何覆盖精细细节。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;anydoor笔记&quot;&gt;AnyDoor笔记&lt;/h1&gt;
&lt;p&gt;在这项工作中，香港大学，阿里联合提出了提出了 AnyDoor，这是一种基于扩散的生成器，可以进行对象隐形传态。这项研究的核心贡献是使用判别 ID 提取器和频率感知细节提取器来表征目标对象。在视频和图像数据的</summary>
      
    
    
    
    <category term="文字生成图片" scheme="https://studyinglover.com/categories/%E6%96%87%E5%AD%97%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87/"/>
    
    
  </entry>
  
  <entry>
    <title>Archlinux安装scrcpy加载共享库出错 error while loading shared libraries:libusb-1.0.so.0:wrong ELF class:ELFCLASS32</title>
    <link href="https://studyinglover.com/2023/07/21/Archlinux%E5%AE%89%E8%A3%85scrcpy%E5%8A%A0%E8%BD%BD%E5%85%B1%E4%BA%AB%E5%BA%93%E5%87%BA%E9%94%99/"/>
    <id>https://studyinglover.com/2023/07/21/Archlinux%E5%AE%89%E8%A3%85scrcpy%E5%8A%A0%E8%BD%BD%E5%85%B1%E4%BA%AB%E5%BA%93%E5%87%BA%E9%94%99/</id>
    <published>2023-07-21T16:13:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="archlinux安装scrcpy加载共享库出错">Archlinux安装scrcpy加载共享库出错</h1><p>在安装scrcpy时通过<code>sudo pacman -S scrcpy</code>顺利安装,但是运行报错 <figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vbnet"><span class="hljs-symbol">scrcpy:</span> <span class="hljs-keyword">error</span> <span class="hljs-keyword">while</span> loading <span class="hljs-keyword">shared</span> libraries: libusb-<span class="hljs-number">1.0</span>.so.<span class="hljs-number">0</span>: wrong ELF <span class="hljs-keyword">class</span>: ELFCLASS32<br></code></pre></td></tr></table></figure></p><p>这是在64位系统上运行32位库出错，我发现了这个10年的issue https://github.com/Rouji/Ergodone-Setup/issues/1 也就是说我们只需要运行<code>sudo pacman -S libusb-compat</code></p><p>但是运行之后出现了新的问题 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">libusb</span>-compat: 文件系统中已存在 /usr/lib/libusb-<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.so.<span class="hljs-number">4</span> <br><span class="hljs-attribute">libusb</span>-compat: 文件系统中已存在 /usr/lib/libusb-<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.so.<span class="hljs-number">4</span>.<span class="hljs-number">4</span>.<span class="hljs-number">4</span> <br><span class="hljs-attribute">libusb</span>-compat: 文件系统中已存在 /usr/lib/libusb-<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.so.<span class="hljs-number">4</span>.<span class="hljs-number">4</span>.<span class="hljs-number">4</span> <br></code></pre></td></tr></table></figure></p><p>一般来说已经有的库就不要动它了，运行<code>sudo pacman -Syu</code> 没有解决，会报同样的错误，说明libusb这个文件不是包管理器提供的，那就删掉现有的库然后让pacman帮我们安装</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sudo</span> rm -f /usr/lib/libusb-<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.so.<span class="hljs-number">4</span> <br><span class="hljs-attribute">sudo</span> rm -f /usr/lib/libusb-<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.so.<span class="hljs-number">4</span>.<span class="hljs-number">4</span>.<span class="hljs-number">4</span> <br><span class="hljs-attribute">sudo</span> rm -f /usr/lib/libusb-<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.so.<span class="hljs-number">4</span>.<span class="hljs-number">4</span>.<span class="hljs-number">4</span> <br><span class="hljs-attribute">sudo</span> pacman -S libusb-compat<br></code></pre></td></tr></table></figure><p>插上手机，运行<code>scrcpy</code>,成功运行</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;archlinux安装scrcpy加载共享库出错&quot;&gt;Archlinux安装scrcpy加载共享库出错&lt;/h1&gt;
&lt;p&gt;在安装scrcpy时通过&lt;code&gt;sudo pacman -S scrcpy&lt;/code&gt;顺利安装,但是运行报错 &lt;figure class=&quot;</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
    <category term="ArchLinux" scheme="https://studyinglover.com/tags/ArchLinux/"/>
    
  </entry>
  
  <entry>
    <title>npc_gzip笔记</title>
    <link href="https://studyinglover.com/2023/07/18/npc_gzip%E7%AC%94%E8%AE%B0/"/>
    <id>https://studyinglover.com/2023/07/18/npc_gzip%E7%AC%94%E8%AE%B0/</id>
    <published>2023-07-18T16:57:00.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="npc_gzip笔记">npc_gzip笔记</h1><h2 id="论文笔记">论文笔记</h2><p>npc_gzip 的论文名叫做 "Low-Resource" Text Classification: A Parameter-Free Classification Method with Compressors ,意为不需要参数，使用压缩器的文本分类方法。论文的代码也只有仅仅的十四行，就在部分数据集上取得了超越 <strong>bert</strong> 的效果。</p><p>npc_gzip由一个无损压缩器，一个基于距离的度量函数和K近邻算法组成。</p><p>使用压缩器进行分类的直觉是有两方面 1. 压缩器擅长捕捉规律性；<br />2. 来自同一类别的对象比不同类别的对象具有更多的规律性。</p><p>假设<span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> 属于相同的类别，<span class="math inline">\(x_3\)</span> 属于不同的类别，用<span class="math inline">\(C(\cdot)\)</span> 代表压缩器， 我们会发现<span class="math inline">\(C\left(x_1 x_2\right)-C\left(x_1\right)&lt;C\left(x_1 x_3\right)-C\left(x_1\right)\)</span> , <span class="math inline">\(C\left(x_1 x_2\right)\)</span> 代表 x1 和 x2 的串联的压缩长度。换句话说<span class="math inline">\(C\left(x_1 x_2\right)\)</span> 可以解释为我们仍然需要根据 x1 的信息对 x2 进行编码多少字节： <figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs erlang">x1 = Japan&#x27;s Seiko Epson Corp. has developed a <span class="hljs-number">12</span>-gram flying microrobot.<br><br>x2 = The latest tiny flying robot has been unveiled in Japan.<br><br>x3 = Michael Phelps won the gold medal in the <span class="hljs-number">400</span> individual medley.<br></code></pre></td></tr></table></figure></p><p>这种直觉可以形式化为源自 Kolmogorov 复杂度的距离度量。Kolmogorov 复杂度 K(x) 表征了可以生成 x 的最短二进制程序的长度。K(x) 理论上是信息测量的最终下限。</p><p><span class="math display">\[\begin{aligned} E(x, y) &amp; =\max \{K(x \mid y), K(y \mid x)\} \\ &amp; =K(x y)-\min \{K(x), K(y)\}\end{aligned}\]</span></p><p>由于 Kolmogorov 复杂度的可计算性质使得 E(x,y) 不可计算，所以可以使用归一化压缩距离 (NCD)，利用压缩长度 C(x) 来近似 Kolmogorov 复杂度 K(x)。形式上是<span class="math display">\[N C D(x, y)=\frac{C(x y)-\min \{C(x), C(y)\}}{\max \{C(x), C(y)\}}\]</span> 使用压缩长度背后的直觉是压缩器最大压缩的 x 的长度接近 K(x)。一般来说，压缩比越高，C(x)越接近K(x)。</p><p>实验的结果使用 gzip 作为压缩器，这里的<span class="math inline">\(C(x)\)</span> 表示 gzip 压缩后 x 的长度。<span class="math inline">\(C(xy)\)</span> 是 x 和 y 的串联的压缩长度。NCD 提供距离矩阵使用 k-最近邻来执行分类。</p><p>核心代码真的真的就非常简单了 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> gzip2 <br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">for</span> ( x1 , _ ) <span class="hljs-keyword">in</span> test_set :<br>Cx1 = <span class="hljs-built_in">len</span> ( gzip . compress ( x1 . encode () ) )<br>distance_from_x1 = []<br><span class="hljs-keyword">for</span> ( x2 , _ ) <span class="hljs-keyword">in</span> training_set :<br>Cx2 = <span class="hljs-built_in">len</span> ( gzip . compress ( x2 . encode () )<br>x1x2 = <span class="hljs-string">&quot; &quot;</span> . join ([ x1 , x2 ])<br>Cx1x2 = <span class="hljs-built_in">len</span> ( gzip . compress ( x1x2 . encode () )<br>ncd = ( Cx1x2 - <span class="hljs-built_in">min</span> ( Cx1 , Cx2 )) / <span class="hljs-built_in">max</span> ( Cx1 , Cx2 )<br>distance_from_x1 . append ( ncd )<br>sorted_idx = np . argsort ( np . array ( distance_from_x1 ) )<br>top_k_class = training_set [ sorted_idx [: k ] , <span class="hljs-number">1</span>]<br>predict_class = <span class="hljs-built_in">max</span> ( <span class="hljs-built_in">set</span> ( top_k_class ) , key = top_k_class . count )<br></code></pre></td></tr></table></figure></p><p>这种方法是 DNN 的简单、轻量级和通用的替代方案。很简单，因为它不需要任何预处理或训练。它的轻量级在于它不需要参数或 GPU 资源进行分类。由于压缩器是数据类型不可知的，非参数方法不会带来潜在的假设。</p><h2 id="代码实践">代码实践</h2><p>作者在GitHub上开源了他的代码 <a href="https://github.com/bazingagin/npc_gzip">npc_gzip</a> .我们先把代码拉到本地 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/bazingagin/npc_gzip<br></code></pre></td></tr></table></figure> 接下来安装依赖项，有条件的话创建一个虚拟环境 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ./npc_gzip<br>pip install -r requirements.txt<br></code></pre></td></tr></table></figure></p><p>安装完了之后运行<code>main_text.py</code> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python main_text.py<br></code></pre></td></tr></table></figure></p><p>注意，如果你遇到了这个问题 <figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">Traceback (most recent <span class="hljs-keyword">call</span> last):<br>  File &quot;main_text.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">2</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    <span class="hljs-keyword">from</span> data <span class="hljs-keyword">import</span> *<br>  File &quot;/home/npc_gzip/data.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">12</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    <span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br>  File &quot;/home/.conda/envs/npc_gzip/lib/python3.7/site-packages/datasets/__init__.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">43</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    <span class="hljs-keyword">from</span> .arrow_dataset <span class="hljs-keyword">import</span> Dataset<br>  File &quot;/home/.conda/envs/npc_gzip/lib/python3.7/site-packages/datasets/arrow_dataset.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">59</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    <span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi, HfFolder<br>  File &quot;/home/.conda/envs/npc_gzip/lib/python3.7/site-packages/huggingface_hub/__init__.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">322</span>, <span class="hljs-keyword">in</span> __getattr__<br>    submod = importlib.import_module(submod_path)<br>  File &quot;/home/.conda/envs/npc_gzip/lib/python3.7/importlib/__init__.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">127</span>, <span class="hljs-keyword">in</span> import_module<br>    <span class="hljs-keyword">return</span> _bootstrap._gcd_import(<span class="hljs-type">name</span>[<span class="hljs-keyword">level</span>:], package, <span class="hljs-keyword">level</span>)<br>  File &quot;/home/.conda/envs/npc_gzip/lib/python3.7/site-packages/huggingface_hub/hf_api.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">32</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    <span class="hljs-keyword">import</span> requests<br>  File &quot;/home/.conda/envs/npc_gzip/lib/python3.7/site-packages/requests/__init__.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">43</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    <span class="hljs-keyword">import</span> urllib3<br>  File &quot;/home/.conda/envs/npc_gzip/lib/python3.7/site-packages/urllib3/__init__.py&quot;, <span class="hljs-type">line</span> <span class="hljs-number">42</span>, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    &quot;urllib3 v2.0 only supports OpenSSL 1.1.1+, currently &quot;<br>ImportError: urllib3 v2<span class="hljs-number">.0</span> <span class="hljs-keyword">only</span> supports OpenSSL <span class="hljs-number">1.1</span><span class="hljs-number">.1</span>+, currently the <span class="hljs-string">&#x27;ssl&#x27;</span> module <span class="hljs-keyword">is</span> compiled <span class="hljs-keyword">with</span> <span class="hljs-string">&#x27;OpenSSL 1.0.2u  20 Dec 2019&#x27;</span>. See: https://github.com/urllib3/urllib3/issues/<span class="hljs-number">2168</span><br></code></pre></td></tr></table></figure></p><p>urllib3 v2.0（您安装的版本）需要 OpenSSL 1.1.1+ 才能正常工作，因为它依赖于 OpenSSL 1.1 的一些新功能.</p><p>安装旧版本即可解决 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install urllib3==1.26.6 <br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;npc_gzip笔记&quot;&gt;npc_gzip笔记&lt;/h1&gt;
&lt;h2 id=&quot;论文笔记&quot;&gt;论文笔记&lt;/h2&gt;
&lt;p&gt;npc_gzip 的论文名叫做 &quot;Low-Resource&quot; Text Classification: A Parameter-Free Classifi</summary>
      
    
    
    
    <category term="自然语言处理" scheme="https://studyinglover.com/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
    
  </entry>
  
  <entry>
    <title>python调用c++函数</title>
    <link href="https://studyinglover.com/2023/07/15/python%E8%B0%83%E7%94%A8c++%E5%87%BD%E6%95%B0/"/>
    <id>https://studyinglover.com/2023/07/15/python%E8%B0%83%E7%94%A8c++%E5%87%BD%E6%95%B0/</id>
    <published>2023-07-15T09:30:00.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="python调用c函数">python调用c++函数</h1><p>当我们需要在Python中使用C++编写的函数时，可以将C++代码编译成共享库文件（.so文件），然后来调用这些函数。这里介绍两种方法。</p><h2 id="使用python的api">使用python的api</h2><p>首先要安装安装<code>python-dev</code> 和<code>cmake</code></p><p>在Archlinux下<code>yay python-dev</code> ，<code>yay cmake</code>即可。其他平台需要自行搜索</p><p>首先创建一个C++文件 <code>main.cpp</code> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;Python.h&gt;</span></span><br>  <br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span> </span>&#123;<br><span class="hljs-keyword">return</span> a + b;<br>&#125;<br>  <br><span class="hljs-function"><span class="hljs-type">static</span> PyObject* <span class="hljs-title">py_add</span><span class="hljs-params">(PyObject* self, PyObject* args)</span> </span>&#123;<br><span class="hljs-type">int</span> a, b;<br><span class="hljs-keyword">if</span> (!<span class="hljs-built_in">PyArg_ParseTuple</span>(args, <span class="hljs-string">&quot;ii&quot;</span>, &amp;a, &amp;b)) &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>&#125;<br><span class="hljs-type">int</span> result = <span class="hljs-built_in">add</span>(a, b);<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">PyLong_FromLong</span>(result);<br>&#125;<br>  <br><span class="hljs-type">static</span> PyMethodDef module_methods[] = &#123;<br>&#123;<span class="hljs-string">&quot;add&quot;</span>, py_add, METH_VARARGS, <span class="hljs-string">&quot;Add two integers.&quot;</span>&#125;,<br>&#123;<span class="hljs-literal">NULL</span>, <span class="hljs-literal">NULL</span>, <span class="hljs-number">0</span>, <span class="hljs-literal">NULL</span>&#125;<br>&#125;;<br>  <br><span class="hljs-type">static</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">PyModuleDef</span> module_def = &#123;<br>PyModuleDef_HEAD_INIT,<br><span class="hljs-string">&quot;my_module&quot;</span>,<br><span class="hljs-string">&quot;My custom module.&quot;</span>,<br><span class="hljs-number">-1</span>,<br>module_methods<br>&#125;;<br>  <br><span class="hljs-function">PyMODINIT_FUNC <span class="hljs-title">PyInit_my_module</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> </span>&#123;<br><span class="hljs-keyword">return</span> <span class="hljs-built_in">PyModule_Create</span>(&amp;module_def);<br>&#125;<br></code></pre></td></tr></table></figure></p><p>接着用cmake构建<code>.so</code>文件，<code>CMakeLists.txt</code> 内容如下 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs CMakeLists">cmake_minimum_required(VERSION 3.0)<br>  <br>project(my_module)<br>  <br>find_package(Python REQUIRED COMPONENTS Interpreter Development)<br>  <br>add_library(my_module SHARED main.cpp)<br>  <br>target_include_directories(my_module PRIVATE $&#123;Python_INCLUDE_DIRS&#125;)<br>target_link_libraries(my_module PRIVATE $&#123;Python_LIBRARIES&#125;)<br>  <br>set_target_properties(my_module PROPERTIES PREFIX &quot;&quot;)<br>set_target_properties(my_module PROPERTIES SUFFIX &quot;.so&quot;)<br></code></pre></td></tr></table></figure></p><p>构建完成后会有一个名为<code>my_module.so</code> 的文件</p><p>接下来使用python调用,注意将python文件和<code>my_module.so</code> 放到同一个目录下 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> my_module<br>  <br>result = my_module.add(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure></p><h2 id="按照-c-语言的规则来编译和链接">按照 C 语言的规则来编译和链接</h2><p>首先，我们需要编写一个C++文件<code>mylib.cpp</code> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">extern</span> <span class="hljs-string">&quot;C&quot;</span> <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-type">int</span> a, <span class="hljs-type">int</span> b)</span> </span>&#123;<br>    <span class="hljs-keyword">return</span> a + b;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>接下来，编译<code>mylib.cpp</code> 为一个<code>.so</code>文件 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">g++ -shared -o mylib.so -fPIC mylib.cpp<br></code></pre></td></tr></table></figure></p><p>最后使用python加载<code>mylib.so</code> 文件并调用 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> ctypes<br><br><span class="hljs-comment"># 加载共享库文件</span><br>mylib = ctypes.cdll.LoadLibrary(<span class="hljs-string">&#x27;./mylib.so&#x27;</span>)<br><br>result = mylib.add(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;python调用c函数&quot;&gt;python调用c++函数&lt;/h1&gt;
&lt;p&gt;当我们需要在Python中使用C++编写的函数时，可以将C++代码编译成共享库文件（.so文件），然后来调用这些函数。这里介绍两种方法。&lt;/p&gt;
&lt;h2 id=&quot;使用python的api&quot;&gt;使用</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
  </entry>
  
  <entry>
    <title>Filesystem type ntfs3,ntfs not configured in kernel</title>
    <link href="https://studyinglover.com/2023/07/14/Filesystem%20type%20ntfs3,ntfs%20not%20configured%20in%20kernel/"/>
    <id>https://studyinglover.com/2023/07/14/Filesystem%20type%20ntfs3,ntfs%20not%20configured%20in%20kernel/</id>
    <published>2023-07-14T09:35:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="filesystem-type-ntfs3ntfs-not-configured-in-kernel">Filesystem type ntfs3,ntfs not configured in kernel</h1><p>昨天卸载硬盘的时候卡住了，然后我就直接拔下了硬盘，再插上就出现了这个问题 <img src="https://cdn.studyinglover.com/pic/2023/07/7da166adca81943084fbc25dae0a3e16.png" alt="image.png" /></p><p>我先用备份恢复了一下，但是重新插上硬盘问题依然存在。接下来google了一下，Archwiki中有提到<a href="https://wiki.archlinux.org/title/NTFS">这个问题</a>，但是标记这个问题是已经过时的，所描述的问题已得到解决。从内核版本6.2开始，ntfs3支持<code>windows_names</code>选项。我就先按照文档说的做了，但是问题依然没有解决。 <img src="https://cdn.studyinglover.com/pic/2023/07/92f0be4c455602d2eda6b9ecd6229969.png" alt="image.png" /></p><p>接下来翻了下reddit，发现有人存在类似的问题 https://www.reddit.com/r/archlinux/comments/s3w6uu/cannot_mount_ntfs_drives_on_516/ ， 有人提到需要安装<code>ntfs-3g</code> ,那么就是 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">yay ntfs-3g<br></code></pre></td></tr></table></figure></p><p>问题解决</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;filesystem-type-ntfs3ntfs-not-configured-in-kernel&quot;&gt;Filesystem type ntfs3,ntfs not configured in kernel&lt;/h1&gt;
&lt;p&gt;昨天卸载硬盘的时候卡住了，然后我就直接拔</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
  </entry>
  
  <entry>
    <title>open_clip编码图像和文本</title>
    <link href="https://studyinglover.com/2023/07/13/open_clip%E7%BC%96%E7%A0%81%E5%9B%BE%E5%83%8F%E5%92%8C%E6%96%87%E6%9C%AC/"/>
    <id>https://studyinglover.com/2023/07/13/open_clip%E7%BC%96%E7%A0%81%E5%9B%BE%E5%83%8F%E5%92%8C%E6%96%87%E6%9C%AC/</id>
    <published>2023-07-13T23:14:00.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<p>open_clip是CLIP的开源实现版本，只训练了CLIP效果最好的几个模型。</p><p>安装是 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install open_clip_torch<br></code></pre></td></tr></table></figure></p><p>首先导入 open_clip，并创建相关模型 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> open_clip<br><span class="hljs-keyword">import</span> torch<br><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>clip_model_name = <span class="hljs-string">&quot;ViT-L-14&quot;</span><br>clip_model,_,clip_preprocess = open_clip.create_model_and_transforms(clip_model_name<br>clip_model_name,pretrained = <span class="hljs-string">&quot;openai&quot;</span>,precision=<span class="hljs-string">&#x27;fp16&#x27;</span> <span class="hljs-keyword">if</span> device == <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;fp32&#x27;</span>,device=device,<br>)<br><br>tokenize = open_clip.get_tokenizer(clip_model_name)<br></code></pre></td></tr></table></figure></p><p><code>tokenize</code> 是分词器，所有的文本都要先经过分析器才能放入模型进行推理。</p><h4 id="编码图像">编码图像</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">image_to_features</span>(<span class="hljs-params">image: Image.Image</span>) -&gt; torch.Tensor:<br>images = clip_preprocess(image).unsqueeze(<span class="hljs-number">0</span>).to(device)<br><span class="hljs-keyword">with</span> torch.no_grad(), torch.cuda.amp.autocast():<br>image_features = clip_model.encode_image(images)<br><span class="hljs-keyword">return</span> image_features<br>  <br>img = cv.imread(<span class="hljs-string">&quot;/path/to/example.png&quot;</span>)<br>img = Image.fromarray(img)<br><br>image_feature = image_to_features(img)<br></code></pre></td></tr></table></figure><p><code>/path/to/example.png</code> 替换成自己图片的路径</p><p><code>image_to_features</code> 函数是一个封装过的将图像转成文本的函数，传入的参数是一个<code>image_to_features</code>格式的图片。</p><p><code>image_feature</code> 就是经过CLIP的编码器得到的特征</p><h4 id="编码文本">编码文本</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">prompt = <span class="hljs-string">&quot;a photo of a cat&quot;</span><br>text_tokens = tokenize([prompt]).to(device)<br>text_features = clip_model.encode_text(text_tokens)<br></code></pre></td></tr></table></figure><p><code>text_features</code> 就是得到的特征。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;open_clip是CLIP的开源实现版本，只训练了CLIP效果最好的几个模型。&lt;/p&gt;
&lt;p&gt;安装是 &lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;</summary>
      
    
    
    
    <category term="多模态" scheme="https://studyinglover.com/categories/%E5%A4%9A%E6%A8%A1%E6%80%81/"/>
    
    
  </entry>
  
  <entry>
    <title>PicGo配置CloudflareR2图片储存</title>
    <link href="https://studyinglover.com/2023/07/09/PicGo%E9%85%8D%E7%BD%AECloudflareR2%E5%9B%BE%E7%89%87%E5%82%A8%E5%AD%98/"/>
    <id>https://studyinglover.com/2023/07/09/PicGo%E9%85%8D%E7%BD%AECloudflareR2%E5%9B%BE%E7%89%87%E5%82%A8%E5%AD%98/</id>
    <published>2023-07-09T20:24:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="picgo配置cloudflarer2图片储存">PicGo配置CloudflareR2图片储存</h1><p>首先需要安装PicGo,并购买CloudFlare R2。CloudFlare R2选择免费计划即可，只是需要绑定银行卡或者paypal(淘宝两块钱解君忧)。</p><p>在R2的管理界面选择管理R2 API Tokens， <img src="https://cdn.studyinglover.com/pic/2023/07/c5fa048794dc5eab45d6e83efef1df8e.png" alt="image.png" /></p><p>创建一个API Token <img src="https://cdn.studyinglover.com/pic/2023/07/eed2d1b23fb75a7abc5ac334688baba7.png" alt="image.png" /> 注意选择权限为edit <img src="https://cdn.studyinglover.com/pic/2023/07/0a7ece4445c1a2f190adc2dd82351f62.png" alt="image.png" /></p><p>创建API Token之后，保存Access Key ID和Secret Access Key。</p><p>接下来返回R2的管理界面，创建一个储存桶 <img src="https://cdn.studyinglover.com/pic/2023/07/6de3892cb5f8a0bf1c53bb83d2070ca6.png" alt="image.png" /> 填入名字并创建桶，点击进入储存桶的管理界面，进入setting界面。 <img src="https://cdn.studyinglover.com/pic/2023/07/674ad9e98a4d4c064cd135353f967fce.png" alt="image.png" /></p><p>自定义自己的域名并允许公开访问，选择Connect Domain绑定到自己的域名，选择AllowAccess允许公开访问。 <img src="https://cdn.studyinglover.com/pic/2023/07/135bb11e6b475ed4d7acdf491003cf52.png" alt="image.png" /></p><p>接下来打开PicGo,安装s3插件 <img src="https://cdn.studyinglover.com/pic/2023/07/bc0d82dee02bc1a2b114477b827b125c.png" alt="image.png" /></p><p>应用密钥ID和应用密钥填入在API Token获取的Access Key ID和Secret Access Key，桶名填入创建的桶的名称，自定义节点填入储存桶管理界面中途中对应的路径。自定义域名填入前面绑定的自己的域名。 <img src="https://cdn.studyinglover.com/pic/2023/07/0c0cc997c92cd807ecb48c3b2b08e394.png" alt="image.png" /></p><p>尝试上传不出意外就上传成功了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;picgo配置cloudflarer2图片储存&quot;&gt;PicGo配置CloudflareR2图片储存&lt;/h1&gt;
&lt;p&gt;首先需要安装PicGo,并购买CloudFlare R2。CloudFlare R2选择免费计划即可，只是需要绑定银行卡或者paypal(淘宝两块钱解</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
  </entry>
  
  <entry>
    <title>ArchlinuxGnome快捷键打开终端</title>
    <link href="https://studyinglover.com/2023/06/28/ArchlinuxGnome%E9%85%8D%E7%BD%AE%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%89%93%E5%BC%80%E7%BB%88%E7%AB%AF/"/>
    <id>https://studyinglover.com/2023/06/28/ArchlinuxGnome%E9%85%8D%E7%BD%AE%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%89%93%E5%BC%80%E7%BB%88%E7%AB%AF/</id>
    <published>2023-06-28T19:30:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<p>网上大量教程说命令打开终端的命令是<code>gnome-terminal</code> ， 然而</p><figure><img src="https://proxy.thisis.plus/202306281925975.png" alt="" /><figcaption>image.png</figcaption></figure><p>经过一番搜索，我发现 https://www.omglinux.com/gnome-console-tab-overview/ <img src="https://proxy.thisis.plus/202306281927089.png" alt="image.png" /></p><p>emmmmm,意思是终端命令是<code>kgx</code> ?</p><p>果然，又被一些教程坑了 <img src="https://proxy.thisis.plus/202306281928138.png" alt="image.png" /></p><p>最后配置如图 <img src="https://proxy.thisis.plus/202306211810384.png" alt="image.png" /></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;网上大量教程说命令打开终端的命令是&lt;code&gt;gnome-terminal&lt;/code&gt; ， 然而&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;https://proxy.thisis.plus/202306281925975.png&quot; alt=&quot;&quot; /&gt;&lt;figcapt</summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
    <category term="ArchLinux" scheme="https://studyinglover.com/tags/ArchLinux/"/>
    
  </entry>
  
  <entry>
    <title>clip-interrogator代码解析</title>
    <link href="https://studyinglover.com/2023/06/23/clip-interrogator%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <id>https://studyinglover.com/2023/06/23/clip-interrogator%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/</id>
    <published>2023-06-23T22:59:40.000Z</published>
    <updated>2023-08-06T15:02:45.498Z</updated>
    
    <content type="html"><![CDATA[<h1 id="clip-interrogator代码解析">clip-interrogator代码解析</h1><p>clip-interrogator 的的主要代码在仓库的<code>./clip-interrogator</code> 文件夹下 <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs stylus">.<br>├── clip_interrogator<span class="hljs-selector-class">.py</span><br>├── data<br>│   ├── artists<span class="hljs-selector-class">.txt</span><br>│   ├── flavors<span class="hljs-selector-class">.txt</span><br>│   ├── mediums<span class="hljs-selector-class">.txt</span><br>│   ├── movements<span class="hljs-selector-class">.txt</span><br>│   └── negative<span class="hljs-selector-class">.txt</span><br>└── __init__<span class="hljs-selector-class">.py</span><br><br></code></pre></td></tr></table></figure></p><p>这里主要解析<code>clip-interrogator.py</code> 文件。</p><h2 id="init.py"><strong>init</strong>.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> .clip_interrogator <span class="hljs-keyword">import</span> Config, Interrogator, LabelTable, list_caption_models, list_clip_models, load_list<br><br>__version__ = <span class="hljs-string">&#x27;0.6.0&#x27;</span><br>__author__ = <span class="hljs-string">&#x27;pharmapsychotic&#x27;</span><br></code></pre></td></tr></table></figure><p>这个 <code>__init__.py</code> 文件的作用是在包被导入时执行初始化操作，并提供了版本号和作者信息。</p><h2 id="clip_interrogator.py">clip_interrogator.py</h2><p>文件的大致结构是这样的 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> 需要的库<br><br>CAPTION_MODELS = &#123;<br><span class="hljs-string">&#x27;blip-base&#x27;</span>: <span class="hljs-string">&#x27;Salesforce/blip-image-captioning-base&#x27;</span>, <span class="hljs-comment"># 990MB</span><br><span class="hljs-string">&#x27;blip-large&#x27;</span>: <span class="hljs-string">&#x27;Salesforce/blip-image-captioning-large&#x27;</span>, <span class="hljs-comment"># 1.9GB</span><br><span class="hljs-string">&#x27;blip2-2.7b&#x27;</span>: <span class="hljs-string">&#x27;Salesforce/blip2-opt-2.7b&#x27;</span>, <span class="hljs-comment"># 15.5GB</span><br><span class="hljs-string">&#x27;blip2-flan-t5-xl&#x27;</span>: <span class="hljs-string">&#x27;Salesforce/blip2-flan-t5-xl&#x27;</span>, <span class="hljs-comment"># 15.77GB</span><br><span class="hljs-string">&#x27;git-large-coco&#x27;</span>: <span class="hljs-string">&#x27;microsoft/git-large-coco&#x27;</span>, <span class="hljs-comment"># 1.58GB</span><br>&#125;<br><br>CACHE_URL_BASE = <span class="hljs-string">&#x27;https://huggingface.co/pharma/ci-preprocess/resolve/main/&#x27;</span><br><br><span class="hljs-meta">@dataclass</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Config</span>:<br>    具体实现<br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Interrogator</span>():<br>    具体实现<br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LabelTable</span>():<br>    具体实现<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_download_file</span>(<span class="hljs-params">url: <span class="hljs-built_in">str</span>, filepath: <span class="hljs-built_in">str</span>, chunk_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">4</span>*<span class="hljs-number">1024</span>*<span class="hljs-number">1024</span>, quiet: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span></span>):<br>    具体实现<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_merge_tables</span>(<span class="hljs-params">tables: <span class="hljs-type">List</span>[LabelTable], ci: Interrogator</span>) -&gt; LabelTable:<br>    具体实现<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_prompt_at_max_len</span>(<span class="hljs-params">text: <span class="hljs-built_in">str</span>, tokenize</span>) -&gt; <span class="hljs-built_in">bool</span>:<br>    具体实现<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_truncate_to_fit</span>(<span class="hljs-params">text: <span class="hljs-built_in">str</span>, tokenize</span>) -&gt; <span class="hljs-built_in">str</span>:<br>    具体实现<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">list_caption_models</span>() -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:<br>    具体实现<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">list_clip_models</span>() -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:<br>    具体实现<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_list</span>(<span class="hljs-params">data_path: <span class="hljs-built_in">str</span>, filename: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:<br>    具体实现<br></code></pre></td></tr></table></figure></p><p><code>CAPTION_MODELS</code> 定义了各个所需要的模型在huggingface 地址。<code>CACHE_URL_BASE</code> 是缓存地址</p><h3 id="config-class">Config class</h3><p>首先定义了CLIP和BILP模型 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">caption_model = <span class="hljs-literal">None</span><br>caption_processor = <span class="hljs-literal">None</span><br>clip_model = <span class="hljs-literal">None</span><br>clip_preprocess = <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure></p><p>接下来对BLIP和CLIP进行了详细的设置2 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># blip settings</span><br>caption_max_length: <span class="hljs-built_in">int</span> = <span class="hljs-number">32</span><br>caption_model_name: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-string">&#x27;blip-large&#x27;</span> <span class="hljs-comment"># use a key from CAPTION_MODELS or None</span><br>caption_offload: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span><br>  <br><span class="hljs-comment"># clip settings</span><br>clip_model_name: <span class="hljs-built_in">str</span> = <span class="hljs-string">&#x27;ViT-L-14/openai&#x27;</span><br>clip_model_path: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span><br>clip_offload: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure></p><p>这段代码是Config类中与Interrogator类相关的配置参数。</p><p>接下来定义了interrogator的相关设置 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">cache_path: <span class="hljs-built_in">str</span> = <span class="hljs-string">&#x27;cache&#x27;</span> <span class="hljs-comment"># 存储缓存的文本嵌入的路径</span><br>download_cache: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">True</span> <span class="hljs-comment"># 是否从huggingface下载缓存的嵌入向量</span><br>chunk_size: <span class="hljs-built_in">int</span> = <span class="hljs-number">2048</span> <span class="hljs-comment"># CLIP的批处理大小</span><br>data_path: <span class="hljs-built_in">str</span> = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;data&#x27;</span>)<span class="hljs-comment"># 数据文件的路径</span><br>device: <span class="hljs-built_in">str</span> = (<span class="hljs-string">&quot;mps&quot;</span> <span class="hljs-keyword">if</span> torch.backends.mps.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>flavor_intermediate_count: <span class="hljs-built_in">int</span> = <span class="hljs-number">2048</span><br>quiet: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span> <span class="hljs-comment"># 是否显示进度条</span><br></code></pre></td></tr></table></figure></p><p><code>apply_low_vram_defaults</code>方法，用于将配置参数设置为适合低显存设备的默认值。在该方法中，将一些参数设置为较小的值，以减少显存的使用。</p><h3 id="interrogator-class">Interrogator class</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, config: Config</span>):<br>self.config = config<br>self.device = config.device<br>self.dtype = torch.float16 <span class="hljs-keyword">if</span> self.device == <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">else</span> torch.float32<br>self.caption_offloaded = <span class="hljs-literal">True</span><br>self.clip_offloaded = <span class="hljs-literal">True</span><br>self.load_caption_model()<br>self.load_clip_model()<br></code></pre></td></tr></table></figure><p>继承了<code>Config</code> 类中的一些配置。</p><h4 id="load_caption_model">load_caption_model</h4><p>这个方法用于加载图像描述模型。首先判断配置中是否直接传入了图像描述模型对象，并且是否指定了图像描述模型名称。如果没有直接传入模型对象并且指定了模型名称，则根据模型名称加载对应的模型。加载过程中根据模型名称的不同选择不同的加载方式。加载完成后，将模型设置为eval模式，并根据配置决定是否将模型移动到指定的设备上</p><h4 id="load_clip_model">load_clip_model</h4><p>这个方法用于加载CLIP模型。首先根据配置中指定的CLIP模型名称解析出模型名称和预训练模型名称。然后判断配置中是否直接传入了CLIP模型对象。如果没有直接传入模型对象，则根据模型名称和预训练模型名称加载模型。加载过程中会调用<code>open_clip.create_model_and_transforms()</code>方法创建模型和预处理函数，并设置模型为eval模式。加载完成后，将模型和预处理函数保存到对应的属性中。</p><p>接下来，根据配置中的数据路径加载一些标签数据，并创建<code>LabelTable</code>对象。<code>LabelTable</code>类用于管理标签和对应的嵌入向量。这里创建了artists、flavors、mediums、movements、trendings和negative等LabelTable对象。</p><p>最后，打印加载CLIP模型和数据所花费的时间。</p><h4 id="chain">chain</h4><p>这个方法用于它用于在一组短语中选择最佳的短语，以构建一个完整的提示。</p><p>首先调用_prepare_clip()方法，准备CLIP模型。</p><p>然后，将短语列表转换为一个集合，方便操作。如果没有指定最佳提示，则通过调用rank_top()方法选择当前短语列表中与图像特征最相似的短语作为最佳提示，并计算其相似度。然后从短语集合中移除最佳提示。</p><p>接下来，使用curr_prompt和curr_sim变量保存当前的提示和相似度。</p><p>定义了一个名为check的内部函数，用于检查给定的附加短语是否应该成为当前提示的一部分。该函数会根据相似度比较结果更新最佳提示和最佳相似度，并判断是否需要更新当前提示。</p><p>使用一个循环遍历max_count次，每次迭代中选择当前短语列表中与当前提示加上附加短语后最相似的短语作为最佳短语。然后将该短语的一部分（从curr_prompt的长度加2开始）作为附加短语。调用check()函数进行相似度比较和更新。</p><p>在循环过程中，如果当前提示已经达到了最大长度，则停止迭代。最后，返回最佳提示。</p><h4 id="generate_caption">generate_caption</h4><p>使用BILP生成图像的描述。它首先对图像进行预处理，然后使用图像描述模型生成描述的tokens，最后将tokens解码为文本描述。</p><h4 id="image_to_features">image_to_features</h4><p>使用CLIP的图像编码器将图片转换成torch格式的特征</p><h4 id="interrogate">interrogate</h4><p><code>interrogate_classic</code> 首先生成一个标准格式的提示，描述图像，然后列出艺术家、趋势、风格和口味等文本修饰符。它使用了mediums、artists、trendings、movements和flavors等LabelTable对象来选择相应的修饰符。</p><p><code>interrogate_fast</code> 在生成的描述后面简单地添加排名靠前的词语。它通常比经典模式产生更好的生成提示和图像之间的相似度，但提示的可读性较差。它使用了artists、flavors、mediums、movements和trendings等LabelTable对象来选择排名靠前的词语。</p><p><code>interrogate_negative</code> 主要生成负面词汇，将与图像最不相似的词语连接在一起。它可以用于构建与正面提示相对应的负面提示，并且通常可以改善生成图像的结果，特别是在使用稳定扩散2（Stable Diffusion 2）时。它使用了flavors和negative等LabelTable对象来选择最不相似的词语。</p><p><code>interrogate</code> 会生成一个完整的提示。首先生成一个基于图像的描述，然后根据图像特征和LabelTable对象生成一组修饰符。然后使用chain方法选择最佳的修饰符，并根据相似度和一些条件选择最佳提示。最后，根据生成的多个提示的相似度，选择最终的生成提示。</p><h4 id="prepare_caption">_prepare_caption</h4><p>用于加载BLIP模型。</p><h4 id="prepare_clip">_prepare_clip</h4><p>用于加载CLIP模型。</p><h4 id="rank_top">rank_top</h4><p>这个方法用于对文本进行排名，并返回排名最高的文本。</p><p>首先加载CLIP模型。使用tokenize方法将文本数组转换为文本tokens，并将其移动到设备上。</p><p>然后，使用<code>clip_model</code>的<code>encode_text</code>方法对文本tokens进行编码，得到文本的特征向量。对特征向量进行归一化处理，使其长度为1。接着，计算文本特征向量与图像特征向量之间的相似度。通过计算特征向量的点积得到相似度。如果<code>reverse</code>为<code>True</code>，则将相似度取负，以实现按相似度降序排列。最后，返回排名最高的文本，即相似度最大的文本。</p><h4 id="similarity和similarities">similarity和similarities</h4><p>通过计算点积的方式计算了相似度</p><h3 id="labeltable-class">LabelTable class</h3><p>这个类创建标签，并对标签进行排名</p><h4 id="init"><strong>init</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, labels:<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>], desc:<span class="hljs-built_in">str</span>, ci: Interrogator</span>):<br>clip_model, config = ci.clip_model, ci.config<br>self.chunk_size = config.chunk_size<br>self.config = config<br>self.device = config.device<br>self.embeds = []<br>self.labels = labels<br>self.tokenize = ci.tokenize<br>  <br><span class="hljs-built_in">hash</span> = hashlib.sha256(<span class="hljs-string">&quot;,&quot;</span>.join(labels).encode()).hexdigest()<br>sanitized_name = self.config.clip_model_name.replace(<span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-string">&#x27;_&#x27;</span>).replace(<span class="hljs-string">&#x27;@&#x27;</span>, <span class="hljs-string">&#x27;_&#x27;</span>)<br>self._load_cached(desc, <span class="hljs-built_in">hash</span>, sanitized_name)<br>  <br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.labels) != <span class="hljs-built_in">len</span>(self.embeds):<br>self.embeds = []<br>chunks = np.array_split(self.labels, <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(self.labels)/config.chunk_size))<br><span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> tqdm(chunks, desc=<span class="hljs-string">f&quot;Preprocessing <span class="hljs-subst">&#123;desc&#125;</span>&quot;</span> <span class="hljs-keyword">if</span> desc <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>, disable=self.config.quiet):<br>text_tokens = self.tokenize(chunk).to(self.device)<br><span class="hljs-keyword">with</span> torch.no_grad(), torch.cuda.amp.autocast():<br>text_features = clip_model.encode_text(text_tokens)<br>text_features /= text_features.norm(dim=-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>text_features = text_features.half().cpu().numpy()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(text_features.shape[<span class="hljs-number">0</span>]):<br>self.embeds.append(text_features[i])<br>  <br><span class="hljs-keyword">if</span> desc <span class="hljs-keyword">and</span> self.config.cache_path:<br>os.makedirs(self.config.cache_path, exist_ok=<span class="hljs-literal">True</span>)<br>cache_filepath = os.path.join(self.config.cache_path, <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;sanitized_name&#125;</span>_<span class="hljs-subst">&#123;desc&#125;</span>.safetensors&quot;</span>)<br>tensors = &#123;<br><span class="hljs-string">&quot;embeds&quot;</span>: np.stack(self.embeds),<br><span class="hljs-string">&quot;hash&quot;</span>: np.array([<span class="hljs-built_in">ord</span>(c) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">hash</span>], dtype=np.int8)<br>&#125;<br>save_file(tensors, cache_filepath)<br>  <br><span class="hljs-keyword">if</span> self.device == <span class="hljs-string">&#x27;cpu&#x27;</span> <span class="hljs-keyword">or</span> self.device == torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>):<br>self.embeds = [e.astype(np.float32) <span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> self.embeds]<br></code></pre></td></tr></table></figure><p>继承了<code>Interrogator</code> 中的一些内容，同时对embeds 做了预处理。</p><h4 id="load_cached">_load_cached</h4><p>用于加载缓存的嵌入向量。</p><h4 id="rank和rank">_rank和rank</h4><p>用于对图像特征和文本嵌入向量进行排名。<code>_rank</code>方法计算图像特征与文本嵌入向量之间的相似度，并返回排名最高的文本索引。<code>rank</code>方法根据<code>chunk_size</code>的大小，将文本嵌入向量分成多个批次进行排名，然后返回排名最高的文本标签。</p><h2 id="data">data</h2><p>存储了常用的文字生成图片的prompt</p><h2 id="clip-interrogator究竟做了什么">clip-interrogator究竟做了什么</h2><p>首先，clip-interrogator会使用BILP生成一段对图片的自然语言描述。</p><p>接下来会根据四种模式，从data文件夹下的txt文件中组合出文字生成图片常用的prompt,通过CLIP进行编码，然后将图片也用CLIP进行编码，计算出相似度最大的一组prompt,和BILP生成的prompt拼接到一起，就得到了一组prompt。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;clip-interrogator代码解析&quot;&gt;clip-interrogator代码解析&lt;/h1&gt;
&lt;p&gt;clip-interrogator 的的主要代码在仓库的&lt;code&gt;./clip-interrogator&lt;/code&gt; 文件夹下 &lt;figure class</summary>
      
    
    
    
    
    <category term="文字生成图片" scheme="https://studyinglover.com/tags/%E6%96%87%E5%AD%97%E7%94%9F%E6%88%90%E5%9B%BE%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>GroundingDINO安装报错解决</title>
    <link href="https://studyinglover.com/2023/06/21/GroundingDINO%E5%AE%89%E8%A3%85%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/"/>
    <id>https://studyinglover.com/2023/06/21/GroundingDINO%E5%AE%89%E8%A3%85%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3/</id>
    <published>2023-06-21T17:25:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="groundingdino安装报错解决">GroundingDINO安装报错解决</h1><p>在安装会遇到这个错误 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs bash">  ERROR: Command errored out with <span class="hljs-built_in">exit</span> status 1:<br>   <span class="hljs-built_in">command</span>: /usr/bin/python3 /tmp/tmpmhvo4wyp build_wheel /tmp/tmp3a4xwmi4<br>       cwd: /tmp/pip-install-x0mg8qpf/pycocotools<br>  Complete output (77 lines):<br>  running bdist_wheel<br>  running build<br>  running build_py<br>  creating build<br>  creating build/lib.linux-x86_64-cpython-38<br>  creating build/lib.linux-x86_64-cpython-38/pycocotools<br>  copying pycocotools/coco.py -&gt; build/lib.linux-x86_64-cpython-38/pycocotools<br>  copying pycocotools/mask.py -&gt; build/lib.linux-x86_64-cpython-38/pycocotools<br>  copying pycocotools/cocoeval.py -&gt; build/lib.linux-x86_64-cpython-38/pycocotools<br>  copying pycocotools/__init__.py -&gt; build/lib.linux-x86_64-cpython-38/pycocotools<br>  running build_ext<br>  cythoning pycocotools/_mask.pyx to pycocotools/_mask.c<br>  building <span class="hljs-string">&#x27;pycocotools._mask&#x27;</span> extension<br>  creating build/temp.linux-x86_64-cpython-38<br>  creating build/temp.linux-x86_64-cpython-38/common<br>  creating build/temp.linux-x86_64-cpython-38/pycocotools<br>  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-build-env-xkmgfc0t/overlay/lib/python3.8/site-packages/numpy/core/include -I./common -I/usr/include/python3.8 -c ./common/maskApi.c -o build/temp.linux-x86_64-cpython-38/./common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99<br>  ./common/maskApi.c: In <span class="hljs-keyword">function</span> ‘rleToBbox’:<br>  ./common/maskApi.c:151:32: warning: unused variable ‘xp’ [-Wunused-variable]<br>    151 |     uint h, w, xs, ys, xe, ye, xp, cc; siz j, m;<br>        |                                ^~<br>  ./common/maskApi.c: In <span class="hljs-keyword">function</span> ‘rleFrPoly’:<br>  ./common/maskApi.c:197:3: warning: this ‘<span class="hljs-keyword">for</span>’ clause does not guard... [-Wmisleading-indentation]<br>    197 |   <span class="hljs-keyword">for</span>(j=0; j&lt;k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];<br>        |   ^~~<br>  ./common/maskApi.c:197:54: note: ...this statement, but the latter is misleadingly indented as <span class="hljs-keyword">if</span> it were guarded by the ‘<span class="hljs-keyword">for</span>’<br>    197 |   <span class="hljs-keyword">for</span>(j=0; j&lt;k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];<br>        |                                                      ^<br>  ./common/maskApi.c:198:3: warning: this ‘<span class="hljs-keyword">for</span>’ clause does not guard... [-Wmisleading-indentation]<br>    198 |   <span class="hljs-keyword">for</span>(j=0; j&lt;k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];<br>        |   ^~~<br>  ./common/maskApi.c:198:54: note: ...this statement, but the latter is misleadingly indented as <span class="hljs-keyword">if</span> it were guarded by the ‘<span class="hljs-keyword">for</span>’<br>    198 |   <span class="hljs-keyword">for</span>(j=0; j&lt;k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];<br>        |                                                      ^<br>  ./common/maskApi.c: In <span class="hljs-keyword">function</span> ‘rleToString’:<br>  ./common/maskApi.c:243:7: warning: this ‘<span class="hljs-keyword">if</span>’ clause does not guard... [-Wmisleading-indentation]<br>    243 |       <span class="hljs-keyword">if</span>(more) c |= 0x20; c+=48; s[p++]=c;<br>        |       ^~<br>  ./common/maskApi.c:243:27: note: ...this statement, but the latter is misleadingly indented as <span class="hljs-keyword">if</span> it were guarded by the ‘<span class="hljs-keyword">if</span>’<br>    243 |       <span class="hljs-keyword">if</span>(more) c |= 0x20; c+=48; s[p++]=c;<br>        |                           ^<br>  ./common/maskApi.c: In <span class="hljs-keyword">function</span> ‘rleFrString’:<br>  ./common/maskApi.c:251:3: warning: this ‘<span class="hljs-keyword">while</span>’ clause does not guard... [-Wmisleading-indentation]<br>    251 |   <span class="hljs-keyword">while</span>( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;<br>        |   ^~~~~<br>  ./common/maskApi.c:251:22: note: ...this statement, but the latter is misleadingly indented as <span class="hljs-keyword">if</span> it were guarded by the ‘<span class="hljs-keyword">while</span>’<br>    251 |   <span class="hljs-keyword">while</span>( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;<br>        |                      ^~~~<br>  ./common/maskApi.c:259:5: warning: this ‘<span class="hljs-keyword">if</span>’ clause does not guard... [-Wmisleading-indentation]<br>    259 |     <span class="hljs-keyword">if</span>(m&gt;2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;<br>        |     ^~<br>  ./common/maskApi.c:259:34: note: ...this statement, but the latter is misleadingly indented as <span class="hljs-keyword">if</span> it were guarded by the ‘<span class="hljs-keyword">if</span>’<br>    259 |     <span class="hljs-keyword">if</span>(m&gt;2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;<br>        |                                  ^~~~<br>  x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-build-env-xkmgfc0t/overlay/lib/python3.8/site-packages/numpy/core/include -I./common -I/usr/include/python3.8 -c pycocotools/_mask.c -o build/temp.linux-x86_64-cpython-38/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99<br>  pycocotools/_mask.c:6:10: fatal error: Python.h: No such file or directory<br>      6 | <span class="hljs-comment">#include &quot;Python.h&quot;</span><br>        |          ^~~~~~~~~~<br>  compilation terminated.<br>  /tmp/pip-build-env-xkmgfc0t/overlay/lib/python3.8/site-packages/setuptools/dist.py:745: SetuptoolsDeprecationWarning: Invalid dash-separated options<br>  !!<br>  <br>          ********************************************************************************<br>          Usage of dash-separated <span class="hljs-string">&#x27;index-url&#x27;</span> will not be supported <span class="hljs-keyword">in</span> future<br>          versions. Please use the underscore name <span class="hljs-string">&#x27;index_url&#x27;</span> instead.<br>  <br>          By 2023-Sep-26, you need to update your project and remove deprecated calls<br>          or your builds will no longer be supported.<br>  <br>          See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html <span class="hljs-keyword">for</span> details.<br>          ********************************************************************************<br>  <br>  !!<br>    opt = self.warn_dash_deprecation(opt, section)<br>  /tmp/pip-build-env-xkmgfc0t/overlay/lib/python3.8/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive <span class="hljs-string">&#x27;language_level&#x27;</span> not <span class="hljs-built_in">set</span>, using 2 <span class="hljs-keyword">for</span> now (Py2). This will change <span class="hljs-keyword">in</span> a later release! File: /tmp/pip-install-x0mg8qpf/pycocotools/pycocotools/_mask.pyx<br>    tree = Parsing.p_module(s, pxd, full_module_name)<br>  error: <span class="hljs-built_in">command</span> <span class="hljs-string">&#x27;/usr/bin/x86_64-linux-gnu-gcc&#x27;</span> failed with <span class="hljs-built_in">exit</span> code 1<br>  ----------------------------------------<br>  ERROR: Failed building wheel <span class="hljs-keyword">for</span> pycocotools<br>Failed to build pycocotools<br>ERROR: Could not build wheels <span class="hljs-keyword">for</span> pycocotools <span class="hljs-built_in">which</span> use PEP 517 and cannot be installed directly<br></code></pre></td></tr></table></figure> 细读报错，我们会发现是编译过程中少了一个<code>Python.h</code> 的头文件导致编译pycocotools失败。</p><p>我们尝试直接安装<code>pycocotools</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install pycocotools<br></code></pre></td></tr></table></figure><p>会出现和上面一样的错误。</p><p>google一番,提示说<code>sudo apt-get install libsuitesparse-dev</code></p><p>受到报错 <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk">Building wheel <span class="hljs-keyword">for</span> pycocotools (pyproject.toml) ... error<br> error: subprocess-exited-with-error<br> <br> × Building wheel <span class="hljs-keyword">for</span> pycocotools (pyproject.toml) did not run successfully.<br> │ <span class="hljs-keyword">exit</span> code: <span class="hljs-number">1</span><br> ╰─&gt; [<span class="hljs-number">77</span> lines of output]<br></code></pre></td></tr></table></figure></p><p>最后的结果依然是 <figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs subunit">  note: This error originates from a subprocess, and is likely not a problem with pip.<br>  ERROR: Failed building wheel for pycocotools<br>Failed to build pycocotools<br><span class="hljs-keyword">ERROR: </span>Could not build wheels for pycocotools, which is required to install pyproject.toml-based projects<br></code></pre></td></tr></table></figure></p><p>尝试通过安装<code>pip install "git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&amp;subdirectory=PythonAPI"</code> 解决</p><p>获得报错 <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs awk">fatal: unable to access <span class="hljs-string">&#x27;https://github.com/philferriere/cocoapi.git/&#x27;</span>: GnuTLS recv error (-<span class="hljs-number">110</span>): The TLS connection was non-properly terminated.<br>  error: subprocess-exited-with-error<br>  <br>  × git clone --filter=blob:none --quiet https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/philferriere/</span>cocoapi.git <span class="hljs-regexp">/tmp/</span>pip-install-a4vtujvc/pycocotools_f76f853260a94fd79f5ac4cef5f3a557 did not run successfully.<br>  │ <span class="hljs-keyword">exit</span> code: <span class="hljs-number">128</span><br>  ╰─&gt; See above <span class="hljs-keyword">for</span> output.<br>  <br>  note: This error originates from a subprocess, and is likely not a problem with pip.<br>error: subprocess-exited-with-error<br><br>× git clone --filter=blob:none --quiet https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/philferriere/</span>cocoapi.git <span class="hljs-regexp">/tmp/</span>pip-install-a4vtujvc/pycocotools_f76f853260a94fd79f5ac4cef5f3a557 did not run successfully.<br>│ <span class="hljs-keyword">exit</span> code: <span class="hljs-number">128</span><br>╰─&gt; See above <span class="hljs-keyword">for</span> output.<br></code></pre></td></tr></table></figure></p><p>运行<code>sudo apt install python3.8-dev</code></p><p>然后<code>git clone https://github.com/cocodataset/cocoapi.git</code> , <code>cd ./cocoapi/PythonAPI</code> ,接下来 <code>make</code></p><p>运行<code>pip install -e .</code> ,成功安装<code>pycocotools</code> .</p><p>再次运行<code>pip install GroundingDINO</code> , 成功。</p><figure><img src="https://proxy.thisis.plus/202306211724652.png" alt="" /><figcaption>image.png</figcaption></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;groundingdino安装报错解决&quot;&gt;GroundingDINO安装报错解决&lt;/h1&gt;
&lt;p&gt;在安装会遇到这个错误 &lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span </summary>
      
    
    
    
    <category term="踩坑" scheme="https://studyinglover.com/categories/%E8%B8%A9%E5%9D%91/"/>
    
    
  </entry>
  
  <entry>
    <title>2023华为鲲鹏畅想日暨西安高新国际会议中心零食午饭测评</title>
    <link href="https://studyinglover.com/2023/06/19/2023%E5%8D%8E%E4%B8%BA%E9%B2%B2%E9%B9%8F%E7%95%85%E6%83%B3%E6%97%A5%E6%9A%A8%E8%A5%BF%E5%AE%89%E9%AB%98%E6%96%B0%E5%9B%BD%E9%99%85%E4%BC%9A%E8%AE%AE%E4%B8%AD%E5%BF%83%E9%9B%B6%E9%A3%9F%E5%8D%88%E9%A5%AD%E6%B5%8B%E8%AF%84/"/>
    <id>https://studyinglover.com/2023/06/19/2023%E5%8D%8E%E4%B8%BA%E9%B2%B2%E9%B9%8F%E7%95%85%E6%83%B3%E6%97%A5%E6%9A%A8%E8%A5%BF%E5%AE%89%E9%AB%98%E6%96%B0%E5%9B%BD%E9%99%85%E4%BC%9A%E8%AE%AE%E4%B8%AD%E5%BF%83%E9%9B%B6%E9%A3%9F%E5%8D%88%E9%A5%AD%E6%B5%8B%E8%AF%84/</id>
    <published>2023-06-19T23:06:00.000Z</published>
    <updated>2023-08-06T15:02:45.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="华为鲲鹏畅想日暨西安高新国际会议中心零食午饭测评">2023华为鲲鹏畅想日暨西安高新国际会议中心零食午饭测评</h1><h2 id="鲲鹏活动">鲲鹏活动</h2><p>我是白吃白喝来的你真以为我是来学技术的？</p><h3 id="上午场">上午场</h3><p><img src="https://proxy.thisis.plus/202306190655993.jpg" /></p><p>院士发言，讲了从教多年开设公共课的历程，还有将核心技术掌握在自己手里的重要性，举了上世纪欧洲软件和20年哈工大哈工程被禁用matlab的例子。 <img src="https://proxy.thisis.plus/202306190655529.jpg" /></p><p>然后我就牙疼的受不了看牙去了……</p><h3 id="下午场">下午场</h3><p>下午场有三部分，星享会，鲲鹏训练营还有人才发展论坛。星享会是关于互联网+产业命题赛道和鲲鹏应用创新大赛的分享。鲲鹏训练营没有参与，我猜是用类似华为云的沙盒做实验。人才发展论坛是大佬们发言讲自己做的一些研究和人才培养模式 <img src="https://proxy.thisis.plus/202306190703495.jpg" alt="IMG_20230617_135653.jpg" /></p><figure><img src="https://proxy.thisis.plus/202306190704505.jpg" alt="" /><figcaption>IMG_20230617_173651.jpg</figcaption></figure><figure><img src="https://proxy.thisis.plus/202306190704514.jpg" alt="" /><figcaption>IMG_20230617_165145.jpg</figcaption></figure><h2 id="零食午饭测评">零食午饭测评</h2><p>因为牙疼刚做了根管的缘故没有吃的太全，所以只能聊一聊自己吃了的部分</p><h3 id="午饭">午饭</h3><p><img src="https://proxy.thisis.plus/202306190642829.jpg" /></p><p>左边粥是皮蛋瘦肉粥，绝对好评，好喝还适合我这种牙刚做了手术的人，我喝了三碗。</p><p>右边的甜点里我们最远的那一排左边的是蒸饺，正常。右边的不知道叫什么，夹心，正常水平。</p><p>中间的一排虽然长得不一样，都是千层饼。有一点咸味，有点硬不适合那天的牙。</p><p>离我们最近的一排最左边的小蛋糕，我吃了两个，第一个没啥味道，第二个有苦味。中间的豆沙。最右边的，流心绿豆糕，非常好吃，很软口感很好，很适合我的牙，吃了六个吧。</p><h3 id="零食">零食</h3><p><img src="https://proxy.thisis.plus/202306190642391.jpg" /></p><p>右边的饮料据工作人员说是他们自己调的，气泡莫吉托，挺好喝的，有碳酸饮料的感觉 <img src="https://proxy.thisis.plus/202306190642335.jpg" /></p><p>左边盘子里左上是芒果蛋糕，右上草莓蛋糕。芒果蛋糕整个是芒果和奶油，草莓蛋糕正常。左下不好吃，很硬没啥味道。右下核桃芯还是很好吃的。</p><h2 id="收获">收获</h2><p>一本基于鲲鹏的大数据挖掘de书，两个水杯，一个肩带，一个文化衫</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;华为鲲鹏畅想日暨西安高新国际会议中心零食午饭测评&quot;&gt;2023华为鲲鹏畅想日暨西安高新国际会议中心零食午饭测评&lt;/h1&gt;
&lt;h2 id=&quot;鲲鹏活动&quot;&gt;鲲鹏活动&lt;/h2&gt;
&lt;p&gt;我是白吃白喝来的你真以为我是来学技术的？&lt;/p&gt;
&lt;h3 id=&quot;上午场&quot;&gt;上午场&lt;/h3</summary>
      
    
    
    
    
  </entry>
  
</feed>
